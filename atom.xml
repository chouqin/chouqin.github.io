<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Chouqin's Blog]]></title>
  <link href="http://chouqin.github.io/atom.xml" rel="self"/>
  <link href="http://chouqin.github.io/"/>
  <updated>2015-01-02T09:11:03+08:00</updated>
  <id>http://chouqin.github.io/</id>
  <author>
    <name><![CDATA[chouqin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[2014年终总结]]></title>
    <link href="http://chouqin.github.io/blog/2014/12/31/2014-summary/"/>
    <updated>2014-12-31T18:13:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2014/12/31/2014-summary</id>
    <content type="html"><![CDATA[<p>2014年算是过得比较充实的一年，看了比较多的书和论文，
也沉下心来写过一些代码，在专业方面还是有不少的积累。
另外，在性格方面，也慢慢改变了一些自己的缺点，
虽然还需要继续努力～。</p>

<h2 id="section">计划的完成程度</h2>

<blockquote>
  <p>修身仍旧还是第一位，而且必须要花一定的时间。</p>
</blockquote>

<p>这个感觉完成得并不是很好，不过需要慢慢来，
多反省，多总结就好。</p>

<blockquote>
  <p>多看书，多看非专业书。</p>
</blockquote>

<p>看的书还挺多的，待会再慢慢总结。</p>

<blockquote>
  <p>看完Graphlab和Spark的源码, 期间需要巩固C++和学习Scala。</p>
</blockquote>

<p>Spark的源码看了大部分，了解代码的基本结构，
知道每一个功能的实现大概在什么位置。一直在跟进社区的Pull Request，
在研究Spark上面花了不少的时间，坚持下来有不少的收获。这一点明年继续保持。
Scala也在读Spark源码过程中不断熟悉，现在看Spark的源码不会有不理解的地方了。</p>

<p>至于Graphlab，完全没看。。</p>

<blockquote>
  <p>上完Convex Optimization、Probabilistic Graphical Models
和Neural Networks for Machine Learning这三门在线课程。</p>
</blockquote>

<p>Convex Optimization比较圆满的完成了，看完了整本书，
同时顺便看了ADMM的那篇比较长的论文，Boyd老师真是大师，
讲课非常幽默，听完他的课之后对于优化这方面算是有了一个整体的框架，
了解了解决优化问题的思考方式。</p>

<p>另外两门课程没有参加，不过已经放在2015年的目标里了。</p>

<blockquote>
  <p>在github上为开源项目提交代码。</p>
</blockquote>

<p>今年给Spark提交过几个patch，主要是和MLlib里面的决策树相关。</p>

<p>整体来说，2014年的计划完成了60%吧，由于完成了计划之外的一些事情。</p>

<h2 id="section-1">看完的书</h2>

<h3 id="section-2">计算机方面的</h3>

<ol>
  <li>《Effective C++》: 想写好C++程序的必读书籍，
看完里面的建议能够避免一些初学者易犯的错误。
读起来并不难，关键需要在实际写代码的过程中去使用这些建议。</li>
  <li>《Unix编程艺术》：整本书的中心思想就两个字：简单。
通过简单的方式去实现程序，将程序拆分成简单的低耦合的模块。
这是一本关于“知识”，更关注于“思想”； 关于“方法”，更关注于“理念”的书。 整本书都是在讲述在UNIX哲学中如何设计软件， 如何使用工具，如何看待各种技术， 这是一本教你如何从UNIX的视角去看待问题的书。
且不说这里面的观点正确与否， 它确实能够给你提供一个看待问题的新的思路。 而且UNIX文化和哲学中拥有许多值得去领悟的精华。 看这本书一点都不觉得沉闷，每一个观点都能够引发我思考， 结合自己的经历得出新的感悟和体会。 书中的代码虽然不多，却能够教你如何编程， 而大量的软件实例分析又像一个个路标， 指出设计中的陷阱和正确的方向。</li>
  <li>《统计学习方法》：虽然只有一些简单的机器学习算法，
但是里面的公式推导还是比较好理解的。对于入门来说，这样一本中文的图书真的很有帮助。</li>
  <li>《多处理器编程的艺术》：这本书开阔了我对于写并发程序的看法，通过一个个并发数据结构的例子，
可以学习到编写“无锁”程序的技巧。为了写好并发的程序，需要对于底层的体系结构有一定的了解。
书中第3章有一些理论部分没有认真地看过。</li>
  <li>《计算机程序的构造和解释》：非常经典的一本书，
通过这本书可以体会到函数式编程的优雅。</li>
  <li>《编程人生》：英文名叫《Coders at Worker》，对于国外10多个优秀程序员的采访，
从这些人身上可以学习到程序设计的技巧和思考问题的方式。</li>
  <li>《Convex Optimization》：虽然整本书超过700页，但是理解起来并不困难，只要掌握微积分和线性代数即可。
看完整本书，结合对应的课程讲解，有一种豁然开朗的感觉。</li>
  <li>《Masterminds of Programming》: 采访了一些语言的作者，看完了对于C#的作者和Haskell作者的采访，
感觉一门语言能够支持EDSL很重要。</li>
  <li>《人月神话》：本书描述的是作者在上个实际60年代管理大型软件工程项目的一些经验和看法，
这些观点拿到现在来看也仍然没有过时。</li>
</ol>

<h3 id="section-3">非计算机的</h3>

<ol>
  <li>《史玉柱》：一本史玉柱自述的关于营销的书，观点都很实在，很接地气。</li>
  <li>《信息简史》：这本书和计算机也有一定的关系，讲述信息相关的各个方面，
介绍信息技术发展从古到今的一些科技成果，令人大开眼界。</li>
  <li>《The Elements of Style》: 讲述如何用英语进行写作的书，非常薄的一本书（才100多页），
对于如何使用词语、标点符号和如何组织段落等都有一些很好的建议。</li>
  <li>《自控力》：标题像鸡汤，其实是关于如何认识大脑中的三种不同的力量，
以及如何使用它们来达到自控的效果。书中的一些案例让我感同身受，
照着书中的建议去做确实能起到不错的效果。</li>
  <li>《周鸿祎》：看过的最差的书之一，里面提到的有用的观点很少，
大部分是对于360的自我标榜，重复的废话太多，根本不值得用一本书来讲述。</li>
  <li>《文明之光》：有点科技史的感觉，没有《浪潮之巅》和《数学之美》有趣，
不知道是不是个人兴趣的问题。</li>
  <li>《失控》：看完了前面3章，讲述如何真正地实现机器的智能，
使用群体的智慧。</li>
</ol>

<h2 id="section-4">计划之外</h2>

<h3 id="haskell">Haskell的课程</h3>

<p>今年在Edx上学习了一门FP101的课程，比较基础地学习了Haskell，
Haskell确实和我见过的程序设计语言不一样，它主张使用各种抽象来达到代码的复用。
其中，最难以理解的就是Monad这个概念，当时花了很长时间才明白Monad是什么，
而后通过Monad实现CPS让我不住惊叹于它的强大。现在，仍然不敢说已经完全理解Monad，
以后还需要多多使用来加深对它的理解。它能够给你一个全新的写程序的角度。另外，
Haskell的类型系统真的很强大，当时在没有完全理解CPS的情况下可以依靠类型系统的提示写出正确的程序。</p>

<h3 id="section-5">一些论文</h3>

<p>今年看了不少的论文（相对于以前来说），主要是和机器学习相关的，
看完这些论文除了让我对论文中描述的技术有更深入的理解之外，
更重要的是让我学会了一些看论文的方法，以及不再害怕阅读论文的能力。</p>

<h3 id="section-6">学车</h3>

<p>虽然2014年最后一天的科目三没有通过，稍稍有点遗憾，
但是整个学车的过程还是让我成长了很多。
我克服了自己内心的恐惧，勇敢地走出自己的舒适区，
在一个自己非常不擅长的领域努力并取得了一定的成功。
学车整个的过程确实让我的内心变得更加强大，我也不断地弥补了一些自己性格上的弱势。
现在离最终拿到驾照还有很长的一段路要走，但是我相信我一定会成功的。</p>

<h2 id="section-7">2015年计划</h2>

<ol>
  <li>拿到驾照，顺便锻炼自己强大的内心。</li>
  <li>学习go，深入了解Docker及相关的技术。</li>
  <li>机器学习方面，看完ESL和PRML（或者MLAPP)，学习落下的课程。</li>
  <li>多看书，多看和专业无关的书。</li>
  <li>跟进Spark的进展，争取在这方面能够有所建树。</li>
  <li>看完parameter_server或者pettum的源码。</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《人月神话》读书心得]]></title>
    <link href="http://chouqin.github.io/blog/2014/12/15/the-mythical-man-month/"/>
    <updated>2014-12-15T15:32:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2014/12/15/the-mythical-man-month</id>
    <content type="html"><![CDATA[<p>花几天的时间读完了《人月神话》这本软件工程领域的经典书籍。
本书并不厚，作者的文笔很好，讲述一个观点时能够解释得非常清楚，
翻译得也很不错，没有给理解带来障碍。
书中描述的是作者在上个实际60年代管理大型软件工程项目的一些经验和看法，
可是这些观点拿到现在来看也仍然没有过时。
我在此总结一些我比较有体会的观点，并谈谈我的一些体会。</p>

<h2 id="section">人月神话</h2>

<p>首先是和书名对应的这个观点——“人月神话”，
意思是说尽管一个项目的工作量可以用人月来衡量，
但是“人”和“月”这两个量度并不是可以互换的，
也就是说不能通过增加更多的人手来减少项目完成所需要的时间。
这主要是由于两方面的原因：</p>

<ul>
  <li>有些任务由于次序上的限制不能分解，
也就是说不能把一个任务分给两个人来做来减少一半的时间。</li>
  <li>增加了一个人员就增加了培训和交流的成本。</li>
</ul>

<p>因此，作者提出了Brooks法则：</p>

<blockquote>
  <p>向进度落后的项目中增加人手，只会使进度更加落后。</p>
</blockquote>

<p>这就是除去了神话色彩的人月。</p>

<h2 id="section-1">概念完整性</h2>

<p>概念完整性是指整个系统的设计具有一致性，系统只反应唯一的设计理念。
这要求系统的设计必须由一个人，或者非常少数互有默契的人员来实现。
在本书中，作者希望按照“外科手术队伍”的形式来组织团队，
团队的首席程序员类似于外科手术队伍的医生，他定义系统的功能，
设计程序，编制源代码，其他的人员负责给首席程序员提供必要的帮助。
或者，可以对设计方法和具体实现进行分工，
由架构师来完成设计，制定好技术说明，而实现人员负责实现。</p>

<p>概念完整性是如此重要，我所知的成功的软件项目都是反应了一两个天才程序员的理念，
由他们来决定整个项目的走向。</p>

<h2 id="section-2">没有银弹</h2>

<p>这是本书中一个颇具争议的观点：</p>

<blockquote>
  <p>在未来十年内，无论是在技术还是管理方法上，
都看不出有任何突破性的进步，
能够独立保证在十年内大幅度地提高软件的生产率、可靠性和简洁性。</p>
</blockquote>

<p>首先，作者把软件项目的开发过程分为两部分：</p>

<ul>
  <li>根本任务，打造构成抽象软件的复杂概念结构，我理解就是完成软件的设计。</li>
  <li>次要任务，使用编程语言表达这些抽象实体，也就是完成实现。</li>
</ul>

<p>作者认为，现在的技术或管理方法的革新，只能改进次要任务的生产率，
而根本任务的难度并没有发生改变。这样，除非次要任务能够占到所有工作的9/10以上，
否则总体的生产率不会有数量级的提升。</p>

<p>那为什么根本任务的生产率无法提高呢？这是由于开发软件系统需要面对这些无法规避的问题：</p>

<ul>
  <li>
    <p>复杂度。一个软件系统有大量的状态，存在大量不同元素的相互叠加。
这使得软件系统的复杂性以指数的形式增长。而且，这些复杂度是软件系统的根本属性，
而不像数学和物理中那样可以建立简化的模型而忽略复杂的次要因素。</p>
  </li>
  <li>
    <p>一致性。复杂度的问题不只是软件工程师才会面对，物理学家也会面临复杂度的问题。
但是他们相信能够建立一个通用的理论将这些复杂性统一起来，因为整个宇宙的规律是由上帝创造的，
而上帝不是反复无常的。而软件工程师需要控制的复杂度是随心所欲，毫无规律可言的，
需要遵循人为惯例和系统约束，需要和这些系统保持一致。
（可以这样理解，这些复杂度是由不同的PM带来的，我没有黑PM啊。。）</p>
  </li>
  <li>
    <p>可变性。有两个因素导致软件需要经常发生变化，
一是软件系统改变的容易性使得有更多改变的需求（PM说，不就是改两行代码吗？
他绝不会轻易让人去改装一辆生产好的汽车）；二是软件的寄主（操作系统，硬件）经常发生变化，
使得软件需要改变。</p>
  </li>
  <li>
    <p>不可见性。这一点我不是很理解，可能随着图形界面的提出，
软件的可见性能够得到很大程度的改善吧。</p>
  </li>
</ul>

<p>似乎，作者提出的这些问题40年后仍然没有得到解决，
对抗软件复杂性和可变性一个比较好的方式是快速原型，然后不断迭代。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2013年终总结]]></title>
    <link href="http://chouqin.github.io/blog/2013/12/31/2013-summary/"/>
    <updated>2013-12-31T21:56:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/12/31/2013-summary</id>
    <content type="html"><![CDATA[<p>还是踩着年末的尾巴发一篇年终总结吧。</p>

<p>2013对我来说不是平淡的一年。
这一年，我大学毕业，从一所大学来到另外一所大学，
分别原来的同学和朋友，
又在新的地方建立起了人际关系网；
这一年，我从大学生变成了研究生，
伴随着学历的增长，我的生活节奏也完全发生变化，
现在的我，开始沉下心来学习一些东西，
虽然现在仍然没有很大的成果。
这一年，我和她吵了不知道多少次架，
每次都是因我而起，我心里十分愧疚，
我现在仍然不够成熟，
心胸不够开阔。</p>

<h2 id="section">计划的完成程度</h2>

<blockquote>
  <p>多看书，多感受生活，开阔自己的胸襟</p>
</blockquote>

<p>虽然这被放在了计划的第一条，但是完成的最不好。
这里的“看书”，当然是说非专业的书籍，
印象当中就看了《天龙八部》和《唐浩明评点曾国藩家书》（上下册），
家书下册还是这两天逼迫自己看完的，
看书之少，现在都替自己不好意思。</p>

<p>至于修身，也没有花多少功夫，
否则也不至于跟女朋友吵那么多架。
没有把这个放在比较重要的位置，
仍然还是我行我素，
只知道在专业方面努力，
其他方面都不在乎。
这一点，在来年必须要改。</p>

<blockquote>
  <p>学习一门新的编程语言，可能是go或者erlang</p>
</blockquote>

<p>也完成的不是很好，大概的学习了一下go(完成了go tour)，
没有用它写过实际的项目。</p>

<blockquote>
  <p>学完完有关数据挖掘的基础知识</p>
</blockquote>

<p>这个完成得还不错，
掌握了很多的机器学习和数据挖掘方面的基础知识。
完成了毕业设计，使用scikit-learn开发过机器学习程序，
写了很多实现机器学习算法的matlab代码。
上了两门机器学习的课程，一门是浙大蔡登老师上的，
另一门是Coursera上的。</p>

<blockquote>
  <p>为github上的一个库提交代码</p>
</blockquote>

<p>为<a href="https://github.com/easychen/TeamToy-Plugins">TeamToy-Plugin</a>这个项目写了两个插件，
一个是OpenId的，一个是创意墙（团队用户可以在上面分享创意，使用类似于Hacknews的排序，
这个插件没有提交）。</p>

<p>这个计划完成程度也不是很满意，投入的时间太少了。</p>

<h2 id="section-1">计划之外</h2>

<h3 id="section-2">专业书</h3>

<p>2013年在专业方面的投入还是蛮多的，
看过的书不能算少，也不能算多：</p>

<ol>
  <li>
    <p>《The C Programming Language》，这仅仅只有200多页的书，
除了让我知道如何写出好的C程序之外，
也让我明白了如何如何精简地表达自己的观点。</p>
  </li>
  <li>
    <p>《The CPP Programming Language》，以前一直对这本书持保留看法，
觉得这么厚的一本书一定晦涩难懂，
直到我认认真真地把整本书都看了一遍，
才发现这是一本不可多得的好书。
整本书讲解清晰，
把C++这么复杂的一门语言的语言特性阐释得十分清楚，
而且，里面还有很多如何写出更好的程序的技巧，
很多时候作者的很多思想会引起我强烈的共鸣，
或者启发我深度的思考。</p>
  </li>
  <li>
    <p>《Introduction to Data Mining》，
这本书总体感觉是介绍性质的，里面设计的理论不是很深，
数学讲解不是很多，不过能从中知道数据挖掘的各个方面。
可能Jiawei Han老师的那本数据挖掘更好一些。</p>
  </li>
  <li>
    <p>《Pattern Classification》，
这本书是上机器学习课程的主要教材，
里面的理论讲得很深，
是一本比较好的参考书。</p>
  </li>
  <li>
    <p>《The Practice of Programming》,
看这本书，完全是冲着Robert Pike的大名去的，
看完之后果然不失所望，
学到了很多的编程方法，
只是这本书的评注实在让人哭笑不得。</p>
  </li>
  <li>
    <p>《Effective Java》,
这本书看的是中文版，
翻译得不是很好，
有少数几个地方有点难以理解。
由于以前写的Java程序太少，
看完这本书之后收益还是蛮大的，
至少现在知道怎么去写Java程序了，
同时对于面向对象的特性也有了更加深入的理解。</p>
  </li>
</ol>

<p>应该说，今年看书确实比以往有所长进，
因为看完书之后能够对它进行总结，
其中一些重要的观点和思想都记录下来，
而不是看完就忘记了。
我觉得这是一种很好的看书方法，
看书不应该一味的追求速度，
看完之后的总结很有必要。</p>

<h3 id="coding">Coding</h3>

<p>2013年写过的代码不能算多，写的代码是PHP和Python，
但是有时候也看一些其它语言的书和文章，
然后拿着这些特性来进行一个比较，
想得比较多。同时，
有时需要写一些代码来测试一些有趣的语言特性，
这些代码可以作为以后的参考。</p>

<p>同时，今年看了几个开源项目的代码，
包括scrapy和redis，
看这些代码一方面能够开阔自己的视野，
另一方面对于如何写程序也能够有所体会。</p>

<h3 id="paper">Paper</h3>

<p>2013年也看过一些论文，
包括google的三大论文，
还有graphlab的4篇论文，
Spark的两篇论文。
对于后面的两种论文，
现在理解还不是很深入，
幸亏存在开源的代码能够加深理解。</p>

<p>在机器学习方面也看过一些论文，
其中推荐系统和聚类方面的论文看得比较多。</p>

<h2 id="section-3">2014年计划</h2>

<ol>
  <li>修身仍旧还是第一位，而且必须要花一定的时间。</li>
  <li>多看书，多看非专业书。</li>
  <li>看完Graphlab和Spark的源码, 期间需要巩固C++和学习Scala。</li>
  <li>上完Convex Optimization、Probabilistic Graphical Models
和Neural Networks for Machine Learning这三门在线课程。</li>
  <li>在github上为开源项目提交代码。</li>
</ol>

<p>祝愿所有人新年快乐，新的一年实现自己的梦想。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bigtable 学习心得]]></title>
    <link href="http://chouqin.github.io/blog/2013/10/24/bigtable/"/>
    <updated>2013-10-24T20:49:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/10/24/bigtable</id>
    <content type="html"><![CDATA[<h2 id="section">基本介绍</h2>

<p>Bigtable是一个分布式的数据库，
它的出现主要是因为传统的关系型数据库在面对大量数据（PB级别）时不具有扩展性。
Bigtable在谷歌内部得到了广泛使用，
<a href="http://hbase.apache.org/">Apache HBase</a>是它的开源实现。</p>

<h3 id="section-1">数据格式</h3>

<p>可以把一个Bigtable当成一个持久化的，分布式的，多维的map。
它的值通过<code>(rowkey, columnkey, timestamp)</code>来索引。
其中<code>rowkey</code>，<code>columnkey</code>和值都可以是任意的字符串。
如下图所示。</p>

<p><img src="http://chouqin.github.io/images/row_column.jpg" alt="Bigtable数据示意图" /></p>

<p>在上图中，<code>rowkey</code>是<code>com.cnn.www</code>。
在Bigtable中，对row的操作是原子(atomic)的。
在Bigtable中，数据的保存顺序是通过<code>rowkey</code>的字典序来维持的，
基于这个特点，可以通过挑选合适的<code>rowkey</code>把相关的数据放在一起。
比如上图，通过使用倒序的主机名作为<code>rowkey</code>，
可以把同一域名下的网页放在一起。
几个row组合起来形成一个tablet，
一个table由一个或多个tablet组成。</p>

<p><code>columnkey</code>通过<code>column family</code>来进行划分，
如上图，anchor就是一个<code>column family</code>，它有两个<code>column key</code>：
<code>anchor:cnnsi.com</code>和<code>anchor:my.look.cn</code>。
contents也是一个<code>column family</code>, 它只有一个<code>column key</code>，
就是<code>contents:</code>。<code>column family</code>是访问控制的基本单位。
每一个<code>column key</code>必须以<code>column family:qualifier</code>的格式命名。</p>

<p>对于同一个<code>rowkey</code>和<code>columnkey</code>的组合，
Bigtable根据不同的<code>timestamp</code>保存了不同的值。
通常，会保存最近的几个版本（具体的版本数用户可以指定），
过期的数据会被垃圾回收掉。</p>

<h3 id="api">API</h3>

<p>Bigtable的API非常简单，下面是两个使用API的例子： </p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>写Bigtable</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="cpp"><span class="line"><span class="c1">// Open the table</span>
</span><span class="line"><span class="n">Table</span> <span class="o">*</span><span class="n">T</span> <span class="o">=</span> <span class="n">OpenOrDie</span><span class="p">(</span><span class="s">&quot;/bigtable/web/webtable&quot;</span><span class="p">);</span>
</span><span class="line"><span class="c1">// Write a new anchor and delete an old anchor</span>
</span><span class="line"><span class="n">RowMutation</span> <span class="n">r1</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="s">&quot;com.cnn.www&quot;</span><span class="p">);</span>
</span><span class="line"><span class="n">r1</span><span class="p">.</span><span class="n">Set</span><span class="p">(</span><span class="s">&quot;anchor:www.c-span.org&quot;</span><span class="p">,</span> <span class="s">&quot;CNN&quot;</span><span class="p">);</span>
</span><span class="line"><span class="n">r1</span><span class="p">.</span><span class="n">Delete</span><span class="p">(</span><span class="s">&quot;anchor:www.abc.com&quot;</span><span class="p">);</span>
</span><span class="line"><span class="n">Operation</span> <span class="n">op</span><span class="p">;</span>
</span><span class="line"><span class="n">Apply</span><span class="p">(</span><span class="o">&amp;</span><span class="n">op</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">r1</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>上面的代码段对<code>rowkey="com.cnn.www"</code>的行，
将<code>columnkey="anchor:www.c-span.org"</code>的列的值设置为<code>CNN</code>，
同时删除<code>columnkey = "anchor:www.abc.com"</code>的列。其中<code>Apply()</code>是原子操作。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>读Bigtable</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="cpp"><span class="line"><span class="n">Scanner</span> <span class="n">scanner</span><span class="p">(</span><span class="n">T</span><span class="p">);</span>
</span><span class="line"><span class="n">ScanStream</span> <span class="o">*</span><span class="n">stream</span><span class="p">;</span>
</span><span class="line"><span class="n">stream</span> <span class="o">=</span> <span class="n">scanner</span><span class="p">.</span><span class="n">FetchColumnFamily</span><span class="p">(</span><span class="s">&quot;anchor&quot;</span><span class="p">);</span>
</span><span class="line"><span class="n">stream</span><span class="o">-&gt;</span><span class="n">SetReturnAllVersions</span><span class="p">();</span>
</span><span class="line"><span class="n">scanner</span><span class="p">.</span><span class="n">Lookup</span><span class="p">(</span><span class="s">&quot;com.cnn.www&quot;</span><span class="p">);</span>
</span><span class="line"><span class="k">for</span> <span class="p">(;</span> <span class="o">!</span><span class="n">stream</span><span class="o">-&gt;</span><span class="n">Done</span><span class="p">();</span> <span class="n">stream</span><span class="o">-&gt;</span><span class="n">Next</span><span class="p">())</span> <span class="p">{</span>
</span><span class="line">    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;%s %s %lld %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span>
</span><span class="line">            <span class="n">scanner</span><span class="p">.</span><span class="n">RowName</span><span class="p">(),</span>
</span><span class="line">            <span class="n">stream</span><span class="o">-&gt;</span><span class="n">ColumnName</span><span class="p">(),</span>
</span><span class="line">            <span class="n">stream</span><span class="o">-&gt;</span><span class="n">MicroTimestamp</span><span class="p">(),</span>
</span><span class="line">            <span class="n">stream</span><span class="o">-&gt;</span><span class="n">Value</span><span class="p">());</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>上面的代码段遍历<code>rowkey="com.cnn.www"</code>的行中<code>column family="anchor"</code>的所有列的所有版本。</p>

<h2 id="section-2">实现</h2>

<p>Bigtable使用了几个部件构建而成：</p>

<ul>
  <li>GFS，Bigtable的底层依赖GFS，它使用GFS来保存数据和commit log，马上就会讲述细节。</li>
  <li>
    <p>Chubby，是Google发布的另外一个分布式系统，它具体的原理我还没有去看那篇论文，
  现在只需要知道Bigtable使用Chubby来完成下面的事情：</p>

    <ul>
      <li>保证任何时候只有一个bigtable master server</li>
      <li>存放Bigtable最开始的数据，用于定位METADATA，接下来会看到。</li>
      <li>用于监控tablet server的状态</li>
      <li>存放schema</li>
      <li>存放ACL(access control list)</li>
    </ul>

    <p>Chubby对于Bigtable非常重要，如果它停止工作了，
  那么整个Bigtable也停止工作。
  Chubby的开源实现是<a href="http://zookeeper.apache.org/">ZooKeeper</a>，
  下次再来研究Chubby。</p>
  </li>
</ul>

<h3 id="section-3">组成部分</h3>

<p>和GFS类似，Bigtable也由三个部分组成，分别是:</p>

<ul>
  <li>client：用于和应用程序交互</li>
  <li>一个master: 管理整个系统，要做的工作包括分配tablet，
负载均衡，垃圾回收，处理schema的变化。</li>
  <li>很多的tablet server：一个tablet server负责多个tablet，
client对于tablet的读写请求直接与tablet server进行交互。</li>
</ul>

<p>需要注意的是，与GFS不一样，
关于tablet的位置信息client不需要通过master就可以知道(接下来就会提到)，
所以大部分情况下client都不需要和master交互，
这样master上的压力更小了。</p>

<h3 id="tablet">Tablet的位置</h3>

<p>Bigtable使用一个三层的结构来存放tablet的位置，
如下图所示。(论文上说这个和B+树比较像，
我倒觉得用inode来类比更加好理解)</p>

<p><img src="http://chouqin.github.io/images/tablet_location_hierarchy.png" alt="" /></p>

<p>首先，一个Chubby File保存了root tablet的位置。
root tablet是一个特殊的METADATA table，
它保存了所有其他METADATA tablet的位置。
每一个METADATA又保存了user tablet的位置。
所以，顺着这个结构走下来，就能找到任意的tablet的位置。</p>

<p>关于这个“位置”，我是这样理解的，
它应该是一个具体的tablet server的名字，
client知道了哪个tablet server之后就向那个tablet server发出请求。
如果是这样的话，把tablet重新分配之后master需要去更新这些保存位置的tablet。</p>

<p>这里还有几个计算：</p>

<ul>
  <li>如果一行占的空间是1KB，一个tablet的空间是128MB，
那么这样一个三层的结构能够保存的tablet的数目为$2^{34}$，
这个很容易理解，128MB / 1KB = $2^{17}$，两级下来就是$2^{34}$。</li>
  <li>客户端会缓存住tablet的location，这样就不用每次都去读这个层级的结构。
如果客户端没有缓存，那么它读取一个tablet需要3次和tablet server的交互
（读root，METADATA，user tablet各一次)。如果缓存过期了，
最多需要6次和tablet server的交互（对于这个，我的理解是，如果客户端缓存了root tablet的location,
但是它过期了，那么它首先顺着这个结构下去，需要3次，然后发现不对，
又重新向Chubby得到root的位置，又再次顺着这个结构下去3次，
一共6次）。</li>
</ul>

<h3 id="tablet-1">Tablet的分配</h3>

<p>一个tablet一次只会被分配给一个tablet server，
master保存下面的信息：</p>

<ul>
  <li>哪些tablet server是正常工作的（alive）</li>
  <li>哪些tablet被分配给哪些tablet server</li>
  <li>哪些tablet没有被分配（这个只是暂时的，master会把这些tablet分配好，外面看不到这个状态？）</li>
</ul>

<p>当一个tablet server启动时，
它会去获取Chubby的某个特定目录下的一个文件（一个tablet server唯一的对应这个目录下的一个文件）的互斥锁。
master通过检查这个目录查看哪些tablet server是alive的。
tablet server如果丢失了这个互斥锁，那么它会尝试重新获取，
如果这个文件不存在了，tablet server永远都拿不到这个锁了，
那么它会自动停止。
如果tablet server不工作了，它会释放这个锁，
这样master就知道它没有工作了，把它上面的tablet分配给其他的tablet server。</p>

<p>master会频繁地和那些正常工作的tablet server进行通信来获取它们的状态，
如果tablet server告诉master它失去了锁或者无法和这个tablet server进行通信，
那么master会尝试获取这个tablet server对应的文件锁，
如果能够拿到这个锁，说明Chubby能正常工作，
而这个tablet server要么死掉了要么不能和Chubby交互，
那么master就删除这个tablet server对应的文件，
这样这个tablet server就没用了，
然后master把这个tablet server上的tablet分配给其他的tablet server。</p>

<p>在master启动时，它会执行下面的步骤：</p>

<ol>
  <li>首先，它会去Chubby上获取master锁，确保同一时间只有一个master工作</li>
  <li>然后，扫描Chubby上的目录（就是上面提到的目录，所有tablet server对应的文件都在这个目录下），
知道哪些tablet server是alive的</li>
  <li>然后，和每个alive的tablet server交互，知道哪些tablet已经被分配了</li>
  <li>最后，便利tablet位置的三层结构（Figure 4），知道一共有哪些tablet，
然后把这些tablet分配给tablet server。</li>
</ol>

<p>这里有一个问题是，如果METADATA的tablet没有被分配，
那么它就不能被读取，那么第4步就没法进行了。
这个问题可以这样解决，如果需要读取某个tablet时它还没有被分配，
那么先把它分配给某个tablet server，然后就可以继续接下来的步骤。</p>

<p>当下面的情况发生时，tablet的分配情况要进行调整：</p>

<ul>
  <li>tablet被创建或删除</li>
  <li>tablet被合并</li>
  <li>tablet被切分成两个tablet</li>
</ul>

<p>前面两种情况都是在master进行的，所以master直接进行调整就行，
而第三种过程是在某个tablet server上进行的，
master怎么知道的呢？
当tablet server对tablet进行切分时，
它首先在METADATA的tablet上记录下这个新的tablet，
然后通知master发生了改变。
如果这个通知丢失了，
那么当master去请求这个被切分的tablet时，
tablet server会发现这个tablet的METADATA table只是请求的METADATA的一部分，
就知道发生了切分，然后告诉master。</p>

<h3 id="tablet-2">Tablet的保存</h3>

<p>下面来看下一个tablet具体是如何保存的。</p>

<p><img src="http://chouqin.github.io/images/tablet_representation.png" alt="Tablet的表示" /></p>

<p>根据<a href="http://www.nosqlnotes.net/archives/122">这篇博客</a>，
要保存一个tablet，有这么几个部分：</p>

<ul>
  <li>主SSTable，就是持久化的不可变的哈系表，保存在GFS上</li>
  <li>memtable，在内存中记录最近的修改操作</li>
  <li>commit log，修改记录，分为compacted和uncompacted（待会会说明）</li>
  <li>次SSTable(为了区分两种SSTable，我用了“主”， “次”，不是重要性的区分)，
这种SSTable是memtable的持久化版本，次SSTable的存在是为了加快recovery的速度，
因为recovery需要从commit log恢复memtable，同时可以释放memtable的内存</li>
</ul>

<p>有了这几个部分，对tablet的操作也就变得容易了，
对于写操作，只需要记录把操作记录在commit log中，
同时写入memtable。对于读操作，
由于数据不仅仅保存在主SSTable上，
还需要结合memtable和次SSTable来进行。</p>

<h3 id="compactions">Compactions</h3>

<p>Compaction主要是为了解决上面过程中出现的问题，它分为3种：</p>

<ul>
  <li>minor compaction: 这个操作就是把memtable中的内容保存到SSTable,
释放memtable的内存，同时减小recovery时需要读取的commit log的数目，
已经被保存到次SSTable上的操作对应的commit称为compacted，
recovery时只需要从uncompacted的commit log中恢复就行了。 </li>
  <li>merge compaction: 
因为每次读取操作时都需要读取主SSTable和相关的次SSTable，
所以次SSTable的数量不能太多，因此，
master会把一些次SSTable组合成一个新的次SSTable。</li>
  <li>major compaction: 
master把次SSTable和memtable中的内容整合到SSTable里，
这样，就能回收掉修改的和删除的记录所占的空间。</li>
</ul>

<h2 id="section-4">优化</h2>

<h3 id="locality-groups">Locality groups</h3>

<p>client可以把一些列组放在一起形成一个locality group,
在每一个tablet里面，会为每一个locality group生成一个单独的SSTable,
使用locality group的好处是：</p>

<ul>
  <li>可以提高读的性能，比如把网页的contents放在一个locality group，
而metadata放在另外一个locality group，
这样读取metadata时就不需要读取网页的内容。</li>
  <li>可以对于不同的locality采取不同的调优参数。比如，
可以把有些locality group的SSTable放入内存。</li>
</ul>

<h3 id="cache">Cache</h3>

<p>为了提高读性能，tablet server采用了两种级别的cache:</p>

<ol>
  <li>Scan Cache，缓存从SSTable返回的key-value对</li>
  <li>Block Cache，缓存从GFS读回来的SSTable的block</li>
</ol>

<h3 id="bloom-filters">Bloom filters</h3>

<p>读操作需要结合SSTable和memtable，因此，
可以通过bloom filter来制定某些locality group的数据不可能存在于某些SSTable，
这样就可以减少需要读取的SSTable的数量。
Bloom filter一般保存在tablet server的内存中。</p>

<h3 id="commit-log">Commit log实现</h3>

<p>在Bigtable中，每一个tablet server只保存一个commit log, 
这个commit log保存了所有的tablet相关的log。这样做的好处是：</p>

<ul>
  <li>如果每个tablet一个commit log，就会导致同时有很多写请求发到GFS,
这样就会很多的磁盘seek。</li>
  <li>这样限制了group commit的作用，
因为只有同一个tablet的写操作才能被合并成一个到一个group commit。</li>
</ul>

<p>所有tablet的commit log组合成一个文件增加了恢复的复杂性，
因为这样不同的tablet可能被迁移到不同的tablet server，
这样所有相关的tablet server都需要读取这个commit log来获取tablet的信息，
这个commit log会被重复读多次。</p>

<p>解决这个问题的一个办法是在recovery时，
先把commit log使用<code>&lt;table, row name, log sequence number&gt;</code>作为key进行排序，
这样一个tablet的commit log就是连续的，可以通过一次seek，
然后连续读就可以得到。
这个排序的过程也可以通过把这个commit log分成几块，然后并发地进行排序来加快速度。</p>

<p>为了避免GFS集群中由于网络原因或者load情况带来性能上的波动，
通常使用两个线程来完成写commit log的操作，
每一个线程有自己的commit log文件，
同一时课只有一个线程在写，
如果一个线程写出现了性能上的问题，
就切换到另外一个线程（因为两个线程使用了不同的文件，
可能分布到不同的chunkserver）。同时，
使用序列号来消除重复的commit log。</p>

<h3 id="recovery">加快recovery</h3>

<p>如果master把tablet从一个tablet server移到另一个，
源tablet server可以进行一次minor compaction，
这样uncompacted的commit log就减少了很多，
因为这个过程中可能会有其他的写操作，
所以在upload这个tablet时，
可以再进行一次非常快的minor compaction，
这样就不要进行recovery了。</p>

<h3 id="section-5">不变性</h3>

<p>利用SSTable的不可变性带来了以下的方便：</p>

<ul>
  <li>缓存。</li>
  <li>memtable是唯一可变的数据结果，对它使用<a href="http://en.wikipedia.org/wiki/Copy-on-write">copy-on-write</a>来消除读写冲突。</li>
  <li>回收垃圾只需要回收SSTable就好了。</li>
  <li>在split时，child tablet可以使用parent tablet的SSTable。</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[把博客迁到Octopress]]></title>
    <link href="http://chouqin.github.io/blog/2013/10/21/migrate-to-octopress/"/>
    <updated>2013-10-21T20:02:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/10/21/migrate-to-octopress</id>
    <content type="html"><![CDATA[<p>折腾了一个下午，终于把博客迁到到了Octopress。
迁移的原因主要有两点：</p>

<ul>
  <li>
    <p>喜欢Octopress整体的风格，包括它的响应式设计，
还有特别好看的<code>solarized</code>的语法高亮。</p>
  </li>
  <li>
    <p>以前在<code>jekyll</code>上写博客，在<code>github</code>上面开了两个库，
原因在于Github Pages上不允许运行ruby脚本，
这样很多功能包括分页就都不能做了。为了完成分页的目的，
我在一个库里保存博客的源代码，使用<code>jekyll</code>来生成静态页面，
然后另一个库也就是<code>chouqin.github.io</code>就完全是静态页面，
把它发布到Github Pages上去。Octopress也是这样，
只不过它省去了我的麻烦，要发布到Github Pages，
只要一条<code>rake deploy</code>就够了，非常方便。</p>
  </li>
</ul>

<p>来说一下具体的迁移过程吧。</p>

<h2 id="section">基础博客搭建</h2>

<p>其实完全是照着Octopress的<a href="http://octopress.org/docs/setup/">官方文档</a>一步步安装过来的，
官方博客已经写得很清楚了。Ruby管理使用的是<a href="http://rvm.io">rvm</a>。</p>

<p>出现了一个问题是<code>rake</code>安装的是10.1.0的版本，跟Gemfile对应的不一致，
直接把Gemfile里的那行改为<code>gem 'rake', '~&gt; 10.1.0'</code>。</p>

<h2 id="section-1">修改配置</h2>

<p>首先是按照文档修改了一些<code>_conf.yml</code>配置:</p>

<ul>
  <li>把使用的markdown改为<code>kramdown</code></li>
  <li>启用<code>pygments</code>来进行语法高亮</li>
  <li>Aside Bar只显示最近的Post和Github。</li>
  <li>配置了<code>disqus_short_name</code>。</li>
</ul>

<p>具体的配置可以查看我的<a href="https://github.com/chouqin/chouqin.github.io/tree/source">github</a></p>

<h3 id="mathjax">使用MathJax</h3>

<p>由于使用的是<code>kramdown</code>，它的语法包含数学，为了在页面上展示数学公式，
在<code>source/_includes/head.html</code>上加入以下的内容：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
</pre></td><td class="code"><pre><code class="html"><span class="line"><span class="c">&lt;!-- mathjax config similar to math.stackexchange --&gt;</span>
</span><span class="line">
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/x-mathjax-config&quot;</span><span class="nt">&gt;</span>
</span><span class="line">  <span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">.</span><span class="nx">Config</span><span class="p">({</span>
</span><span class="line">    <span class="nx">tex2jax</span><span class="o">:</span> <span class="p">{</span>
</span><span class="line">      <span class="nx">inlineMath</span><span class="o">:</span> <span class="p">[</span> <span class="p">[</span><span class="s1">&#39;$&#39;</span><span class="p">,</span><span class="s1">&#39;$&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;\\(&quot;</span><span class="p">,</span><span class="s2">&quot;\\)&quot;</span><span class="p">]</span> <span class="p">],</span>
</span><span class="line">      <span class="nx">processEscapes</span><span class="o">:</span> <span class="kc">true</span>
</span><span class="line">    <span class="p">}</span>
</span><span class="line">  <span class="p">});</span>
</span><span class="line"><span class="nt">&lt;/script&gt;</span>
</span><span class="line">
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/x-mathjax-config&quot;</span><span class="nt">&gt;</span>
</span><span class="line">    <span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">.</span><span class="nx">Config</span><span class="p">({</span>
</span><span class="line">      <span class="nx">tex2jax</span><span class="o">:</span> <span class="p">{</span>
</span><span class="line">	<span class="nx">skipTags</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;script&#39;</span><span class="p">,</span> <span class="s1">&#39;noscript&#39;</span><span class="p">,</span> <span class="s1">&#39;style&#39;</span><span class="p">,</span> <span class="s1">&#39;textarea&#39;</span><span class="p">,</span> <span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="s1">&#39;code&#39;</span><span class="p">]</span>
</span><span class="line">      <span class="p">}</span>
</span><span class="line">    <span class="p">});</span>
</span><span class="line"><span class="nt">&lt;/script&gt;</span>
</span><span class="line">
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/x-mathjax-config&quot;</span><span class="nt">&gt;</span>
</span><span class="line">    <span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">.</span><span class="nx">Queue</span><span class="p">(</span><span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
</span><span class="line">	<span class="kd">var</span> <span class="nx">all</span> <span class="o">=</span> <span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">.</span><span class="nx">getAllJax</span><span class="p">(),</span> <span class="nx">i</span><span class="p">;</span>
</span><span class="line">	<span class="k">for</span><span class="p">(</span><span class="nx">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">all</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">	    <span class="nx">all</span><span class="p">[</span><span class="nx">i</span><span class="p">].</span><span class="nx">SourceElement</span><span class="p">().</span><span class="nx">parentNode</span><span class="p">.</span><span class="nx">className</span> <span class="o">+=</span> <span class="s1">&#39; has-jax&#39;</span><span class="p">;</span>
</span><span class="line">	<span class="p">}</span>
</span><span class="line">    <span class="p">});</span>
</span><span class="line"><span class="nt">&lt;/script&gt;</span>
</span><span class="line">
</span><span class="line"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span>
</span><span class="line">   <span class="na">src=</span><span class="s">&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;</span><span class="nt">&gt;</span>
</span><span class="line"><span class="nt">&lt;/script&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="section-2">迁移原来的博文</h2>

<p>原来的博客是基于<code>jekyll</code>的，对于每一篇博客，修改这几个地方即可：</p>

<ul>
  <li>删除掉前面的<code>Included file 'JB/setup' not found in _includes directory</code>。</li>
  <li>在配置上加入<code>comments: true</code>。</li>
</ul>

<h2 id="section-3">发布到七牛</h2>

<p>因为生成的是静态页面，所以也可以发布到七牛来加速访问。
在部署之前，你需要先<a href="https://portal.qiniu.com/signup?code=3l94gjc9mqzwx">注册</a>成为七牛用户，
然后获取<a href="https://portal.qiniu.com/setting/key">AccessKey 和 SecretKey</a>。</p>

<p>然后安装七牛的<a href="http://docs.qiniu.com/tools/v6/qrsync.html">qrsync</a>。</p>

<p>在<code>octopress</code>目录下创建<code>qiniu.conf</code>，写入以下内容:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="json"><span class="line"><span class="p">{</span>
</span><span class="line">    <span class="nt">&quot;access_key&quot;</span><span class="p">:</span> <span class="s2">&quot;Please apply your access key here&quot;</span><span class="p">,</span>
</span><span class="line">    <span class="nt">&quot;secret_key&quot;</span><span class="p">:</span> <span class="s2">&quot;Dont send your secret key to anyone&quot;</span><span class="p">,</span>
</span><span class="line">    <span class="nt">&quot;bucket&quot;</span><span class="p">:</span> <span class="s2">&quot;Bucket name on qiniu resource storage&quot;</span><span class="p">,</span>
</span><span class="line">    <span class="nt">&quot;sync_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;_deploy&quot;</span><span class="p">,</span>
</span><span class="line">    <span class="nt">&quot;async_ops&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
</span><span class="line">    <span class="nt">&quot;debug_level&quot;</span><span class="p">:</span> <span class="mi">1</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>最后执行<code>qrsync qiniu.conf</code>，就能部署到七牛了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MapReduce学习心得]]></title>
    <link href="http://chouqin.github.io/blog/2013/10/16/mapreduce/"/>
    <updated>2013-10-16T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/10/16/mapreduce</id>
    <content type="html"><![CDATA[<h2 id="section">简介</h2>

<p>对于计算机系的同学来说，MapReduce这个词应该并不陌生，
现在是所谓的“大数据时代”，“大数据”这个词被炒得非常热。
何为“大数据”？随着互联网的发展，现在的数据越来越多，
给原先的技术带来了两方面的挑战，一是<strong>存储</strong>，
如何存储这些PB级别的数据，
二是<strong>分析</strong>， 如何对这么大的数据进行分析，
从中提取出有用的信息。</p>

<p>MapReduce就是一个对大数据进行分析的框架。
使用MapReduce，用户只需要定义自己的<code>map</code>函数和<code>reduce</code>函数，
然后MapReduce就能把这些函数分配到不同的机器上去并行的执行，
MapReduce帮你解决好调度，容错，节点交互的问题。
这样，一个没有分布式系统编程经验的人也可以利用MapReduce把自己的程序放到几千台机器上去执行。</p>

<p><code>map</code>和<code>reduce</code>都是来自于函数式编程的概念，<code>map</code>函数接受一条条的纪录作为输入，
然后输出一个个<code>&lt;key, value&gt;</code>对，<code>reduce</code>函数接受<code>&lt;key, values&gt;</code>对，
（其中<code>values</code>是每一个<code>key</code>对应的所有的<code>value</code>)，通过对这些<code>values</code>进行一个“总结”，
得到一个<code>&lt;key, reduce_value&gt;</code>。</p>

<p>比如拿经典的<strong>WordCount</strong>例子来说，对于文本中的每一个单词<code>word</code>，
<code>map</code>都会生成一个<code>&lt;word, 1&gt;</code>对（注意如果一个文本中一个单词出现多次就生成多个这样的对）,
<code>reduce</code>函数就会收到<code>&lt;word, 1,...&gt;</code>这样的输入，它的工作就是把所有的<code>1</code>都加起来，
生成一个<code>&lt;word, sum&gt;</code>。</p>

<p>MapReduce函数基于键值对进行处理，看起来很简单，
那很多的分析任务不仅仅只是简单的Wordcount而已，能够使用这两个函数来实现吗？
幸运的是，很多的大规模数据分析任务都能通过MapReduce来表达，
这也是为什么MapReduce能够作为一个框架被提出的原因，
在最后一个部分中会给出一些更加复杂的使用MapReduce的例子。</p>

<h2 id="section-1">架构</h2>

<p>在大概了解了MapReduce之后，我们来看一下它到底是怎么实现的。
我们首先看一下一个MapReduce任务执行完需要经过那些流程，
然后再看一下在实现MapReduce的时候需要考虑的几个因素。</p>

<h3 id="section-2">基本流程</h3>

<p><img src="http://chouqin.github.io/images/map_reduce_execution.png" alt="" /></p>

<p>我们首先假定把一个任务分成M个<code>map</code>Task和R个<code>reduce</code>task，
如上图,
整个任务的执行过程如下：</p>

<ol>
  <li>
    <p>首先根据<code>map</code>的数量把原来的数据分成M个splits，每一个split对应一个<code>map</code>task。</p>
  </li>
  <li>
    <p>在集群的节点上启动<code>master</code>，M个<code>map</code>task和N个<code>reduce</code>task, 
<code>master</code>把split分配给相应的<code>map</code>task。需要注意的是，
一个集群的节点（又称作一个worker）上可能有多个<code>map</code>task,
也有可能<code>map</code>task和<code>reduce</code>task在同一个worker。</p>
  </li>
  <li>
    <p>每一个<code>map</code>task读取自己的split，根据用户定义的<code>map</code>函数生成<code>&lt;key value&gt;</code>对，
把结果保存在<strong>本地文件</strong>中，
根据<code>key</code>的不一样，结果被写入到R个不同的文件。
这些文件的位置会告知给<code>master</code>，然后<code>master</code>再告知给相应的<code>reduce</code>task。</p>
  </li>
  <li>
    <p>当一个<code>reduce</code>task被告知这些文件的位置时，它通过远程调用读取这些文件的内容，
当和这个<code>reduce</code>task相关的所有文件都被读到之后，它把这些内容按照<code>key</code>进行一个排序，
然后就能保证同一个<code>key</code>的所有<code>values</code>同时被传给<code>reduce</code>。</p>
  </li>
  <li>
    <p><code>reduce</code>task使用用户定义的<code>reduce</code>函数处理上述排序好的数据，
将最终的结果保存到一个<strong>Global File System</strong>（比如GFS），
这是为了保证数据的可靠性。</p>
  </li>
</ol>

<h3 id="section-3">文件的保存</h3>

<p>在上述的过程中，我们看到<code>map</code>task的结果被保存在本地，
而把<code>reduce</code>task的结果保存在具有可靠性保证的文件系统上。
这是因为<code>map</code>task产生的是中间结果，当这些结果被<code>reduce</code>之后，
就可以被扔掉，不需要备份，这样可以节约磁盘空间。
而<code>reduce</code>task产生的是最终结果，需要一定的可靠性保证。</p>

<h3 id="split">split的粒度</h3>

<p>在对一个任务进行划分时，需要考虑split的粒度：</p>

<ul>
  <li>
    <p>如果split太小，M就会很大，
<code>master</code>需要纪录的数据就会很多，
就会消耗很多<code>master</code>的内存。</p>
  </li>
  <li>
    <p>如果split太大，一方面调度不具有灵活性，
因为调度是以split为单位的，一个较大的task无法被分割放到其他空闲的worker上去执行。
另一方面无法利用<code>locality</code>进行调度，
因为<code>map</code>task的输入文件一般保存在分布式文件系统上，
<code>master</code>在调度时尽量把一个split分配到较近的节点上去执行，
如果split太大超过了一个文件block的大小，
这样可能两个block在不同的节点上，甚至跨了不同的机架，
这样无法利用<code>locality</code>了。</p>
  </li>
</ul>

<p>所以，在实际应用中，split的大小为一个block。</p>

<h3 id="section-4">容错</h3>

<p>由于MapReduce被分布到上千台机器上去执行，
错误是不可避免的。
MapReduc需要在节点发生故障时进行处理。</p>

<p>当一个节点发生故障，
在这个节点上的所有的<code>map</code>task都需要重新执行，
因为<code>map</code>task的结果是保存在节点本地的，
节点发生故障之后，这些结果就不可用了。
而成功执行的<code>reduce</code>task就不需要重新执行了，
因为它的结果是保存在分布式文件系统上，
可靠性是可以保证的。</p>

<h2 id="section-5">常见应用</h2>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h3 id="section-6">矩阵向量乘法</h3>

<p>假设有一个<script type="math/tex">m \times n</script>的矩阵M，
它和一个n维列向量v的乘积是一个m维的列向量x，有</p>

<script type="math/tex; mode=display">
x_i = \sum_{j=1}^{n} m_{ij}v_j
</script>

<p>可以根据j，把M按列分成k块，把v也对应分成k块，
每个M块和对应的v块被分给一个<code>map</code>task，
<code>map</code>task生成的结果为<script type="math/tex">(i, m_{ij}v_j)</script>对，
<code>reduce</code>task把每一个i对应的所有<script type="math/tex">m_{ij}v_j</script>加起来。</p>

<h3 id="section-7">关系代数运算</h3>

<p>关系数据库表的Join，Selection，Projection, Union, Intersection, 
Difference，Group And Aggregation等操作都可以使用MapReduce来实现。</p>

<p>值得一提的是，对于Join运算，比如链接关系R(a, b)和关系S(b, c)，
在生成以b为键的键值对时，需要指定来自于哪一个关系，
比如关系R生成的键值对的形式为<code>&lt;b, (R, a)&gt;</code>,
这样<code>reduce</code>时就可以根据这个信息进行组合。</p>

<h3 id="section-8">矩阵乘法</h3>

<p>假设有一个<script type="math/tex">m \times n</script>的矩阵M，
和一个<script type="math/tex">n \times p</script>的矩阵N，
它们的乘积是一个<script type="math/tex">m \times p</script>的矩阵P,
有:</p>

<script type="math/tex; mode=display">
p_{ik} = \sum_{j=1}^{n} m_{ij}n_{jk}
</script>

<p>矩阵M和矩阵N的乘法可以看成是关系M(I, J, V)和关系N(J, K, W)先进行一次Join，
再进行一次Group And Aggregation之后的结果，
因此可以直接通过两次MapReduce进行矩阵的乘法运算。</p>

<p>如果想要一次MapReduce就得到结果，可以在<code>map</code>时以(i, k)为键生成键值对，
同样的，需要指明来自于矩阵M还是矩阵N，因此，相应的键值对的格式分别为
<script type="math/tex">((i, k), (M, j, m_{ij}))</script>(对于矩阵M)，<script type="math/tex">((i, k), (N, j, n_{jk}))</script>(对于矩阵N)。
<code>reduce</code>时进行相应的组合。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GFS学习心得]]></title>
    <link href="http://chouqin.github.io/blog/2013/10/10/gfs/"/>
    <updated>2013-10-10T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/10/10/gfs</id>
    <content type="html"><![CDATA[<p>又好久没写博客了，这几个月来零零散散做了一些事情，
学到的东西很杂，一直都没有形成系统，也没有在某些方面有很深的体会。
有些东西刚刚深入进去看了一点（比如<a href="redis.io">redis</a>，看过一些代码，下次一定要写点心得出来），
还没来得及总结，就被一些其他的事情把时间挤走了。而现在，
时间相对来说比较空闲，可以认真研究一些技术，学得一些东西了。</p>

<p>这几天一直在看<a href="http://research.google.com/archive/gfs.html">The Google File System</a>这篇论文，
看得很慢，一天才能看几页，有些地方还要反反复复看几遍才能“理解”，
但也确实学得了不少东西，包括一些分布式系统设计的基本思想，
以及如何根据应用的具体场景来做设计决策。
诚然，对于一个这么大的系统，要想弄明白它的全部细节是比较困难的，
能够把它的整个过程捋顺就可以了。本文中，
我把我对这篇论文印象比较深的内容用我自己的理解讲出来，
希望能够给对GFS感兴趣的同学一点帮助。</p>

<h2 id="section">特殊的应用场景</h2>

<p>GFS作为一个分布式的文件系统，
除了要满足一般的文件系统的需求之外，
还根据一些特殊的应用场景（原文反复提到的<code>application workloads and technological environment</code>），
来完成整个系统的设计。</p>

<h3 id="section-1">分布式文件系统的要求</h3>

<p>一般的分布式文件系统需要满足以下四个要求：</p>

<ul>
  <li>Performance：高性能，较低的响应时间，较高的吞吐量</li>
  <li>Scalability: 易于扩展，可以简单地通过增加机器来增大容量</li>
  <li>Reliability: 可靠性，系统尽量不出错误</li>
  <li>Availability: 可用性，系统尽量保持可用</li>
</ul>

<p>（注：关于reliability和availability的区别，
请参考<a href="http://unfolding-mirror.blogspot.com/2009/06/reliability-vs-availability.html">这篇</a>）</p>

<h3 id="gfs">GFS基于的假设</h3>

<p>基于对实际应用场景的研究，GFS对它的使用场景做出了如下假设：</p>

<ol>
  <li>
    <p>GFS运行在成千上万台便宜的机器上，这意味着节点的故障会经常发生。
必须有一定的容错的机制来应对这些故障。</p>
  </li>
  <li>
    <p>系统要存储的文件通常都比较大，每个文件大约100MB或者更大，
GB级别的文件也很常见。必须能够有效地处理这样的大文件，
基于这样的大文件进行系统优化。</p>
  </li>
  <li>
    <p>workloads的读操作主要有两种：</p>

    <ul>
      <li>
        <p>大规模的流式读取，通常一次读取数百KB的数据,
 更常见的是一次读取1MB甚至更多的数据。
 来自同一个client的连续操作通常是读取同一个文件中连续的一个区域。</p>
      </li>
      <li>
        <p>小规模的随机读取，通常是在文件某个随机的位置读取
 几个KB数据。
 对于性能敏感的应用通常把一批随机读任务进行排序然后按照顺序批量读取，
 这样能够避免在通过一个文件来回移动位置。（后面我们将看到，
 这样能够减少获取metadata的次数，也就减少了和master的交互）</p>
      </li>
    </ul>
  </li>
  <li>
    <p>workloads的写操作主要由大规模的，顺序的append操作构成。
一个文件一旦写好之后，就很少进行改动。因此随机的写操作是很少的，
所以GFS主要针对于append进行优化。</p>
  </li>
  <li>
    <p>系统必须有合理的机制来处理多个client并发写同一个文件的情况。
文件经常被用于生产者-消费者队列，需要高效地处理多个client的竞争。
正是基于这种特殊的应用场景，GFS实现了一个无锁并发append。</p>
  </li>
  <li>
    <p>利用高带宽比低延迟更加重要。基于这个假设，
可以把读写的任务分布到各个节点，
尽量保证每个节点的负载均衡，
尽管这样会造成一些请求的延迟。</p>
  </li>
</ol>

<!--more-->

<h2 id="section-2">架构</h2>

<p>下面我们来具体看一下GFS的整个架构。</p>

<p><img src="http://chouqin.github.io/images/gfs-arch.png" alt="" /></p>

<p>可以看到GFS由三个不同的部分组成，分别是<code>master</code>，<code>client</code>, <code>chunkserver</code>。
<code>master</code>负责管理整个系统（包括管理metadata，垃圾回收等），一个系统只有一个<code>master</code>。
<code>chunkserver</code>负责保存数据，一个系统有多个<code>chunkserver</code>。
<code>client</code>负责接受应用程序的请求，通过请求<code>master</code>和<code>chunkserver</code>来完成读写等操作。
由于系统只有一个<code>master</code>，<code>client</code>对<code>master</code>请求只涉及metadata，
数据的交互直接与<code>chunkserver</code>进行，这样减小了<code>master</code>的压力。</p>

<p>一个文件由多个chunk组成，一个chunk会在多个<code>chunkserver</code>上存在多个replica。
对于新建文件，目录等操作，只是更改了metadata，
只需要和<code>master</code>交互就可以了。注意，与linux的文件系统不同，
目录不再以一个inode的形式保存，也就是它不会作为data被保存在<code>chunkserver</code>。
如果要读写文件的文件的内容，就需要<code>chunkserver</code>的参与，
<code>client</code>根据需要操作文件的偏移量转化为相应的<code>chunk index</code>，
向<code>master</code>发出请求，<code>master</code>根据文件名和<code>chunk index</code>，得到一个全局的<code>chunk handle</code>，
一个chunk由唯一的一个<code>chunk handle</code>所标识，
<code>master</code>返回这个<code>chunk handle</code>以及拥有这个chunk的<code>chunkserver</code>的位置。
（不止一个，一个chunk有多个replica，分布在不同的<code>chunkserver</code>。
必要的时候，<code>master</code>可能会新建chunk，
并在<code>chunkserver</code>准备好了这个chunk的replica之后，才返回）
<code>client</code>拿到<code>chunk handle</code>和<code>chunkserver</code>列表之后，
先把这个信息用文件名和<code>chunk index</code>作为key缓存起来，
然后对相应的<code>chunkserver</code>发出数据的读写请求。
这只是一个大概的流程，对于具体的操作过程，下面会做分析。</p>

<h3 id="chunk">Chunk大小</h3>

<p>Chunk的大小是一个值得考虑的问题。在GFS中，chunk的大小是64MB。
这比普通文件系统的block大小要大很多。
在<code>chunkserver</code>上，一个chunk的replica保存成一个文件，
这样，它只占用它所需要的空间，防止空间的浪费。</p>

<p>Chunk拥有较大的大小由如下几个好处:</p>

<ul>
  <li>它减少了<code>client</code>和<code>master</code>交互的次数。</li>
  <li>减少了网络的开销，由于一个客户端可能对同一个chunk进行操作，
这样可以与<code>chunkserver</code>维护一个长TCP连接。</li>
  <li>chunk数目少了，metadata的大小也就小了，这样节省了<code>master</code>的内存。</li>
</ul>

<p>大的chunk size也会带来一个问题，一个小文件可能就只占用一个chunk，
那么如果多个<code>client</code>同时操作这个文件的话，就会变成操作同一个chunk，
保存这个chunk的<code>chunkserver</code>就会称为一个hotspot。
这样的问题对于小的chunk并不存在，因为如果是小的chunk的话，
一个文件拥有多个chunk，操作同一个文件被分布到多个<code>chunkserver</code>.
虽然在实践中，可以通过错开应用的启动的时间来减小同时操作一个文件的可能性。</p>

<h3 id="metadata">Metadata</h3>

<p>GFS的<code>master</code>保存三种metadata：</p>

<ol>
  <li>文件和chunk的namespace</li>
  <li>文件到chunk的映射</li>
  <li>每一个chunk的具体位置</li>
</ol>

<p>metadata保存在内存中，可以很快地获取。
前面两种metadata会通过operation log来持久化。
第3种信息不用持久化，因为在<code>master</code>启动时，
它会问<code>chunkserver</code>要chunk的位置信息。
而且chunk的位置也会不断的变化，比如新的<code>chunkserver</code>加入。
这些新的位置信息会通过日常的<code>HeartBeat</code>消息由<code>chunkserver</code>传给<code>master</code>。</p>

<p>将metadata保存在内存中能够保证在<code>master</code>的日常处理中很快的获取metadata，
为了保证系统的正常运行，<code>master</code>必须定时地做一些维护工作，比如清除被删除的chunk，
转移或备份chunk等，这些操作都需要获取metadata。
metadata保存在内存中有一个不好的地方就是能保存的metadata受限于<code>master</code>的内存，
不过足够大的chunk size和使用前缀压缩，能够保证metadata占用很少的空间。</p>

<p>对metadata进行修改时，使用锁来控制并发。需要注意的是，对于目录，
获取锁的方式和linux的文件系统有点不太一样。在目录下新建文件，
只获取对这个目录的读锁，而对目录进行snapshot，却对这个目录获取一个写锁。
同时，如果涉及到某个文件，那么要获取所有它的所有上层目录的读锁。
这样的锁有一个好的地方是可以在通过一个目录下同时新建两个文件而不会冲突，
因为它们都是获得对这个目录的读锁。</p>

<h3 id="operation-log">Operation Log</h3>

<p>Operation log用于持久化存储前两种metadata，这样<code>master</code>启动时，
能够根据operation log恢复metadata。同时，可以通过operation log知道metadata修改的顺序，
对于重现并发操作非常有帮助。因此，必须可靠地存储operation log，
只有当operation log已经存储好之后才向<code>client</code>返回。
而且，operation log不仅仅只保存在<code>master</code>的本地，而且在远程的机器上有备份，
这样，即使<code>master</code>出现故障，也可以使用其他的机器做为<code>master</code>。</p>

<p>从operation log恢复状态是一个比较耗时的过程，因此，使用checkpoint来减小operation log的大小。
每次恢复时，从checkpoint开始恢复，只处理checkpoint只有的operation log。
在做checkpoint时，新开一个线程进行checkpoint，原来的线程继续处理metadata的修改请求，
此时把operation log保存在另外一个文件里。</p>

<h3 id="section-3">一致性模型</h3>

<p>关于一致性，先看几个定义，对于一个file region，存在以下几个状态：</p>

<ul>
  <li>consistent。如果任何replica, 包含的都是同样的data。</li>
  <li>defined。defined一定是consistent，而且能够看到一次修改造成的结果。</li>
  <li>undefined。undefined一定是consistent，是多个修改混合在一块。举个例子，
修改a想给文件添加A1,A2，修改b想给文件添加B1,B2，如果最后的结果是A1,A2,B1,B2，
那么就是defined，如果是A1,B1,A2,B2，就是undefined。</li>
  <li>inconsitent。对于不同的replica，包含的是不同的data。</li>
</ul>

<p>在GFS中，不同的修改可能会出现不同的状态。对于文件的append操作（是GFS中的主要写操作），
通过放松一定的一致性，更好地支持并发，在下面的具体操作时再讲述具体的过程。</p>

<h3 id="lease">Lease机制</h3>

<p><code>master</code>通过lease机制把控制权交给<code>chunkserver</code>，当写一个chunk时，
<code>master</code>指定一个包含这个chunk的replica的<code>chunkserver</code>作为<code>primary replica</code>，
由它来控制对这个chunk的写操作。一个lease的过期时间是60秒，如果写操作没有完成，
<code>primary replica</code>可以延长这个lease。<code>primary replica</code>通过一个序列号控制对这个chunk的写的顺序，
这样能够保证所有的replica都是按同样的顺序执行同样的操作，也就保证了一致性。</p>

<h3 id="section-4">版本号</h3>

<p>对于每一个chunk的修改，chunk都会赋予一个新的版本号。
这样，如果有的replica没有被正常的修改（比如修改的时候当前的<code>chunkserver</code>挂了）,
那么这个replica就被<code>stale replica</code>，当<code>client</code>请求一个chuck时，<code>stale replica</code>会被<code>master</code>忽略，
在<code>master</code>的定时管理过程中，会把<code>stale replica</code>删除。</p>

<h3 id="section-5">负载均衡</h3>

<p>为了尽量保证所有<code>chunkserver</code>都承受差不多的负载，
<code>master</code>通过以下机制来完成：</p>

<ul>
  <li>首先，在新建一个chunk或者是复制一个chunk的replica时，
尽量保证负载均衡。</li>
  <li>当一个chunk的replica数量低于某个值时，尝试给这个chuck复制replica</li>
  <li>扫描整个系统的分布情况，如果不够平衡，则通过移动一些replica来达到负责均衡的目的。</li>
</ul>

<p>注意，<code>master</code>不仅考虑了<code>chunkserver</code>的负载均衡，也考虑了机架的负载均衡。</p>

<h2 id="section-6">基本操作</h2>

<h3 id="read">Read</h3>

<p>Read操作其实已经在上面的Figure 1中描述得很明白了，有如下几个过程：</p>

<ol>
  <li>
    <p><code>client</code>根据chunk size的大小，把<code>(filename,byte offset)</code>转化为<code>(filename,chunk index)</code>,
发送<code>(filename,chunk index)</code>给<code>master</code></p>
  </li>
  <li>
    <p><code>master</code> 返回<code>(chunk handle,所有正常replica的位置)</code>, 
<code>client</code>以<code>(filename,chunk index)</code>作为key缓存这个信息</p>
  </li>
  <li>
    <p><code>client</code>发<code>(chunk handle,byte range)</code>给其中一个<code>chunkserver</code>，通常是最近的一个。</p>
  </li>
  <li>
    <p><code>chunkserver</code>返回chunk data</p>
  </li>
</ol>

<h3 id="overwrite">Overwrite</h3>

<p>直接假设<code>client</code>已经知道了要写的chunk，如Figure 2，具体过程如下:</p>

<p><img src="http://chouqin.github.io/images/gfs-write.png" alt="" /></p>

<ol>
  <li><code>client</code>向<code>master</code>询问拥有这个chunk的lease的<code>primary replica</code>，如果当前没有<code>primary replica</code>，
<code>master</code>把lease给其中的replica</li>
  <li><code>master</code>把<code>primary replica</code>的位置和其他的拥有这个chunk的replica的<code>chunkserver</code>（<code>secondary replica</code>）的位置返回，
<code>client</code>缓存这个信息。</li>
  <li><code>client</code>把数据以流水线的方式发送到所有的replica，流水线是一种最高效利用的带宽的方法，
每一个replica把数据用LRU buffer保存起来，并向<code>client</code>发送接受到的信息。</li>
  <li><code>client</code>向<code>primary replica</code>发送write请求，<code>primary replica</code>根据请求的顺序赋予一个序列号</li>
  <li><code>primary replica</code>根据序列号修改replica和请求其他的<code>secondary replica</code>修改replica，
这个统一的序列号保证了所有的replica都是按照统一的顺序来执行修改操作。</li>
  <li>当所有的<code>secondary replica</code>修改完成之后，返回修改完成的信号给<code>primary replica</code></li>
  <li><code>primary replica</code>向<code>client</code>返回修改完成的信号，如果有任何的<code>secondary replica</code>修改失败，
信息也会被发给<code>client</code>，<code>client</code>然后重新尝试修改，重新执行步骤3-7。</li>
</ol>

<p>如果一个修改很大或者到了chuck的边界，那么client会把它分成两个写操作，
这样就有可能发生在两个写操作之间有其他的写操作，所以这时会出现undefined的情况。</p>

<h3 id="record-append">Record Append</h3>

<p>Record Append的过程相对于Overwrite的不同在于它的错误处理不同，
当写操作没有成功时，<code>client</code>会尝试再次操作，由于它不知道offset，
所以只能再次append，这就会导致在一些replica有重复的记录，
而且不同的replica拥有不同的数据。</p>

<p>为了应对这种情况的发生，应用程序必须通过一定的校验手段来确保数据的正确性，
如果对于生产者-消费者队列，消费者可以通过唯一的id过滤掉重复的记录。</p>

<h3 id="snapshot">Snapshot</h3>

<p>Snapshot是对文件或者一个目录的“快照”操作，快速地复制一个文件或者目录。
GFS使用<em>Copy-on-Write</em>实现snapshot，首先<code>master</code>revoke所有相关chunk的lease，
这样所有的修改文件的操作都需要和<code>master</code>联系，
然后复制相关的metadata，复制的文件跟原来的文件指向同样的chunck，
但是chuck的reference count大于1。</p>

<p>当有<code>client</code>需要写某个相关的chunck C时，<code>master</code>会发现它的reference count大于1，
<code>master</code>推迟回复给<code>client</code>，先新建一个<code>chunk handle</code>C’，
然后让所有拥有C的replica的<code>chunkserver</code>在本地新建一个同样的C‘的replica，
然后赋予C’的一个replica一个lease，把C’返回给<code>client</code>用于修改。</p>

<h3 id="delete">Delete</h3>

<p>当<code>client</code>请求删除文件时，GFS并不立即回收这个文件的空间。
也就是说，文件相关的metadata还在，
文件相关的chunk也没有从<code>chunkserver</code>上删除。
GFS只是简单的把文件删除的operation log记下，
然后把文件重新命名为一个hidden name， 里面包含了它的删除时间。
在<code>master</code>的日常维护工作时，
它会把删除时间删除时间超过3天的文件从metadata中删除，
同时删除相应chunk的metadata，
这样这些chunk就变成了orphan chunk，
它们会在<code>chunkserver</code>和<code>master</code>进行<code>Heartbeat</code>交互时从<code>chunkserver</code>删除。</p>

<p>这样推迟删除（原文叫垃圾回收）的好处有：</p>

<ul>
  <li>对于分布式系统而言，要确保一个动作正确执行是很难的，
所以如果当场要删除一个chunk的所有replica需要复杂的验错，重试。
如果采用这种推迟删除的方法，只要metadata被正确的处理，最后的replica就一定会被删除，
非常简单</li>
  <li>把这些删除操作放在<code>master</code>的日常处理中，可以使用批处理这些操作，
平摊下来的开销就小了</li>
  <li>可以防止意外删除的可能，类似于回收站</li>
</ul>

<p>这样推迟删除的不好在于浪费空间，如果空间吃紧的话，<code>client</code>可以强制删除，
或者指定某些目录下面的文件直接删除。</p>

<h2 id="section-7">后记</h2>

<p>GFS，MapReduce，BigTable并称为Google的“三架马车”，
既然看了GFS，怎么能不看另外两篇？
欲知Mapreduce，BigTable到底是怎么一回事，
请静候我接下来的博文。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用markdown和reStructuredText生成文档]]></title>
    <link href="http://chouqin.github.io/blog/2013/04/20/markup-lang/"/>
    <updated>2013-04-20T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/04/20/markup-lang</id>
    <content type="html"><![CDATA[<h3 id="section">基本介绍</h3>
<p><a href="http://daringfireball.net/projects/markdown/">Markdown</a>和
<a href="http://docutils.sourceforge.net/rst.html">reStructuredText</a>(下面简称rst)
是现在比较流行的<a href="http://en.wikipedia.org/wiki/Lightweight_markup_language">轻量级标注语言</a>，
这些语言拥有比较强大的表现力，可以通过简单的书写代码就可以写出包含代码，图片，数学公式等各种格式的文档。
这样，我们不用把心思花在各种格式的调节，而只需要专注于文档的内容就行了。
我们通过标记语言写成的文本文件能够被转化为html, tex, pdf，epub, word等各种格式，
我们只需要利用标记语言提供的语法把文本文件写好，相应的转换器会为你转换为特定的文档格式。
我的博客其实都是使用markdown一个特定版本<a href="http://kramdown.rubyforge.org/">kramdown</a>写的，
然后转换为html来发布。</p>

<p>学习这些标记语言其实很简单，远远比学习latex简单，把它提供的一些语法都写一遍，比如说怎么写标题，
怎么写列表，怎么插入代码，怎么插入数学符号等等。知道怎么写了之后，
就多练习，写得多了，熟悉之后就会发现，确实能够省去你控制格式的很多烦恼。</p>

<h3 id="pandoc">使用pandoc</h3>

<p>Markdown有很多超集，比如上面提到的kramdown，这些超集在markdown的基础之上有提供了一些功能，
比如说原生的markdown是不支持数学公式的，但kramdown支持，
它可以把你写在两个在源文件中的这样一段markdown代码:</p>

<div class="highlight"><pre><code class="tex"><span class="sb">$$</span><span class="nb"></span>
<span class="nb">O</span><span class="o">(</span><span class="nb">g</span><span class="o">(</span><span class="nb">n</span><span class="o">))</span><span class="nb"> </span><span class="o">=</span><span class="nb"> </span><span class="nv">\{</span><span class="nb">f</span><span class="o">(</span><span class="nb">n</span><span class="o">)</span><span class="nb">: </span><span class="nv">\exists</span><span class="nb"> c,n， </span><span class="nv">\forall</span><span class="nb"> n </span><span class="nv">\geq</span><span class="nb"> n_</span><span class="m">0</span><span class="nb">,  </span><span class="m">0</span><span class="nb"> </span><span class="nv">\leq</span><span class="nb"> f</span><span class="o">(</span><span class="nb">n</span><span class="o">)</span><span class="nb"> </span><span class="nv">\leq</span><span class="nb"> cg</span><span class="o">(</span><span class="nb">n</span><span class="o">)</span><span class="nv">\}</span><span class="nb"></span>
<span class="s">$$</span>
</code></pre></div>

<p>转化为这样一段html:</p>

<div class="highlight"><pre><code class="html"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;math/tex; mode=display&quot;</span><span class="nt">&gt;</span>
    <span class="nx">O</span><span class="p">(</span><span class="nx">g</span><span class="p">(</span><span class="nx">n</span><span class="p">))</span> <span class="o">=</span> <span class="err">\</span><span class="p">{</span><span class="nx">f</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span><span class="o">:</span> <span class="err">\</span><span class="nx">exists</span> <span class="nx">c</span><span class="p">,</span><span class="nx">n</span><span class="err">，</span> <span class="err">\</span><span class="nx">forall</span> <span class="nx">n</span> <span class="err">\</span><span class="nx">geq</span> <span class="nx">n_0</span><span class="p">,</span>  <span class="mi">0</span> <span class="err">\</span><span class="nx">leq</span> <span class="nx">f</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span> <span class="err">\</span><span class="nx">leq</span> <span class="nx">cg</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span><span class="err">\</span><span class="p">}</span>
<span class="nt">&lt;/script&gt;</span>
</code></pre></div>

<p>包含这个的html<strong>如果里面包含<a href="http://www.mathjax.org/">MathJax</a>这个js库</strong>的话，
MathJax就会把上述的一段html转换为如下的数学公式呈现给你。</p>

<script type="math/tex; mode=display">
O(g(n)) = \{f(n): \exists c,n， \forall n \geq n_0,  0 \leq f(n) \leq cg(n)\}
</script>

<!--more-->

<p>如果你使用了kramdown去处理一个包含数学公式的markdown，却发现没有转化为数学公式，
那么极有可能是没有把MathJax的库包含到这个markdown中，需要通过下面这一行代码引用:</p>

<div class="highlight"><pre><code class="html"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">&quot;text/javascript&quot;</span> <span class="na">src=</span><span class="s">&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;</span><span class="nt">&gt;&lt;/script&gt;</span>
</code></pre></div>

<p>下面我介绍一个转换模板语言的神器——<a href="http://johnmacfarlane.net/pandoc/">Pandoc</a>，
它能够在各种格式的文本之间进行转换，而且支持的格式非常多。
我觉得使用pandoc比较适用的场景是你要写一个几页的文档，这个文档里包含了代码，数学公式等。
在这种情况下，你先写成一个markdown的文本文件，然后利用pandoc转换成需要的格式(pdf, html等)。
而如果写比较大型的文档，或者是写书，我觉得待会我要介绍的Sphinx可能更加合适。
当然，也有很多人使用markdown来写书。</p>

<p>使用这些标记语言，包括我下面提到的rst, 转换为pdf，
最大的不好就是如果里面包含了中文，就需要一些比较麻烦的处理。
因为这些标记语言在转换为pdf时，都是先转换为latex，而latex对中文的支持又不是那么的好。
对于pandoc，如果需要转换为中文的话，需要另外提供一个模板，
这个模板引入了一些中文需要的包，还声明了一些中文的字体。
需要注意两点：</p>

<ol>
  <li>模板里面的声明的字体，一定要是系统已经安装好的字体。
可以通过<code>fc-list :lang=zh</code>查看已经安装的中文字体。</li>
  <li>使用<code>xelatex</code>作为latex引擎。</li>
</ol>

<p>我<a href="https://gist.github.com/chouqin/5412396">这里</a>有一个我自己写的一个用于转化简单pdf的模板。
记得修改成你已经安装好的字体。这样就能通过下面的命令生成pdf：</p>

<pre><code>pandoc -o solution.pdf solution.md --latex-engine=xelatex\
--template=mytemplate.tex
</code></pre>

<h3 id="sphinx">使用Sphinx来制作文档</h3>

<p><a href="http://sphinx-doc.org/">Sphinx</a>是一个很强大的用于制作文档的工具，
几乎所有的Python文档都是用Sphinx这个工具生成的，
在Python代码里面的注释能够很方便的转换为相应的API文档。
但是它并不仅仅局限于Python，它现在也能够支持C/C++，
而且在朝着更多的语言发展。除去和语言相关的成分，
它本身就十分适合写文档。</p>

<p>Sphinx使用rst作为它的标记语言，而且扩充了一些rst的模块，
用于更方便的书写文档，比如说<code>toctree</code>。
而且它还有很多的html主题可以使用，能够让你生成的html比较美观。</p>

<p>很多人拿Sphinx用来写书，同样的，如果要生成pdf，还是会面临中文问题，
好在还是有方法可以解决一些比较简单的问题，
在<a href="http://hyry.dip.jp:8000/pydoc/pydoc_write_tools.html">这个文档</a>中,
作者比较详细地介绍了一些它在写这本书时遇到的一些问题，
虽然还有些许问题没有解决，但已经能解决大部分的问题了,
从作者生成书籍的质量可以看出。</p>

<p>我其实就是打算用Sphinx来记录一些学习的笔记，
暂时还没有出书的打算，因此针对于我的需求，
我使用这两个步骤达到生成pdf的目的:</p>

<ol>
  <li>在conf.py中，设置<code>latex_elements.preamble</code>：</li>
</ol>

<div class="highlight"><pre><code class="python"><span class="s">&#39;preamble&#39;</span> <span class="p">:</span> <span class="s">r&quot;&quot;&quot;</span>
<span class="s">    \usepackage{float}</span>
<span class="s">    \usepackage{xeCJK}</span>
<span class="s">    \usepackage{indentfirst}</span>
<span class="s">    \setlength{\parindent}{2em}</span>
<span class="s">    \textwidth 6.5in</span>
<span class="s">    \oddsidemargin -0.2in</span>
<span class="s">    \evensidemargin -0.2in</span>
<span class="s">    \usepackage{ccaption}</span>
<span class="s">    \usepackage{fontspec,xunicode,xltxtra}</span>
<span class="s">    \setmonofont[Mapping={}]{Source Code Pro}</span>
<span class="s">    \setCJKmainfont[ItalicFont={Adobe Kaiti Std R}, BoldFont={Adobe Heiti Std}]{Adobe Song Std}</span>
<span class="s">    \setCJKmonofont[BoldFont={WenQuanYi Zen Hei Mono}]{Adobe Fangsong Std}</span>
<span class="s">    \setCJKsansfont[ItalicFont={Adobe Kaiti Std R},BoldFont={Adobe Heiti Std}]{Adobe Song Std}</span>
<span class="s">    \XeTeXlinebreaklocale &quot;zh&quot;</span>
<span class="s">    \XeTeXlinebreakskip = 0pt plus 1pt</span>
<span class="s">    \renewcommand{\baselinestretch}{1.3}</span>
<span class="s">    \captiontitlefont{\small\sffamily}</span>
<span class="s">    \captiondelim{ - }</span>
<span class="s">    \renewcommand\today{\number\year年\number\month月\number\day日}</span>
<span class="s">    \makeatletter</span>
<span class="s">    \renewcommand*\l@subsection{\@dottedtocline{2}{2.0em}{4.0em}}</span>
<span class="s">    \renewcommand*\l@subsubsection{\@dottedtocline{3}{3em}{5em}}</span>
<span class="s">    \makeatother</span>
<span class="s">    \titleformat{\chapter}[display]</span>
<span class="s">    {\bfseries\Huge}</span>
<span class="s">    {\filleft \Huge 第 \hspace{2 mm} \thechapter \hspace{4 mm} 章}</span>
<span class="s">    {4ex}</span>
<span class="s">    {\titlerule</span>
<span class="s">    \vspace{2ex}%</span>
<span class="s">    \filright}</span>
<span class="s">    [\vspace{2ex}%</span>
<span class="s">    \titlerule]</span>
<span class="s">    %\definecolor{VerbatimBorderColor}{rgb}{0.2,0.2,0.2}</span>
<span class="s">    \definecolor{VerbatimColor}{rgb}{0.95,0.95,0.95}</span>
<span class="s">&quot;&quot;&quot;</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">&quot;utf-8&quot;</span><span class="p">)</span>
</code></pre></div>

<ol>
  <li>在index.rst的开始加上:</li>
</ol>

<div class="highlight"><pre><code class="rst"><span class="p">..</span> <span class="ow">raw</span><span class="p">::</span> latex

    \renewcommand\partname{部分}
    \renewcommand{\chaptermark}[1]{\markboth{第 \thechapter\ 章 \hspace{4mm} #1}{}}
    \fancyhead[LE,RO]{学习笔记}
    \renewcommand{\figurename}{\textsc{图}}
    \renewcommand\contentsname{目 录}
</code></pre></div>

<p>这样就能生成看上去还比较不错的pdf了。
注意不能直接通过<code>make latexpdf</code>去生成pdf，
而是需要先通过<code>make latex</code> 生成tex文件，
再使用<code>xelatex</code>去编译tex文件生成pdf.</p>

<h3 id="section-1">总结</h3>
<p>我在这边博客中主要总结了一些编译中文pdf的经验，
至于这些标记语言的语法，应该不难，
多写写，就会熟练的，我就不在这赘述了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[毕业论文点滴]]></title>
    <link href="http://chouqin.github.io/blog/2013/04/04/bachelor-thesis/"/>
    <updated>2013-04-04T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/04/04/bachelor-thesis</id>
    <content type="html"><![CDATA[<p>已经好久没写博客了，因为寒假一个多月都没看书，
而一回到学校，又要忙着毕业论文的事，所以也无暇顾及这个。
大部分牛人的博客，都是记载着自己正在研究的方面，
在博客中也是向读者传达着一些知识，我们总是可以从其中学到某种东西。
而我，要达到这样的程度要有很长的一段路需要走，
由于技术水平较低，现在的博客记录的仍然还是自己在<strong>学习</strong>过程中的一些心得和体会，
很大程度上是描述自己的坎坷经历，希望能给某些人一些借鉴，少走一些弯路。</p>

<p>好了，言归正传，这一个月，都在忙着做毕业设计，
包括看论文，写代码，找数据，做实验。一个月的时间，
就完成了这么一件事，效率确实不算高，
主要原因在于对于搞科研还是新手，
很多情况下都是在尝试了各种可能之后才找到方法，
有时一个人的蛮干还不如直接通过其他方式获得出路。
哎，科研就是要耐得住寂寞，不停地调参数，不停地跑数据，
把各种可能性都尝试一遍，之后才有好的结果。</p>

<p>先简单介绍一下我这个论文的要求，论文的题目叫
<code>信息缺失情况下的社区挖掘</code>，其实就是一个聚类算法，
根据节点的某些属性和节点之间的边的关系，把图中的比较接近的节点聚到一起，
形成一个社区。而信息缺失，是指节点中的某些边的关系并不知道，
在这样的情况下进行聚类。采用的办法是首先利用节点之间的属性和边的关系，
通过机器学习方法获取所有节点之间的距离，然后再根据这个距离对节点进行聚类。
下面我来说一下整个的过程。</p>

<p>首先是准备数据。一开始准备爬微博的数据，
所以就去网上搜各种微博的爬虫，
然后终于找到了这个<a href="https://bitbucket.org/chineking/weibocrawler">一个简单的分布式新浪微博爬虫</a>，
在这个基础上进行了一点小修改，弄了一个简单的单节点爬虫。
这个爬虫可以抓取用户的微博，用户的个人资料以及用户之间的关注关系。
然后，又使用<a href="http://ictclas.nlpir.org/">NLPIR</a>对微博进行分词，
提取出关键字作为用户的属性，同时以用户之间的关注关系作为边，这样就开始实验。
可是，不知道是实验室的网络不稳定还是新浪微博的限制，这个爬虫很难稳定地抓取微博的数据，
最后实在没办法，学长建议我去网上直接找别人爬取到的数据集。
于是，我先后使用了Google+, Facebook, 
Twitter(这三个数据集都是在<a href="http://snap.stanford.edu/data/">Stanford Large Network Dataset Collection</a>上找到的),
和Flixter数据集做实验。其中使用Flixter数据集做出来的结果也还可以，可是师兄说一定要有<strong>Ground Truth</strong>用于验证，
所以我又只好去找其他的数据集，
最后终于<a href="http://dmml.asu.edu/users/xufei/datasets.html">在这</a>找到了可以用于实验的数据集。</p>

<p>然后是实现代码去做实验。这个代码其实两部分，第一部分要利用机器学习去学习一个距离，
第二部分是基于距离进行聚类。为了学习距离，需要求解一个最优化函数，
而这里面涉及的数学的公式好复杂，实现起来也非常困难，
找到了一份和这个论文比较相似的论文的源代码，却发现里面错误好多，有些地方也不知道从哪里开始改。
大概修改了一下就把这个距离拿到第二步去聚类，发现结果非常差，
然后也不知道是第一步的问题还是第二步的问题，但是我就只会改第二步的代码:P。
终于在第二步实在找不出什么错误然后第一步的结果又不好之后，我去问老师，
老师让我使用谱聚类算法来验证距离是不是正确的，
因为谱聚类算法也是基于距离的聚类算法，如果谱聚类算法得不到正确的结果，那就是距离的问题了。
多好的主意啊，我当时怎么就没想到呢，因为我当时还没听说过谱聚类算法。
于是我就拿谱聚类算法去验证，果然是距离没学对，而除了代码没写对之外，
有一个重要的步骤没有做，<strong>对Feature做Normalize</strong>，
这个步骤对于使用节点的属性来说非常重要，它保证了所有属性的作用是均等的。
而后，我又在<a href="http://www.cs.cmu.edu/~liuy/distlearn.htm">这里</a>找到了一些其他的学习距离的算法，
我使用了其中的DCA算法来作为我的第一步，相当靠谱。
通过谱聚类算法验证之后，我发现我的第二步算法就几乎没有什么问题了，
跑出的结果也比较让人满意。</p>

<p>大概就是这么一个比较纠结的过程，总结出一些经验吧:</p>

<pre><code>&gt;&gt;&gt;import this
</code></pre>

<ol>
  <li>
    <p>写代码还是要多检查，一个bug除了导致几个小时的结果无效，还要浪费更多的时间去找到它。</p>
  </li>
  <li>
    <p>在一个步骤保证正确之前，不要急于开展下一步，这样只会增加更多的复杂性。</p>
  </li>
  <li>
    <p>沉下心来研究论文，尽量采用和别人一样的方法，得到的结果总是好些，虽然不知道为什么好。</p>
  </li>
  <li>
    <p>不要畏惧实验和失败，说不定下一次就是成功的那一次。</p>
  </li>
  <li>
    <p>真爱生命，远离科研。</p>
  </li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[最短路径与最大流]]></title>
    <link href="http://chouqin.github.io/blog/2013/01/06/clrs-24-26/"/>
    <updated>2013-01-06T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/01/06/clrs-24-26</id>
    <content type="html"><![CDATA[<h2 id="section">最短路径</h2>

<p>在最短路径问题中，
希望在一个图中找出从一个节点到另外一个节点的最短路径，
可能要找出从某一个特定节点到其他节点的最短路径，
也可能是找出所有节点对之间的最短路径，
图中边的权重可能为负值，甚至包含负的回路，
因此，在不同的情况下，有不同的算法适合求解问题，
关于求解所有节点之间的最短路径问题已经在动态规划时详细地解释过Floyd算法，
现在就谈谈两个处理单源最短路径的算法, Dijkstra算法和Bellman-Ford算法。</p>

<h3 id="dijkstra">Dijkstra算法</h3>

<p>Dijkstra算法用于求解所有边的权重为非负值时的单源最短路径问题，
它与Prim算法很相似，利用一个集合S保存已经求出最短路径的节点集合，
开始是S只包含源节点s,
每次从V-S中挑选出一个距离S中节点最近的节点u放入S，同时正确地设置u的邻居节点的路径长度，
直到S为V。</p>

<p>对于Dijkstra算法的正确性，只需要递归地证明下面的性质成立：</p>

<pre><code>当节点u被加入到S时，u到s的最短路径已经被正确的设置, 而且u到s的最短路径上的前趋节点w已经被添加进S。
</code></pre>

<ul>
  <li>初始化：一开始时，这个性质显然成立</li>
  <li>保持：假设当u被添加到S时，u到s的最短路径已经被正确的设置，对于u的任何一个邻接节点v，
如果s到v的最短路径是<script type="math/tex"> s \xrightarrow{p} u \xrightarrow{} v </script>，那么s到v的路径能够被正确的设置，
而且从v到s最短路径上的前趋节点u已经被添加进S, 这样当v被添加进S时，上述的性质都是能够保持的。</li>
</ul>

<h3 id="bellman-ford">Bellman-Ford算法</h3>

<p>Bellman-Ford算法用于求解权重可以为负值时的单源最短路径问题，
而且它还可以用于判断图中是否存在s可达的负的回路。
Bellman-Ford的执行过程就是运行|V|-1次更新操作，
每次更新操作遍历每一条边(u, v)更新dist[v]，伪代码如下：</p>

<div class="highlight"><pre><code class="pascal">    <span class="k">procedure</span> <span class="nf">update</span><span class="p">((</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">))</span><span class="o">:</span>
        <span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="p">]</span><span class="o">,</span> <span class="n">dist</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">+</span><span class="n">w</span><span class="p">(</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">k</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="err">|</span><span class="n">V</span><span class="err">|</span><span class="o">-</span><span class="mi">1</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">in</span> <span class="n">E</span><span class="o">:</span>
            <span class="n">update</span><span class="p">((</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">))</span>
</code></pre></div>

<!--more-->

<p>要证明这个算法的正确性，先说明它的两个性质：</p>

<ol>
  <li>如果调用update((u, v))时，dist[u]已经被正确的设置，
那么dist[v]也将会被正确地设置。</li>
  <li>如果dist[v]已经被正确的设置，
调用任意的update((u, v))都不会改变dist[v]的值，
也就是说多次地执行update是安全的。</li>
</ol>

<p>有了这个性质，对于任意节点v, 
通过对v到s的最短路径的长度做一个简单的归纳，
就能够说明当算法结束时，dist[v]能够被正确的设置。</p>

<p>在我看来，Bellman-Ford算法的价值并不在于这个算法本身，
它给出求解一些问题的普遍思路。对于有着相互依赖的k个元素<script type="math/tex"> \{n_1, n_2, ..., n_k\} </script>,
如果它们之间的关系很复杂，比如如果<script type="math/tex"> n_1 </script>和<script type="math/tex"> n_2 </script>之间有关系，那么<script type="math/tex"> n_1 </script>和<script type="math/tex"> n_3 </script>之间可能就会有关系，
而且这种关系可能构成一个循环，如果每次找到了两个元素的关系就去更新其他元素的关系就会陷入一个死循环，
但如果利用Bellman-Ford算法的思想，就能明白对于任意两个元素<script type="math/tex"> n_i </script>和<script type="math/tex"> n_j </script>，它们之间的关系最多隔着k-2个中间元素，
第1次更新的时候可以把没有隔中间元素的两个元素的关系确立好，第2次更新的时候可以把只隔1个元素的两个元素确定好，
依次类推，当k-1次更新的时候，所有元素的关系都能确定好。就不需要一确定两个元素的关系就去考虑要不要更新相关的元素，
思路显得清晰。</p>

<h2 id="section-1">最大流问题</h2>

<p>最大流问题是图论中一类很重要的问题，因为它和线性规划也有着很强的关联，
所以它的应用也十分广泛。在最大流问题中，对于图G，有两个特殊的节点s,t，
它的任何一条边都有一个容量c，对每条边的一个特定赋值称为一个流f，
流必须满足两个性质：</p>

<ol>
  <li>对于任意一条边e，<script type="math/tex"> 0 \leq f_e \leq c_e </script></li>
  <li>对于除了s,t之外的任意节点u, 入流等于出流, 即: <script type="math/tex"> \sum\limits_{(w,u) \in E} f_{wu} = \sum\limits_{(u, z) \in E} f_{uz} </script></li>
</ol>

<p>最大流是想找出一个f，使得<script type="math/tex"> \sum\limits_{s,u \in E} f_{su} </script>最大。</p>

<p>求解最大流的算法非常直观：</p>

<ol>
  <li>从零流量开始</li>
  <li>每次从f的残留网络中选择一条从s到t的路径，在这条路径上增加流，
重复这个过程直到残留网络中不存在从s到t的路径为止</li>
</ol>

<p>要证明这个算法的正确性，需要了解图的(s,t)-割，
以及割的容量，一个图的(s,t)-割把图分成互不交叉的两个组L和R,
使得s在L中，t在R中。该割的容量就是横跨L和R两个集合的所有边的容量之和，
有如下性质成立：</p>

<p>对于任意流f，任意(s,t)-割(L, R), <script type="math/tex"> size(f) \leq capacity(L, R) </script></p>

<p>说明割的容量是任何流的大小的上限。</p>

<p>下面说明最大流算法的正确性。当程序终止时，残留网络<script type="math/tex"> G^f </script>中不存在由s到t的路径，
那么令L为<script type="math/tex"> G^f </script>中s可达的所有节点，R为其他的节点，那么此时size(f) = capacity(L, R)。
这是因为对于任何从L到R的边e, 有</p>

<script type="math/tex; mode=display"> 
f_e = c_e 且 f_{e'} = 0 其中f_{e'}表示从e的反向流量 
</script>

<p>因为这其中任何一个违反都会导致e的终止节点在<script type="math/tex"> G^f </script>中从s可达。所以此时size(f) = capacity(L, R)。
所以对于任意流f’, 都有<script type="math/tex"> size(f') \leq size(f) </script>，意味这f是一个最大流。</p>

<p>关于最大流还有两个很重要的东西：</p>

<ol>
  <li>如果采用BFS在残留网络中寻找从s到t的最短路径，会使得迭代的次数不会超过O(VE)</li>
  <li>最大流可用于二部图的匹配，关键是要证明容量为整数的图中找出的最大流给任意边的赋值都是整数。</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[再见2012，你好2013]]></title>
    <link href="http://chouqin.github.io/blog/2013/01/01/new-2013/"/>
    <updated>2013-01-01T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/01/01/new-2013</id>
    <content type="html"><![CDATA[<p>看着网络上各路牛人的年末总结，也想跟风自己来写一个，
只可惜拖的时间有点长，到现在才开始发表。</p>

<p>2012年对我来说绝对是不一样的一年，求职，面试，外推，实习，
以前对我来说很遥远的事情在这一年真真切切的发生。
有成功，也有失败，有欢笑，也有泪水，有面临抉择时的犹豫不决，
也有选择之后的淡定从容。这些经历，大多是艰辛的，
却没有将我击垮，能让自己觉得人生的充实。世界末日都照样过了，
还有什么挺不过呢？</p>

<p>在学习方面，2012年学习了很多新技术，新的语言，
对于算法，也有了更深入的理解。总的来说，还是广度有余，深度不足。
多多接触一些新的东西当然是有必要的，无论是对于开阔视野还是为了选择一个自己感兴趣的方向，
可是一个人必须要有所专长，在一个方面成为专家，这样才能体现个人的价值，
我在这方面仍然有所欠缺，希望在未来几年能够再某一个方面深入研究下去。
为什么是几年，因为我觉得有所建树，必须经过几年的积累。</p>

<p>在其他方面，相对来说就做得太少了一点，生活显得略微单调了一些。
空闲时间除了打打球，打打dota，似乎就没有干过别的什么事。更让我觉得愧疚的事，
很少看专业方面的其他书，思考的方式也越来越朝着计算机那个非0即1的方向去转了。
现在的情商好像是在下降，在2013年中一定要强迫自己多读书，多读与专业无关的书籍。</p>

<p>今年最好用的工具还是微博，在这上面可以很好地打发时间，
同时可以获取很多很有意思的信息。虽然说能学到的东西很少，
但它确实能很大程度地开阔视野，你能了解到很多你在现实生活中很难碰到的一些人和事。
喜欢微博，喜欢它带给我的快节奏信息。</p>

<p>今年最深的几点感触：</p>

<ol>
  <li>在面临选择时，不要过分地去权衡利弊，在做出选择之后坚定地超前走才是最重要的。</li>
  <li>不要固执地去争论一个观点的正确性，这并不是一个非黑即白的世界</li>
  <li>严于律己，宽以待人</li>
  <li>多看书，多思考，思考和学习一个都不能落下</li>
  <li>珍惜别人给自己的每一条建议</li>
</ol>

<p>2013 To-Do-List:</p>

<ol>
  <li>多看书，多感受生活，开阔自己的胸襟</li>
  <li>学习一门新的编程语言，可能是go或者erlang</li>
  <li>学完完有关数据挖掘的基础知识</li>
  <li>为github上的一个库提交代码</li>
</ol>

<p>祝愿我的亲人和朋友身体健康，考研的同学考上好的学校，
工作的同学工作顺心。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[图的基本算法]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/30/clrs-22-23/"/>
    <updated>2012-12-30T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/30/clrs-22-23</id>
    <content type="html"><![CDATA[<h2 id="section">广度优先遍历</h2>

<p>对于广度优先遍历，在每次遍历时，都试图把同一个级别的所有节点先遍历，
再遍历下一个级别的节点。它的实现方式是通过一个队列保存需要去遍历的节点，
在每次遍历到一个节点时，都把它的邻接节点放入队列（如果这个节点没有被遍历过的话）等待着被遍历，
这样能保证更深层次的节点会遍历在它的任何邻接节点的后面，因为它的邻接节点更先进入队列。</p>

<p>广度优先遍历可以用来求解无权图中的单源最短路径问题，
对于节点s，在它上面执行一次广度优先遍历就能求出各个节点和s相距的节点数，
这也就是它们到达节点s所需的距离。对于广度优先遍历，
算法首先会发现和s距离为k的所有节点，然后再去发现和s距离为k+1的节点。
这其实和Dijkstra算法是采用同样的思想，先找出和s距离更近的节点，
在这基础上再找出更远的节点，因为这样的话当确定好了更远节点的路径时，
就不需要反过来再去修改更近节点的路径，因为通过更远节点的路径肯定没有先前的那条路径好。</p>

<h2 id="section-1">深度优先遍历</h2>

<p>深度优先遍历与广度优先遍历不一样，在遍历到每一个节点时，尽量往更深节点去遍历，
遍历完之后再考虑同一个级别的节点。它的实现方式不需要队列，
直接通过递归函数就可以完成这个步骤。每次遍历到一个节点时，先把当前的节点设为已经遍历过，
然后在它的邻接节点上执行递归遍历的函数（没有遍历过的邻接节点）。如果对整个图进行深度优先遍历，
首先会选定一个节点，然后在它上面执行深度优先遍历，如果遍历到了所有节点就停止，
否则选择另一个没有遍历到的节点重复这个过程直至所有的节点都遍历完。在深度优先搜索的过程中，
会形成一棵棵以挑选出的节点为根的深度优先树组成的深度优先搜索森林。</p>

<p>在深度优先遍历遍历到每一个节点时，可以利用一个计数器记录遍历节点开始时的时间和结束时的时间，
依据这个时间来确定节点遍历的相对顺序。设节点v遍历的开始时间为d[v]，结束时间为f[v]，
那么时间区间[d[v], f[v]]就代表了这个节点处在遍历过程中的时间，更具体的说，
是节点处在递归函数的栈中的时间。因此对于任何节点u, v，
[d[v], f[v]]和[d[u]， f[u]]只能是不相交或者是一个包含另一个。
（通过栈可能更好理解一点）</p>

<p>利用这样的计数器，可以完成对图的很多操作，比如说拓扑排序和有向图的连通性检查。</p>

<!--more-->

<h3 id="section-2">拓扑排序</h3>

<p>拓扑排序是对于有向无环图的节点进行一次排序，使得对于任意的节点u, v，如果u有一条边到v，
那么u一定出现在v的前面。</p>

<p>利用深度优先遍历得到的f值，可以很容易地对节点进行拓扑排序：按f值的大小进行排序，
具有较大f值的节点排在前面。</p>

<p>可以利用f值进行排序是通过如下性质保证的：</p>

<pre><code>如果f[u] &gt; f[v]，那么一定没有从v到u的边。
</code></pre>

<p>要证明这个性质，可以考虑f[u] &gt; f[v]的两种情况：</p>

<ul>
  <li>
    <p>[d[u], f[u]]与[d[v], f[v]]不相交且在其之后，那么此时遍历完v之后，
u还没开始遍历，此时不可能有v到u的边，因为如果有的话那么遍历v完成之前就会遍历u，矛盾。</p>
  </li>
  <li>
    <p>[d[u], f[u]]包含[d[v], f[v]]，那么说明在遍历u结束之前遍历到了v，这样就存在一条从u到v的路径，
如果有v到u的边，就会形成一个环，与无环图矛盾。</p>
  </li>
</ul>

<h3 id="section-3">有向图的强连通分量</h3>

<p>对于处于有向图的同一个强连通分量的任意节点u, v，存在一条路径从u到v，
同时也存在一条路径从v到u。显然任意两个连通分量不能相交，目的是找出有向图中的所有强连通分量，
注意单个节点可以作为一个强连通分量。</p>

<p>利用深度优先遍历，可以确定有向图的所有强连通分量，方法如下：</p>

<ol>
  <li>首先通过一次深度优先遍历确定所有节点的f值</li>
  <li>按f值倒序深度优先遍历原图的反图，在得到的深度优先搜索森林中，
处于同一棵深度优先搜索树中的节点组成一个强连通分量。</li>
</ol>

<p>这个算法的正确性由下面的性质保证：</p>

<pre><code>对于任意节点u,v，u,v处于同一强连通分量当且仅当它们在第2步中处于同一棵深度优先搜索树。
</code></pre>

<p>证明这个性质，不妨设f[u] &gt; f[v]:</p>

<ul>
  <li>左边到右边, 如果u，v处于同一强连通分量，那么在反图中一定存在从u到v的路径，
那么遍历到u时一定会沿着这条路径遍历到v，保证了u，v在同一棵深度优先搜索树中。</li>
  <li>
    <p>右边到左边，如果u, v在同一棵深度优先搜索树中，说明在反图中有一条u到v的路径，
也就是原图有一条从v到u的路径，只需要证明原图有一条从u到v的路径即可。
和证明拓扑排序一样，f[u] &gt; f[v]只有两种情况：</p>

    <ul>
      <li>
        <p>[d[u], f[u]]与[d[v], f[v]]不相交且在其之后，那么此时遍历完v之后，
  u还没开始遍历，由于存在从v到u的路径，那么遍历v完成之前就会遍历u，所以这种情况不可能。</p>
      </li>
      <li>
        <p>[d[u], f[u]]包含[d[v], f[v]]，这种情况是唯一可能的情况，此时存在一条从u到v的路径</p>
      </li>
    </ul>
  </li>
</ul>

<p>因此证明结束。</p>

<h2 id="section-4">最小生成树</h2>

<p>在最小生成树问题中，给定一个无向连通图G = (V, E)，从E中挑出权值和最小的|V| - 1条边，
使得这些节点依旧连通。</p>

<p>有两种算法求解最小生成树问题，而且两种算法都是贪心算法，都满足贪心算法的贪心选择性质。</p>

<h3 id="kruskal">Kruskal算法</h3>

<p>在Kruskal算法中，每次都试图挑选权值最小的一条边，
但要保证添加这条边不会导致存在回路，如果会导致回路，则不考虑这条边。</p>

<p>可以很简单的通过修改最优解的方式证明这个算法的贪心选择性质，从而证明算法的正确性。</p>

<h3 id="prim">Prim算法</h3>

<p>在Prim算法中，利用一个不断增长的集合S，这个集合原来只包含一个元素，
然后每次往集合S中添加一个节点，这个节点是V-S中距离S中任意节点最近的节点，
在把这个节点添加到S的同时，把这个节点和S中与这个节点最近的节点组成的边添加为最小生成树的边。
显然，Prim算法能够保证每次添加一条边时，都不会导致回路。</p>

<p>同样可以很简单的通过修改最优解的方式证明这个算法的贪心选择性质，从而证明算法的正确性。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[贪心算法和B树]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/18/clrs-1618/"/>
    <updated>2012-12-18T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/18/clrs-1618</id>
    <content type="html"><![CDATA[<h2 id="section">贪心算法</h2>
<p>动态规划是一种解决问题的通用方法，
在求解最优化问题的时候，
动态规划能够综合考虑到各种情况然后做出最优的选择。
可是，对于一些特殊的问题，
在从子问题中做出选择时，可以不用考虑所有的子问题，
而只需要考虑一个子问题，
因为选择这个子问题一定可以达到一个最优解，
在这种情况下，就可以采用贪心算法来解决。
贪心算法的好处在于，不需要考虑所有的子问题，
只需要考虑一种情况，这时求解的子问题的数目就减少了，
同时，可以采用一种自顶向下的方法解决问题，
逐步地把问题转化为更小的子问题，直到可以轻易解决。</p>

<h3 id="section-1">从动态规划到贪心</h3>
<p>书上给出了一个这样的例子来说明从动态规划算法转化到贪心算法。</p>

<p>有n个活动组成集合<script type="math/tex"> S = \{a_1, a_2, ..., a_n\} </script>，它们需要占用同一个资源，
这个资源在同一个时间只能被一个活动占用，每一个活动<script type="math/tex"> a_i </script>使用资源的起始时间和结束时间分别为
<script type="math/tex"> s_n, f_n </script>，如果区间<script type="math/tex"> [s_i, f_i) </script>与区间<script type="math/tex"> [s_j, f_j) </script>不重叠，
就称活动<script type="math/tex"> a_i </script>与活动<script type="math/tex"> a_j </script>是兼容的，求S的一个由互相兼容的活动组成的最大子集，
假设活动已经按结束时间排好序。</p>

<p>对于这个问题，可以定义如下子问题<script type="math/tex"> S_{ij} </script>，
表示从S的子集<script type="math/tex"> S_{ij} </script>中得到的最大兼容子集，
其中<script type="math/tex">% &lt;![CDATA[
 S_{ij} = \{ a_k \in S: s_k \geq f_i and f_k < s_j \} %]]&gt;</script>，
也就是说，<script type="math/tex"> S_{ij} </script>是由所有在<script type="math/tex"> a_i </script>结束之后开始，
在<script type="math/tex"> a_j </script>开始之前结束的活动组成的集合。
通过定义这样一个子问题，
就可以很容易地得出如下递推公式，</p>

<script type="math/tex; mode=display">
A_{ij} = A_{ik} \bigcup \{a_k\} \bigcup A_{kj}, 其中A_{ij}表示子问题S_{ij}的解
</script>

<p>从而利用动态规划解决这个问题。</p>

<p>然而，动态规划并不是一个最优的解法，
因为要求解的子问题的个数为<script type="math/tex"> O(n^2) </script>个，
而且求解每个子问题时选择的个数也有<script type="math/tex"> O(n) </script>个，
这就导致了通过动态规划求解问题所需的复杂度为<script type="math/tex"> O(n^3) </script>。</p>

<p>如果采用贪心的算法，每次通过选取<script type="math/tex"> S_{ij} </script>中具有最早结束时间的活动<script type="math/tex"> a_m </script>作为划分元素的话，
那么就可以通过</p>

<script type="math/tex; mode=display">
A_{ij} = A_{im} \bigcup \{a_m\} \bigcup A_{mj}
</script>

<p>得到一个最优的解，而不用考虑其它元素作为划分元素时的子问题。</p>

<!--more-->

<p>定义函数递归函数RECURSIVE-ACTIVITY-SELECTOR(S, f, i, n)求取子问题<script type="math/tex"> S_{i(n+1)} </script>的解，
伪代码如下：</p>

<pre><code>def RECURSIVE-ACTIVITY-SELECTOR(s, f, i, n)
    m := i + 1
    while m &lt;= n and s[m] &lt; f[i]
        do m := m + 1
    if m &lt;= n
        then return {a[m]} union RECURSIVE-ACTIVITY-SELECTOR(s, f, m, n)
        else return EMPTY_SET
</code></pre>

<p>求解原问题就可以通过调用RECURSIVE-ACTIVITY-SELECTOR(s, f, 0, n)来完成。
从代码中可以看出，每个活动都只被检查过一次，如果函数调用的时间可以忽略不计的话(
这个递归地算法可以通过迭代来实现，所以算法本身可以不用考虑这个问题)，
那么整个算法的时间复杂度为<script type="math/tex"> \Theta(n) </script>。相比于动态规划，效率要提高很多。</p>

<h4 id="section-2">关于这个问题的几点解释</h4>

<ol>
  <li>
    <p>关于为什么可以将<script type="math/tex"> a_m </script>选作分界元素需要说明两点：</p>

    <ol>
      <li>
        <p>一定有某一个最大兼容子集包含元素<script type="math/tex"> a_m </script>，也就是说，
 如果要挑选出一些元素组成最大兼容子集，
 那么先把<script type="math/tex"> a_m </script>选中放入这个集合中肯定能导致一个最优解。
 关于这种命题的证明，普遍的方式是假设有一个最优解没有包含这个元素，
 那么把这个元素和某个元素替换后会导致一个不会比原来差的解。
 书上也是采取这样的证明方式。以后在证明最小生成树的贪心算法时也是采取这样的方式。</p>
      </li>
      <li>
        <p>把<script type="math/tex"> a_m </script>放入最大兼容子集后，这个最大兼容子集的其余元素一定是子问题<script type="math/tex"> S_{mj} </script>的一个解。
 这个比较好证明，只需要证明对于任意和<script type="math/tex"> a_m </script>兼容的元素<script type="math/tex"> a_k </script>, 一定有
 <script type="math/tex"> s_k \geq f_m </script>即可。</p>
      </li>
    </ol>

    <p>有了这两点，就能得出：</p>

<script type="math/tex; mode=display">
 A_{ij} = \{a_m\} \bigcup A_{mj} = A_{im} \bigcup \{a_m\} \bigcup A_{mj}, 第二个等式成立是因为A_{im} = \emptyset
 </script>

    <p>也就是将<script type="math/tex"> a_m </script>选作分界元素, 同时可以不需要求解<script type="math/tex"> S_{im} </script>。</p>
  </li>
  <li>
    <p>需要注意的是<script type="math/tex"> S_{ij} \neq \{a_{i+1}, a_{i+2}, ..., a_{j-1} \}</script>，
这个等式只有在<script type="math/tex"> i=0, j=n+1 </script>时成立，
但是从代码中我们可以看到，
在调用RECURSIVE-ACTIVITY-SELECTOR(S, f, i, n)时，
此时可能被添加进最大兼容子集的元素集合是<script type="math/tex"> \{a_{i+1}, a_{i+2}, ..., a_{n} \} </script>,
而不是<script type="math/tex"> S_{i(n+1)} </script>，然而这并不会导致什么问题，因为在选取<script type="math/tex"> a_m </script>时，已经过滤掉了开始时间小于<script type="math/tex"> f_i </script>的元素，
随着迭代次数的加深，那些开始时间小于<script type="math/tex"> f_i </script>的元素也会被过滤掉，因为开始时间小于<script type="math/tex"> f_i </script>也一定会小于<script type="math/tex"> f_m </script>，
在更深的迭代时同样会被过滤。</p>

    <p>采取这样的方式实现代码能够降低时间和空间的复杂度，因为如果每次求解子问题时都需要求出<script type="math/tex"> S_{ij} </script>这个集合的话，
 需要<script type="math/tex"> O(n) </script>的时间来求出，同时也需要一个数组来保存这个子集，显然不如书上的这个实现简单。</p>
  </li>
  <li>
    <p>这个问题如果用动态规划的话可以采用另外一种思路，
令c[i]表示集合<script type="math/tex"> \{a_1, ..., a_i \} </script>中，包含元素<script type="math/tex"> a[i] </script>的最大兼容子集的元素个数，
那么有如下递归公式成立</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

 c[i] = \max \{\max_{j < i}_{s_i > f_j } \{c[j] + 1\}, 1 \}
  %]]&gt;</script>

    <p>利用这个递归公式求解的话，时间复杂度可以降到<script type="math/tex"> O(n^2) </script>。</p>
  </li>
</ol>

<h3 id="section-3">贪心算法的基本条件</h3>
<p>总的来说，贪心算法比动态规划效率要高，实现起来也相对简单一些，
同时也是一般人比较容易想到的算法。但是这并不意味着它比较简单，
因为并不是所有的问题都能够使用贪心法得到解决，
它比动态规划有更多的限制条件，
它必须满足两个基本条件：</p>

<ol>
  <li>
    <p>贪心选择性质：一个全局最优解可以通过局部最有解得到。
这是贪心算法与动态规划的不同之处。
证明贪心选择性质一般用上面提到的修改最优解，
使其包含局部最优解，
然后得到一个不差于最优解的解，就能证明。</p>
  </li>
  <li>
    <p>最优子结构，这和动态规划一样，可以通过”剪切，粘贴”的方法证明。</p>
  </li>
</ol>

<h3 id="section-4">哈夫曼编码</h3>

<p>贪心算法可以用于求解很多问题，
在图算法中的最小生成树算法，
单源最短路径算法等都是利用贪心法解决，
关于这些算法，我在图算法时再详细阐述，
现在说另外一个比较典型的贪心算法的例子。</p>

<p>哈夫曼编码，这个基本是任何算法书都需要提及的使用贪心算法的例子。
有n个不同字符，知道它们的出现的出现次数，
如何设计一个前缀编码使得整个文件的编码最短。利用一个优先级队列，
每次把队列的频率最小的两个元素出队，组成一个新的元素然后入队，直到队列只剩一个元素为止。
这个算法贪心选择性质的证明也比较简单。</p>

<h3 id="section-5">另一种贪心算法</h3>

<p>前面说到的贪心算法都是用于求解最优化问题，
在应用贪心算法的时候，看问题是否具备贪心选择的性质，
如果具备，就通过贪心法求解。
有另外一种问题也可以归入贪心算法的范畴，这样的问题不是求最优解，
而只是需要正确地的解决某一个问题，在这种问题中，没有最优解可言，
只是求出问题的正确的解就可以。在解决问题的过程中，可能会有很多选择，
类似于要不要选择某个元素，要不要把某个变量设成True，
这许多的选择组合起来就会导致解有很多种可能性，
目的就在于从这许多的解中找出满足指定条件的一个解，如果存在的话。
这就类似于走迷宫，有许多的分叉路口，就很多种走法，
从这些走法中找出一个能走到出口的就可以。</p>

<p>对于这些问题，暴力搜索每一种可能性显然不是一种好方法，
动态规划也可以用于解决这样的问题，
在解决一个问题时利用一个子问题是否满足条件来决定当前的问题是否满足条件。
而贪心算法在解决这种问题时采取了一种更加直观的想法: 必须要做某一个选择，
否则就是不满足条件的解。如果问题具有这样的性质，就可以很容易地选出一个解，
因此每次的选择都是唯一的，然后再看这个选择是否满足条件即可。如果满足条件，
那么就找到了一个解，如果不满足，那么就没有解，因为其他的解肯定不满足条件。
下面通过Horn公式来更详细的说明。</p>

<p>在Horn公式中，我们指定了一些布尔变量(比如x，y, z)必须满足的性质，通过两种公式给出:</p>

<ol>
  <li>蕴含式：在这种公式中，左边为合取范式，右边为单一变量, 所有变量必须不含否定，比如<script type="math/tex"> (z \bigwedge w)  \Longrightarrow u </script>
或者<script type="math/tex"> \Longrightarrow x </script>,
而<script type="math/tex"> (z \bigwedge \bar w)  \Longrightarrow u </script>就不是这种蕴含式</li>
  <li>完全由变量的否定组成的析取范式, 比如 <script type="math/tex"> (\bar u \bigvee \bar v \bigvee \bar y )</script>。</li>
</ol>

<p>问题是给定一个Horn公式，确定是否可以给公式中出现的变量赋予合适的布尔值，使所有的这些公式都能得到满足。
很显然，要满足蕴含式，需要要把一些变量设为True, 而要满足析取范式，需要把一些变量设为False。
对于每一个变量，赋值的方式都有两种，遍历所有的可能性显然是效率不高的。</p>

<p>贪心算法通过这样的思路来解决：</p>

<ol>
  <li>首先把变量都设为False，</li>
  <li>如果有蕴含式不满足，就把蕴含式右边的变量设成True，然后继续这个步骤直到所有的蕴含式都满足为止, 否则到步骤3。</li>
  <li>查看是否有析取范式不满足，如果全满足，那么就找到了一个解，否则，无解。</li>
</ol>

<p>说明两点：</p>

<ol>
  <li>
    <p>为什么这个算法是正确的。如果找到了一个解，显然是正确的。
如果没找到解，为什么就无解呢？因为前面的把变量设为True是“必须”的，
也就是说，一个变量被设为True，那么在任何正确的解中，它必须被设为True，
所有在这些必须的步骤都完成之后，如果不满足条件，也就没有解可以满足条件了。</p>
  </li>
  <li>
    <p>重复检查所有蕴含式是否满足的次数的不超过n+1次，其中n为变量的个数。
因为除了第一次检查，其余每一次检查都是因为前一次有变量被设为True，
(否则如果没有变量被设为True, 那么所有的蕴含式都满足，就不会再去检查了),
而变量被设为True的次数不超过n次，所以检查次数不超过n+1次，
这就保证了检查所有蕴含式是否满足并不是一个复杂度非常高的过程。</p>
  </li>
</ol>

<p>在这种贪心算法中，解决思路是找出那些必须要执行的步骤，一步一步，将问题简化，
最终解决。</p>

<h2 id="b">B树</h2>

<p>B树也是一种平衡地二叉查找树，类似于红黑树，
它也能够支持动态地插入，删除和查找数据。
B树主要用于保存数据到磁盘中，
比如很多数据库的索引就是通过B树进行保存。
由于磁盘的读取速度相对于内存要慢得多，
所以尽量地减少IO的次数显得非常重要，
B树也正是实现了这样的思想，B树的深度不会太深，
这样查找数据所需要遍历的节点数就会很少，
相应的IO次数也会减少。</p>

<p>在B树中，一个非根的节点至少包含t-1个关键字，
这样每一个非根的节点就至少有t个子女，这样一棵包含n个关键字的B树的高度h至多为
<script type="math/tex"> \log t \frac{n+1}{2} </script>。但是一个节点包含的关键字又不能太多，
一方面是因为一次IO只能读取指定数量的字节，
另一方面太多的关键字会导致定位一个关键字比较耗时，所以B树的每个节点包含至多2t-1个关键字。</p>

<p>这些性质能够保证B树查找的性能，但是在插入和删除的时候就需要维护这些性质。
具体表现在：</p>

<ul>
  <li>
    <p>当插入一个关键字到一个已经满了节点（包含2t-1个关键字），就需要把这个节点分裂成两个，
同时把这个节点中间关键字插入到它的父节点，这样可能会导致父节点的关键字超过2t-1，
所以需要一直向上到根来进行维护。</p>
  </li>
  <li>
    <p>当删除一个关键字时，会导致只有t-1个关键字的节点不满足性质，这时可以通过向它的兄弟“借”一个关键字，
如果兄弟包含至少t个关键字的话，否则，就和兄弟合并，然后从父节点删除一个关键字，
同样的，此时需要一直向上到根来进行维护。</p>
  </li>
</ul>

<p>书上在插入和删除节点的时候为了避免向上过滤来进行维护，
在遍历到某一个节点的时候，就把性质维护好，这样当一个节点遍历到的时候，
就能保证它的父节点不需要再去维护了。这样的方法，对于插入还好，
对于删除操作就显得有点复杂，考虑了好多种情况，
我觉得还是向上过滤进行维护比较好，并没有增加复杂度。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[红黑树扩充与动态规划]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/12/clrs-14-15/"/>
    <updated>2012-12-12T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/12/clrs-14-15</id>
    <content type="html"><![CDATA[<h2 id="section">红黑树的扩充</h2>

<p>由于红黑树这种结构很好的平衡性（树的高度不会很高），
对于动态变化的集合插入，查找，删除等操作的复杂度都比较低，
通过给它的节点增加一些其他的属性，
能够得到一些在特定情况下很有用的数据结构。</p>

<h3 id="section-1">扩充数据结构的四个步骤</h3>

<ol>
  <li>选择基础的数据结构</li>
  <li>确定需要给数据结构添加哪些信息，
这些信息可能被添加到每个节点中，也可能被添加作为整体数据结构的性质</li>
  <li>验证在数据结构的基本操作的过程中，这些信息可以被有效的维护，
这里的有效是指不会因为维护这些信息增加基础操作的复杂度</li>
  <li>利用这些信息提供一些有用的操作</li>
</ol>

<h3 id="section-2">通过扩充红黑树得到顺序统计</h3>

<p>通过给红黑树的每一个节点x附加属性size[x]，
表示以x为根的子树的节点个数，
可以通过递归确定一棵红黑树的第i小关键字的元素。
由于包含n个元素的红黑树的高度为<script type="math/tex"> O(\lg n) </script>，每次递归高度都会下降一层，
所以查找第i小关键字的时间复杂度为<script type="math/tex"> O(\lg n) </script>。</p>

<p>在第9章中，给出了获取n个元素的数组中第i个元素的<script type="math/tex"> \Theta(n) </script>的算法，
而一个包含n个元素的数组如果是有序的话，那么获取第i个元素的复杂度是<script type="math/tex"> O(1) </script>。
但是这种扩充的数据结构的好处在于它的动态性，它的插入和删除的时间复杂度也是<script type="math/tex"> O(\lg n) </script>，
而一个有序数组的插入和删除的复杂度是<script type="math/tex"> O(n) </script>。</p>

<h3 id="section-3">通过扩充红黑树得到区间树</h3>

<p>在区间树中，每一个节点x包含了一段区间int[x]，同时包含了一个max[x]，
表示以x为根的子树中所有区间的右端点的最大值，同时每一个节点的key[x] = low[int[x]]，
也就是说是把每一个节点所包含区间的左端点作为key。</p>

<p>区间树使得查找整个红黑树中与某一个区间i重合的区间变得十分容易，
可以如下递归实现：</p>

<ol>
  <li>如果当前节点为空，返回空节点</li>
  <li>如果区间i与当前节点的区间重合，返回当前节点</li>
  <li>如果区间i的左端点小于当前节点左儿子的max，递归查找左子树</li>
  <li>否则递归查找右子树</li>
</ol>

<p>情况1，2很自然，情况4也比较好理解，
因为如果i的左端点大于左儿子的max，它就大于那么对于左子树中所有节点的右端点，
左子树中一定不存在和区间i重合区间。情况3需要一定的思考，
因为如果i的左端点小于当前节点左儿子的max，并不能保证它一定不会与右子树中的区间重合，
所以如果只是递归查找左子树，如果左子树中有区间和i重合，那么能够返回正确结果
（因为只需要找到一个和i重合的区间就可以），如果左子树中没有区间与i重合，
那右子树中可能会有区间与i重合，导致没有返回正确的结果。情况是这样的吗？</p>

<p>不是这样的，下面可以证明在情况3时如果左子树中没有找到与i重合的区间，
那么在右子树中也一定不存在和i重合的区间。</p>

<p>假设左儿子的max来自于high[j]（也就是说，是左子树中区间j的右端点)，
那么一定有</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
high[i] < low[j]
 %]]&gt;</script>

<p>否则区间i和j重合，对于右子树中的任意区间k，一定有</p>

<script type="math/tex; mode=display"> 
low[k] \geq low[j] > high[i] \text{第一个不等式成立是根据红黑树关键字的性质}
</script>

<p>所以k与i不重合。</p>

<h2 id="section-4">动态规划</h2>

<!--more-->

<p>动态规划主要用于求解最优化问题，
它的基本思想是通过把子问题的结果保存起来，
这样当遇到一个更大的问题时，如果它需要解决子问题，
那么可以直接使用保存好的子问题的结果，而不用再去重复解决子问题。</p>

<h3 id="section-5">动态规划适用的基本条件</h3>

<p>使用动态规划必须要满足两个基本的条件：</p>

<ol>
  <li>最优子结构。一个问题的最优解包含子问题的最优解。
通常可以通过”剪切-粘贴”的方法证明最优子结构，也就是说，
假设一个问题的最优解没有包含子问题的最优解，
那么把相应的子问题的解替换成最优解将得到一个更好的解，
从而得出矛盾。</li>
  <li>重叠子问题。如果没有大量的重叠子问题，
那么直接通过递归求解子问题就可以，
动态规划相对于递归的好处也就在于不用重复去计算重叠的子问题，
从而节省了时间。</li>
</ol>

<h3 id="section-6">动态规划解题的基本思路</h3>

<p>在确定了一个问题适合采用动态规划进行解决之后，
仍然需要考虑几个问题。最主要的问题就是如何将问题利用更小的子问题来进行解决，
此时的思路是通过把原来的问题通过转化变成更小的子问题，
利用合适的转化可以把一个问题缩小成一个更小的子问题，比如最长递增子序列问题，
求以元素n结尾的最长递增子序列的长度，
可以转化为求以比n小的排在n前面的某个元素结尾的最长递增子序列的长度。
通过转化之后问题就缩小了。</p>

<p>将问题转换成子问题之后，必须要知道如何通过子问题的解得到原问题的解，
也就是所谓的递推公式，
比如上述问题，知道n之前的某个小于n元素的最长子序列的长度之后，
n的最长子序列的长度就是这个长度加1。</p>

<p>一个问题可能转化成多个子问题，比如说上面的问题，
比n小的排在n之前的元素可能有多个，这时，就需要从多个子问题之间做出选择。
这个选择通常是比较容易的，直接从所有根据子问题递推得到的解中选出一个最优解即可。
一般情况下，还需要记录此时的选择，用于构造出一个最优解。</p>

<p>把上述的问题都考虑好之后，就可以按照问题的大小，
从小到大依次将各个问题解决，直到达到所需要的问题的大小，
就得到了所需问题的解。</p>

<h3 id="section-7">动态规划的经典问题</h3>

<h4 id="lcs">最长公共子序列（LCS）</h4>

<ul>
  <li>问题描述：
定义序列<script type="math/tex">% &lt;![CDATA[
 X = <x_1, x_2, ..., x_m>  %]]&gt;</script>的一个子序列为
<script type="math/tex">% &lt;![CDATA[
 Z = <x_{i_1}, x_{i_2}, ..., x_{i_k}>  %]]&gt;</script>，其中
<script type="math/tex">% &lt;![CDATA[
 i_1 < i_2 < ... < i_k, k \geq 1  %]]&gt;</script>。求两个序列
<script type="math/tex">% &lt;![CDATA[
 X = <x_1, x_2, ..., x_m>  %]]&gt;</script>和<script type="math/tex">% &lt;![CDATA[
 Y = <y_1, y_2, ..., y_n>  %]]&gt;</script>的最长公共子序列的长度c[m, n]。</li>
  <li>
    <p>求解方法：
定义c[i, j]为序列<script type="math/tex"> X_i </script>和<script type="math/tex"> Y_j </script>的LCS的长度，
有如下递推公式成立</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
      c[i, j] = 
          \begin{cases}
              0 & \text{i=0 或j=0} \\
              c[i-1, j-1] + 1 & i,j > 0, x_i = y_j \\
              max\{c[i, j-1], c[i-1, j]\} & i,j > 0, x_i \neq y_j
          \end{cases}
   %]]&gt;</script>
  </li>
  <li>说明:
其实c[i, j]有三个子问题， c[i-1, j-1], c[i-1, j], c[i, j-1],
为什么当<script type="math/tex"> x_i = y_j </script>时只需要考虑第一个子问题，因为有如下不等式成立:</li>
</ul>

<script type="math/tex; mode=display">
c[i-1, j-1] + 1 \geq c[i, j-1] \\
c[i-1, j-1] + 1 \geq c[i-1, j]
</script>

<p>因为c[i, j-1]相对于c[i-1, j-1]就多了一个元素c[i]，
最多能够为最长公共子序列多增加长度1，同理对于c[i-1, j]也是如此。</p>

<h4 id="section-8">背包问题</h4>

<ul>
  <li>问题描述：
给定一个重量为w的背包，有n件商品重量分别为<script type="math/tex"> w_1, w_2, ..., w_n </script>,
价值分别为<script type="math/tex"> v_1, v_2, ..., v_n </script>，求这个背包能容纳的最大的商品价值</li>
  <li>
    <p>问题求解：</p>

    <ul>
      <li>如果对于每一件商品，可以拿取任意多次，则定义K(w)表示重量为w的背包最大的价值，
  有如下递推关系成立：</li>
    </ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

  K(w) = max\{K(w-w_i) + v_i\}, i=1..n, w_i < w
   %]]&gt;</script>

    <ul>
      <li>如果没一件商品只能拿一次，就不能采取上面的方法了，因为如果在K(w)转换至<script type="math/tex"> K(w-w_i) </script>时使用了
  商品i, 在求解<script type="math/tex"> K(w-w_i) </script>就不能再使用商品i,上述的递推公式不成立。必须采用另外一种方法。
  定义K(w, i)为重量为w的背包在装载商品1..i时的最大价值，有如下递推关系成立：</li>
    </ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

  K(w, i) = max\{K(w-w_i, i-1) + v_i, K(w, i-1)\}, i=1..n, w_i < w
   %]]&gt;</script>
  </li>
</ul>

<h3 id="floyd">Floyd算法的正确性</h3>

<p>Floyd算法用于求解图中所有节点中的最短路径。
基本思想是通过n（n为节点个数）次循环更新所有节点对之间的最短路径，
伪代码如下：</p>

<div class="highlight"><pre><code class="pascal">    <span class="k">for</span> <span class="n">k</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
        <span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
            <span class="k">for</span> <span class="n">j</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
                <span class="k">if</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">path</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="k">then</span>
                    <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">:=</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">+</span><span class="n">path</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">;</span>
</code></pre></div>

<p>在每次迭代时，对于任意节点对(i, j)，如果(i, k)的路径长度加(k, j)的路径长度小于
原来的(i, j)的路径长度，
那么就将(i, j)的路径长度更新为(i, k)的路径长度加(k, j)的路径长度（也就是说，
让(i, j)的最短路径经过k）。
算法的时间复杂度为<script type="math/tex"> O(n^3) </script>。</p>

<p>动态规划对于这个算法的理解是，在迭代k结束之后，
此时(i, j)的最短路径为仅使用{1, 2, …, k}作为中间节点的最短路径，
当循环结束时，k=n, 此时(i, j)的最短路径为使用任意节点作为中间节点的最短路径，
也就是(i, j)之间的最短路径。</p>

<p>凭直接感觉，比如说(i, j)之间的最短路径为：</p>

<script type="math/tex; mode=display">
i \rightarrow ... \rightarrow k_1 \rightarrow ... \rightarrow k_2 \rightarrow ... \rightarrow j
</script>

<p>其中<script type="math/tex">% &lt;![CDATA[
 k_1 < k_2  %]]&gt;</script>,
如果最外层的循环遍历到<script type="math/tex"> k_1 </script>时，因为此时不能使用<script type="math/tex"> k_2 </script>作为中间节点，
所以不会把(i, j)之间的最短路径经过<script type="math/tex"> k_1 </script>，
当允许使用<script type="math/tex"> k_2 </script>作为中间节点时，
有不会再去遍历<script type="math/tex"> k_1 </script>让(i, j)之间的最短路径经过<script type="math/tex"> k_1 </script>, 
所以，(i, j)之间的最短路径没有被找到，这个算法好像是错误的。</p>

<p>我开始老是纠结在这样的感觉中，
认为Floyd算法可能并没有找到一条最短的路径，
可是又总是找不到一个反例，
后面经过仔细地思考，总结出两种方法来说明这个算法的正确性，
解除了我的疑虑。</p>

<h4 id="floyd-1">通过循环不变式来证明Floyd算法的正确性</h4>

<p>通过证明以下循环不变式证明算法的正确性:</p>

<p>在第k轮迭代开始前，对于任意节点对(i, j)，
此时的最短路径长度为使用节点{1, 2, .., k-1}作为中间节点的最短路径长度。</p>

<ol>
  <li>初始化：在开始时，k=1, 此时的最短的路径为不使用任何中间节点的最短路径。</li>
  <li>保持：在第k轮迭代开始时，
此时(i, j)之间的最短路径为使用{1，2，…, k-1}作为中间节点的最短路径，
令p为(i, j)之间使用{1, 2, …, k}的最短路径：
    <ul>
      <li>如果path[i][k] + path[k][j] &lt; path[i][j]，
 那么此时p一定为<script type="math/tex"> i \xrightarrow{p_1} k \xrightarrow{p_2} j </script>，
 其中<script type="math/tex"> p_1 </script>为(i, k)之间使用{1, 2, …, k-1}作为中间节点的最短路径，
 <script type="math/tex"> p_2 </script>为(k, j)之间使用{1, 2, …, k-1}作为中间节点的最短路径。
 所以此时p的长度为path[i][k] + path[k][j]，不变式得以保持</li>
      <li>如果path[i][k] + path[k][j] &gt;= path[i][j]，
 那么此时p一定也是(i, j)仅经过{1, 2, …, k-1}的最短路径(也就是说，
 此时p一定不经过k)，p的长度就是path[i][j], 不变式同样可以保持</li>
    </ul>
  </li>
  <li>终止：循环结束时，k=n+1, 此时(i, j)的最短路径是使用任意节点作为中间节点的最短路径，
也就是(i, j)的最短路径。</li>
</ol>

<p>对于这个循环不变式，定义<script type="math/tex"> path^{(k)}(i, j) </script>表示(i, j)之间仅使用节点1,…,k作为中间节点的最短路径的长度，
利用这个递推公式：</p>

<script type="math/tex; mode=display">
path^{(k)}(i, j) = min\{ path^{(k-1)}(i, k) + path^{(k-1)}(k, j), path^{(k-1)}(i, j) \}
</script>

<p>可能要更好理解一些。</p>

<h4 id="floyd-2">通过归纳证明Floyd算法的正确性</h4>

<p>可以通过这样一种思路来证明：假设k是(i, j)最短路径中最大的中间节点，
也就是说对于(i, j)最短路径中任意的中间节点m, 有<script type="math/tex"> m \leq k </script>，这样，
k是(i, j)最短路径中最后被迭代的节点，如果在迭代到k时，
能够将(i, j)之间最短路径长度正确的设置，那么这个算法就是正确的。
在迭代k时，如果(i, k)和(k, j)之间的最短路径已经被正确设置时，
那么(i, j)在迭代k结束之后能够被正确设置。</p>

<p>下面通过归纳(i, j)路径中中间节点的个数n来证明在迭代k(k是(i, j)最短路径中最后被迭代的节点)时，
(i, k)和(k, j)最短路径已经被正确的设置：</p>

<ol>
  <li>当n=1, 在迭代k时，(i, k)和(k, j)都没有中间节点，
最短路径就是节点i和k以及k和j之间的距离, 已经被正确的设置。</li>
  <li>如果<script type="math/tex"> n \leq s </script>时，命题成立。那么当n=s+1时，在迭代k时，
对于路径(i, k), 它的中间节点的个数<script type="math/tex"> n_1 \leq s </script>，
那么当这条路径的最后一个节点<script type="math/tex"> k_1 </script>被迭代时，<script type="math/tex"> (i, k_1) </script>和<script type="math/tex"> (k_1, k) </script>已经被正确设置，
迭代之后，能够将路径(i, k)正确设置，同理可以证明路径(k , j)也能够被正确设置。</li>
  <li>由上述两步可以得知对于任意个数的中间节点，(i, j)在迭代最后一个节点k时，
(i, k)和(k, j)能够被正确的设置。</li>
</ol>

<h3 id="section-9">忽略我</h3>
<p>最后还是吐槽一下动态规划这一章的翻译真的很烂，
感觉和前面的章节不是同一个人翻译的，
很多语句很不通顺，比如说有个反问句就绕了我好久，
试着推测原文才明白什么意思。
人和人之间还是有差距的啊，不管做什么都是，
希望后面的几章能够翻译好一点，bless!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《算法导论》之基本数据结构]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/04/clrs-10-13/"/>
    <updated>2012-12-04T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/04/clrs-10-13</id>
    <content type="html"><![CDATA[<h2 id="section">散列表中碰撞的解决</h2>
<p>由于散列表的元素个数小于关键字的取值集合U,
因此会有两个不同的关键字映射到散列表的同一个槽上，
这时就发生了碰撞。发生了碰撞时，
书上给出了两种方法来解决，
而且保证此时的散列表平均情况下的查找复杂度是O(1)。</p>

<h3 id="section-1">链接法</h3>
<p>在链接法中，关键字映射到同一个槽上的元素通过一个链表来保存，
此时散列表T[0..m-1]的任意元素T[j]是一个链表，
当插入一个元素时，将元素放在它所对应的槽所指向链表的头部。
下面对链接法的性能进行分析。</p>

<p>定义散列表T的装载因子<script type="math/tex"> \alpha = n / m </script>, 其中n是元素个数，m是散列表槽数,
我们假设元素满足简单一致散列的条件：
任何元素散列到m个槽中的每一个的可能性是相同的。</p>

<p>用<script type="math/tex"> n_j </script>表示链表T[j]的长度，有
$$
E[n_j] = \alpha = n/m
$$</p>

<p>有如下性质成立：</p>

<ol>
  <li>
    <p>链接方式散列表在简单一致假设下，查找一个不存在元素所需时间的期望为<script type="math/tex"> \Theta (1 + \alpha) </script></p>

    <p>假设查找的元素是k, 它所对应的槽为h(k)，链表T[h(k)]的长度<script type="math/tex"> E[n_{h(k)}] = \alpha </script>，
 所以平均情况下需要遍历一个长度为<script type="math/tex"> \alpha </script>的链表，外加常数的散列函数时间和寻址T[h(k)]的时间，
 总共为<script type="math/tex"> \Theta (1 + \alpha) </script></p>
  </li>
  <li>
    <p>链接方式散列表在简单一致假设下，平均查找一个已存在的元素所需的时间为<script type="math/tex"> \Theta (1 + \alpha) </script></p>

    <p>对于任意元素x，检查的元素个数等于x所在链表中，出现在x之前的元素个数加1。
 设<script type="math/tex"> x_i </script>是第i个插入的元素，i=1,2,..,n,
 定义：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

     X_{ij} =
      \begin{cases}
          1 & x_i\text{和}x_j\text{在同一槽中} \\
          0 & \text{否则}
      \end{cases}
  %]]&gt;</script>

    <p>由简单一致性假设，<script type="math/tex"> E[X_{ij}] = 1/m </script>，所以检查元素个数的期望为：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

 \begin{array} {lcl}
 E[\frac{1}{n} \sum_{i=1}^{n} (1 + \sum_{j=0}^{i-1}X_{ij})]
     &=& 1 + \frac{n-1}{2m} \\
     &=& 1 + \frac{\alpha}{2} - \frac{\alpha}{2n}
 \end{array}
  %]]&gt;</script>

    <p>所以平均查找时间为: <script type="math/tex"> \Theta (2 + \frac{\alpha}{2} - \frac{\alpha}{2n}) = \Theta (1 + \alpha) </script></p>
  </li>
</ol>

<!--more-->

<h3 id="section-2">开放寻址法</h3>
<p>在开放寻址法中，对于每一个关键字k，定义探查序列
    &lt;h(k, 0), h(k, 1),…, h(k, m-1)&gt;
是&lt;0, 1, …, m-1&gt;的一个排列。在插入某一个元素x时，如果它的关键字是k,
按照它所对应的探查序列从h(k, 0)到h(k, m-1)依次检查散列表，如果h(k,i)是空槽，
那么将x插入到这个槽，否则检查h(k, i+1)。在查找时，
也是沿着探查序列开始寻找。</p>

<p>探查序列的计算方法有很多，比如说线性探查法，二次探查法，双重散列法。
但是这些技术都不能保证一致散列的假设：
对于每一个关键字k, &lt;h(k, 0), h(k, 1),…, h(k, m-1)&gt;是&lt;0, 1, …, m-1&gt;的任何一种排列的可能性是相同的。</p>

<p>在一致散列的假设下，有如下性质成立：</p>

<ul>
  <li>对于装载因子为<script type="math/tex">% &lt;![CDATA[
 \alpha = n/m < 1  %]]&gt;</script>的开放散列表，查找一个不存在的元素所需的探查数期望至多为<script type="math/tex"> \frac{1}{1-\alpha} </script>
定义随机变量X为探查数，<script type="math/tex"> A_i </script>为进行了第i次探查，有:</li>
</ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
E[X] &= \sum_{i=1}^{\infty} i \bullet Pr\{X = i\} \\
    &= (Pr\{X=1\} + Pr\{X=2\} + ...) + (Pr\{X=2\} + Pr\{X=3\} + ...) + ... \\
       &= \sum_{i=1}^{\infty}Pr\{ X \geq i \} \\
Pr\{ X \geq i \} &= Pr\{ A_1 \bigcap A_2 \bigcap ... \bigcap A_{i-1} \} \\
    &= Pr\{A_1\} \bullet Pr\{ A_2 | A_1 \} \bullet ... \bullet Pr\{ A_{i-1} | A_1 \bigcap A_2 \bigcap ... \bigcap A_{i-2} \} \\
Pr\{ A_1 \} &= \frac{n}{m} = \alpha \\
Pr\{ A_j | A_1 \bigcap A_2 \bigcap ... \bigcap A_{j-1} \} &= \frac{n-j+1}{m-j+1} \leq \frac{n}{m} = \alpha \\
Pr\{X \geq i \} &= \frac{n}{m} \bullet \frac{n-1}{m-1} \bullet \frac{n-2}{m-2} \bullet ... \bullet \frac{n-i+2}{m-i+2} \\
    &\leq (\frac{n}{m})^{i-1} = \alpha^{i-1} \\
E[X] &= \sum_{i=1}^{\infty}Pr\{ X \geq i \} \leq \sum_{i=1}^{\infty} \alpha^{i-1} \\
    &= \sum_{i=1}^{\infty} \alpha^{i-1} = \frac{1}{1-\alpha}
\end{align}
 %]]&gt;</script>

<ul>
  <li>
    <p>向一个装载因子为<script type="math/tex"> \alpha </script>的开放寻址散列表中插入一个元素，平均情况下最多进行<script type="math/tex"> \frac{1}{1-\alpha} </script>次探查。</p>

    <p>因为要插入一个元素x，只需要做一次查找x就能找到一个空槽，所以探查次数与查找一个不存在元素的查找相同。</p>
  </li>
  <li>
    <p>一个装载因子为<script type="math/tex"> \alpha </script>的开放散列表中查找一个存在的元素的期望探查次数至多为<script type="math/tex"> \frac{1}{\alpha} \ln \frac{1}{1-\alpha} </script></p>

    <p>对于每一个元素x，查找它所需要的探查次数与插入它所需要的探查次数相同，
  对于第i个插入的元素x, 所需的探查次数最多为<script type="math/tex"> \frac{1}{1-\frac{i}{m}} = \frac{m}{m-i} </script>，
  所以平均的探查次数最多为：</p>

<script type="math/tex; mode=display">
  \frac{1}{n} \sum_{i=0}^{n-1} \frac{m}{m-i} = \frac{m}{n} \sum_{i=0}^{n-1}\frac{1}{m-i}
      \leq \frac{1}{\alpha} \ln \frac{1}{1-\alpha}
  </script>
  </li>
</ul>

<p>对比开放寻址法与链接法，链接法能够支持装载因子<script type="math/tex"> \alpha > 1 </script>的情况，
而开放寻址法不能支持。</p>

<h2 id="section-3">二叉查找树与红黑树</h2>
<p>二叉查找树和红黑数都是用来存储动态集合的数据结构，
红黑树对二叉查找树进行了扩展，通过一些额外的性质，
保证了二叉查找树的平衡性，
这样就能够保证树的高度为O(lgn)， 其中n是节点的个数。
有了这些额外的性质时，
在插入节点或者删除节点的时候就需要一些额外的操作来保持这些性质。</p>

<h3 id="section-4">二叉查找树的基本操作</h3>
<p>二叉查找树所支持的基本操作有：</p>

<ol>
  <li>查找。
因为在二叉查找树中， 对于任何一个节点，
左子树中的关键字都小于当前节点的关键字，
而右子树中的关键字都大于当前节点的关键字，
所以可以通过一个简单的递归的来查找一个关键字：
如果关键字大于当前关键字，则递归查询右子树，
否则如果关键字小于当前关键字，递归查询左子树。</li>
  <li>
    <p>插入。插入也可以通过简单的递归来实现：</p>

    <ul>
      <li>如果要插入的关键字大于当前的关键字，如果右子树为空，
 则把这个节点作为当前节点的右儿子，否则递归插入到右子树</li>
      <li>如果要插入的关键字小于当前的关键字，如果左子树为空，
 则把这个节点作为当前节点的左儿子，否则递归插入到左子树</li>
    </ul>
  </li>
  <li>寻找二叉查找树中的最小节点和最大节点。
这两个操作是对称的，只需要给出求最小节点的方法，
采用递归的方式实现：
    <ul>
      <li>如果左子树非空，则返回左子树中的最小节点</li>
      <li>否则返回当前节点</li>
    </ul>
  </li>
  <li>寻找节点x的直接前趋或者直接后继。
这两个操作是对称的，只需要给出寻找直接后继的方法：
节点x的直接后继是指关键字大于key[x]中最小的那个节点，
    <ul>
      <li>如果x的右儿子存在，那么后继在x的右子树中，
 以x的右子树中的最小节点就是x的直接后继</li>
      <li>如果x的右儿子不存在，那么需要</li>
    </ul>
  </li>
  <li>删除。在删除一个节点x的时候，有三种情况需要考虑：
    <ul>
      <li>如果要删除的节点是叶节点，直接删除即可。</li>
      <li>如果要删除的节点只有一个儿子，那么先建立它的祖先和它儿子的父子关系,
 然后把它删除。</li>
      <li>如果要删除的节点有两个儿子，那么先从它的右子树中找到x的直接后继节点y，
 此时y一定没有左儿子（因为如果y有左儿子的话左儿子一定大于x且小于y，
 与y是x的直接后继矛盾）, 所以可以把y先从树中移除(删除y一定属于前两种情况)，
 然后用y代替x的位置。</li>
    </ul>
  </li>
</ol>

<h3 id="section-5">红黑树的性质</h3>
<p>相对于二叉查找树来说，赋予了每一个节点红色或者黑色，
同时整个红黑树需要保持下面的性质：</p>

<ol>
  <li>每个节点或者是红的，或者是黑的</li>
  <li>根节点是黑的</li>
  <li>每个叶节点是黑的</li>
  <li>如果一个节点是红的，那么它的两个儿子必须是黑的</li>
  <li>对每一个节点，从该节点到叶节点的所有路径上包含相同数目的黑节点</li>
</ol>

<p>其中，性质3可以不用考虑，因为在红黑树中，
所有的叶节点都是NIL, 它永远都是黑色。</p>

<p>有了这几条性质之后，
能保证一棵有n个节点（不包括NIL叶节点）的红黑树高度至多为2lg(n+1)。
这时，查找操作能够在O(lgn)的时间内完成。</p>

<h3 id="section-6">在插入和删除时红黑树性质的保持</h3>
<p>红黑树的性质可能在插入或者删除节点的时候被破坏，
此时需要一些操作来维护红黑数的性质。</p>

<h4 id="section-7">插入</h4>
<p>插入一个节点时，始终把新插入的节点的设成红色，
这时，会有两种原因造成红黑树性质的破坏：</p>

<ol>
  <li>如果新插入的节点是根节点，那么会破坏性质2</li>
  <li>如果插入节点的父节点是红色，那么将会破坏性质4</li>
</ol>

<p>函数RB-INSERT_FIX_UP()用于在插入z时红黑树T性质的保持：</p>

<pre><code>def RB-INSERT-FIXUP (T, z):
    while color[p[z]] = RED
        do if p[z] = left[p[p[z]]]
            then y ← right[p[p[z]]]
            if color[y] = RED                   
                then color[p[z]] ← BLACK        ###case1
                color[y] ← BLACK                ###case1
                color[p[p[z]]] ← RED            ###case1
                z ← p[p[z]]                     ###case1
            else if z = right[p[z]]            
                    then z ← p[z]               ###case2
                    LEFT-ROTATE (T, z)          ###case2
                color[p[z]] ← BLACK             ###case3
                color[p[ p[z]]] ← RED           ###case3
                RIGHT-ROTATE (T, p[p[z]])       ###case3
        else (same as then clause
            with “right” and “left” exchanged)
    color[root[T]] ← BLACK
</code></pre>

<p>这个函数能达到目的因为：</p>

<ol>
  <li>如果是上面的原因1违反, 那么p[z]是黑色，不会进入循环，直接在最后一行把根节点设为黑色</li>
  <li>如果是原因2违反，情况就要复杂一些，不能简单地把当前节点或者其父节点设为黑色就能解决问题，
因为此时可能会导致从根到各个叶节点路径上黑节点数目不相等（经过z的个数多1）。在这种情况下，
就要想办法把性质4的不一致向根节点“传递”，因为如果这种不一致到了根节点，
直接把根节点设为红色就可以，而不会引起其他的问题, 代码中分了三种情况：
    <ol>
      <li>
        <p>如果是情况1，p[z]和z的叔叔都是红色，可以把p[z]和y(z的叔叔)都设为黑色，
 然后把p[p[z]]设为红色，这样就把这种红红的不一致向上传递了两层，
 这种不一致在向上传递的过程中会有三种情况：</p>

        <ol>
          <li>没有造成不一致， 因为虽然把newz = p[p[z]]设为了红色，但可能此时p[newz]也是黑色，没有违反性质4</li>
          <li>造成不一致然后遇到了情况1， 这时会把这种不一致继续向上传递</li>
          <li>造成不一致然后遇到了情况2，3，这时直接可以通过旋转和颜色调整解决，不用向上传递</li>
        </ol>
      </li>
    </ol>

    <p>无论是哪一种情况，要么会被解决，要么传递到根由根来解决。</p>

    <ol>
      <li>如果是情况2，3，这时可以通过旋转和重新着色解决性质4的不一致，而不会造成其他问题。</li>
    </ol>
  </li>
</ol>

<h4 id="section-8">删除</h4>
<p>在删除一个节点时，如果被删除的节点是红色，
那么不会有问题，因为它的儿子和父亲都是黑色，
不会违背性质4，
同时任何路径上的黑色节点的个数也不会发生变化。
但如果删除的是一个黑色的节点y，会有以下原因导致性质违背：</p>

<ol>
  <li>如果y是根节点，而y的红色儿子成为了新的根，会违背性质2</li>
  <li>如果y的儿子x(y最多有一个儿子，可以从二叉查找树的删除中得到这个结论)和父亲都是红色，
那么会违背性质4</li>
  <li>删除y会导致经过y的路径上的黑节点数目个数少1，违背性质5</li>
</ol>

<p>函数RB-DELETE-FIXUP()用于在删除节点x的父亲时性质维护：</p>

<pre><code>def RB-DELETE-FIXUP(T, x):
    while x != root[T] and color[x] = BLACK
        do if x = left[p[x]]
            then w ← right[p[x]]
            if color[w] = RED
                then color[w] ← BLACK                                  ###case1
                color[p[x]] ← RED                                      ###case1
                LEFT-ROTATE (T, p[x])                                  ###case1
                w ← right[p[x]]                                        ###case1
            if color[left[w]] = BLACK and color[right[w]] = BLACK
                then color[w] ← RED                                    ###case2
                x ← p[x]                                               ###case2
            else if color[right[w]] = BLACK
                    then color[left[w]] ← BLACK                        ###case3
                    color[w] ← RED                                     ###case3
                    RIGHT-ROTATE (T, w)                                ###case3
                    w ← right[p[x]]                                    ###case3
                color[w] ← color[p[x]]                                 ###case4
                color[p[x]] ← BLACK                                    ###case4
                color[right[w]] ← BLACK                                ###case4
                LEFT-ROTATE (T, p[x])                                  ###case4
                x ← root[T]                                            ###case4
        else (same as then clause with “right” and “left” exchanged)
    color[x] ← BLACK
</code></pre>

<p>从代码中可以看出，原因1或者原因2都没有进入循环，直接通过把x设为黑色就能解决问题。
解决原因3的基本思路是给x赋予一层多余的黑色(充当一个黑色节点的计数)，试着把这个多余的黑色往根传递, 
在向上传递的过程中，可能会遇到3种情况：</p>

<ol>
  <li>这种多余的黑色传递到了一个红色的节点，那么直接把这个红色的节点设为黑色即可</li>
  <li>在传递过程中遇到了情况3，4，可以通过旋转和颜色调整而解决问题，不会引起其他的问题</li>
  <li>一直遇到情况2而传递到了根节点，这时直接去掉这个多余的黑色即可，
因为此时从根到叶节点的所有路径的黑节点数目都少1，性质5得到解决。</li>
</ol>

<p>为什么再调整过程中旋转的次数不超过3次？简单看来，有如下转换关系：</p>

<ol>
  <li>case1 -&gt; case2, case3, case4,情况1结束之后将到达情况2，或情况3，或情况4</li>
  <li>case2 -&gt; new while, 情况2之后将进入新的循环</li>
  <li>case3 -&gt; case4，情况3将到达情况4</li>
  <li>case4 -&gt; 终止，情况4之后把x设为root，将导致循环终止</li>
</ol>

<p>情况1会有旋转，如果进入了情况3或情况4，将导致循环终止，此时旋转次数不超过3次，
但如果进入进入情况2，那么将会进入新的循环，此时有可能碰到情况1然后再次旋转，
然后进入再进入情况2…这样一直向上到根，旋转的次数可能会超过3次，
是这样吗？</p>

<p>上面的情况的是不可能发生的，因为情况1会把p[x]设为红色，如果此时进入情况2，
在新的循环开始时，新的x就是p[x]，它的颜色是红色，直接会退出循环，把x设为黑色，
调整结束，不会再继续向上传递。所以旋转的次数不会超过3次。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[算法导论8~9章读书笔记]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/01/clrs-8-9/"/>
    <updated>2012-12-01T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/01/clrs-8-9</id>
    <content type="html"><![CDATA[<h3 id="section">比较排序的时间下界</h3>
<p>合并排序和堆排序在最坏情况下能够在O(nlgn)时间内排序n个数，
而快速排序则能够在平均情况下达到这个上界。
这些算法在确定元素的次序时，
都是基于元素间的比较。
这类排序算法称为__比较排序__。</p>

<p>比较排序的时间下界是O(nlgn)，
这意味着所有的基于比较的排序算法，在最坏情况下都要用<script type="math/tex"> \Omega (n \lg n) </script>
次比较来完成排序。</p>

<p>这是因为比较排序可以被抽象为__决策树__，
决策树是一棵满二叉数，
它的每一条从根节点到叶节点的路径都对应于比较排序的一次执行过程，
达到叶节点时，叶节点确定了这次排序的结果。
所以比较排序算法的最坏情况的比较次数等于决策树的高度。
n个数的排列总数有n!，每一种排列都必须在决策树的叶节点中出现，
高度为h的决策树的叶节点个数最多为<script type="math/tex"> 2^h </script>，故有：</p>

<script type="math/tex; mode=display">
n! \leq 2^h \\
\Longrightarrow   h \geq \lg (n!) = \Omega (n \lg n)
</script>

<p>所以比较排序的时间下界是O(nlgn)。</p>

<!--more-->

<h3 id="section-1">通过计数排序实现线性时间排序</h3>
<p>如果已经知道n个元素都是来自于0到k的整数，
其中<script type="math/tex"> k = O(n) </script>,
那么可以通过统计0到k中的每一个数在n个元素中出现的次数来达到排序的目的。
计数排序的运行时间为 <script type="math/tex"> \Theta (n) </script>。</p>

<p>书上在实现计数排序时，</p>

<ol>
  <li>首先遍历一遍原数组A，将各个元素出现次数统计到数组C中,此时C[0..k]的每一项C[i]表示i在A中的出现次数</li>
  <li>然后遍历一遍数组C, 使C[i]表示A中小于或等于i的元素个数</li>
  <li>最后遍历A(逆向遍历)，把结果放到数组B中，把A[i]放到B的C[A[i]]位置上，同时把C[A[i]]减1
(这是为了把重复的元素放到不同的位置上去)</li>
</ol>

<p>其实只需要让C[i]记录i在数组A中出现的次数，然后遍历一遍数组C就可以输出排序的结果。
具体遍历方法如下：</p>

<pre><code>j &lt;- 1
for i &lt;- 1 to k
    while C[i] &gt; 0
        do C[i] &lt;- C[i] - 1 
            A[j] = i
            j &lt;- j + 1
</code></pre>

<p>就能把排序好的结果保存到A中，不需要另外的数组B。
但是书上的这种方法有一个好处，它能保证排序是__稳定__的。
也就是说，具有相同值的元素在输出数组中的相对次序与输入数组中的相对次序一样。
因为是采取对A的逆向遍历，两个相同的元素中，位置靠前的元素后被遍历，此时C[i]已经变小了，
所以也会被放在更靠前的位置。稳定排序的好处在于它能够保证基数排序的正确性。</p>

<h3 id="section-2">基数排序：另一种线性时间排序</h3>
<p>基数排序主要解决的问题是对于多位整数的排序问题。
比如有n个d位数，每一位可以取k个不同的值，要对它进行排序，
一般的想法是先对最高位进行排序，
然后对于高位相同的子数组按次高位进行排序，依次类推。
这种想法的好处在于如果两个数中高位较大的数一定较大，
所以很容易把各个子数组的排序结果进行合并。比如排序10进制的三位数，
3XX一定都大于2XX，所以把2XX的子数组放在3XX的子数组前面就能保证合并结果的有序性。
但是它的不好的地方在于需要维护大量的子数组(随着递归的深度加深，子数组个数增多)，
这对于原始的基于纸带的排序的是不可行的。</p>

<p>那有没有一种排序方法，既能使后面的排序利用到前面排序的结果，
而且能够不需要维护大量的子数组呢？基数排序就是这样一种排序方法，
它先把数组按最低位进行排序，然后再对结果按次低位进行排序，依次类推。
每一次的排序都必须是__稳定排序__，这样能保证在按某位进行排序之后，
整个数组在从该位到最低位的子序列上都是有序的，可以通过一个简单的归纳加以证明。</p>

<p>同时，在对n个b位数进行排序时，每次可以按r位进行排序，
而不仅仅是1位，这样能够在<script type="math/tex"> \Omega ((b/r)(n + 2^r)) </script>的时间内完成对数组的排序。
可以选取适当的r达到最好的时间性能。</p>

<h3 id="section-3">同时找出数组中的最大值和最小值</h3>
<p>从一个数组中找出最大值或者最小值需要n-1次比较，
比如寻找最大值，首先将最大值设为第一个元素的值，
然后让n-1个元素和最大值进行比较，如果大于最大值，
就将最大值设为它，一共需要n-1次比较。</p>

<p>而如果是同时找出最大值和最小值呢，
当然可以分别按上面的方法找出最大值和最小值，
一共需要的比较次数是2n-2。</p>

<p>书上给出了另外一种方法：
成对的处理元素，将较小者与最小值相比，较大者与最大值相比，
这样能将比较次数降为<script type="math/tex">  3 \lceil n/2 \rceil </script>。</p>

<h3 id="i">在线性时间内选出数组中的第i小元素</h3>
<p>书上给出了两种方法：</p>

<p>第一种方法利用随机化快速排序算法中的RANDOMIZED-PARTITION函数对数组进行划分，然后根据
i是在哪一个部分中去相应部分中进行查找，这种方法能保证运行时间的期望是线性，代码如下：</p>

<pre><code>def RANDOMIZED-SELECT(A, p, r, i)
    q &lt;- RANDOMIZED-PARTITION(A, p, r)
    k &lt;- q - p + 1
    if i = k
        then return A[q]
    elseif i &lt; k
        then return RANDOMIZED-SELECT(A, p, q-1, i)
    else return RANDOMIZED-SELECT(A, q+1, r, i-k)
</code></pre>

<p>简单说明一下在划分的两个子数组中，如果有一个长度为0，
为什么不会它调用RANDOMIZED-SELECT:</p>

<ul>
  <li>如果子数组A[p..q-1]长度为0，则q = p，k = q - p + 1 = 1，<script type="math/tex"> i \geq k </script>, 不会对这个子数组调用RANDOMIZED-SELECT</li>
  <li>如果子数组A[q+1..r]长度为0，则q = r，k = r - p + 1 = length[A]，<script type="math/tex"> i \leq k </script>, 不会对这个子数组调用RANDOMIZED-SELECT</li>
</ul>

<p>第二种方法通过保证每次的划分是一个好的划分保证算法的线性时间。
具体的划分方式是：</p>

<ol>
  <li>将数组的n个元素划分为 <script type="math/tex"> \lceil n/5 \rceil </script>组，除最后一组之外，其余都有5个元素</li>
  <li>对每一组找到其中位数, 首先对每个数组进行插入排序，然后找到其中的中位数</li>
  <li>通过递归调用SELECT函数(就是找出数组中第i小元素的函数)，找到这些中位数中的中位数x</li>
  <li>以x作为划分元素对数组进行划分</li>
</ol>

<p>这个划分是一个好的划分，
因为能保证划分出来的两个子数组中任意一个的长度都不会超过某一个特定值。
在<script type="math/tex"> \lceil n/5 \rceil </script>个组中，
假设所有的中位数组成数组B[1..m]，其中 <script type="math/tex"> m = \lceil n/5 \rceil </script>,
假设x = B[k]，k = <script type="math/tex"> \lceil \frac{1}{2} \lceil \frac{n}{5} \rceil \rceil </script>,
在所有中位数在A[k..m]的组中，除去最后一组和x所在的组之外，其他的组至少有3个元素大于x，
所以大于x的元素个数至少为：</p>

<script type="math/tex; mode=display">
3(\lceil \frac{1}{2} \lceil \frac{n}{5} \rceil \rceil - 2) \geq \frac{3n}{10} - 6
</script>

<p>类似的小于x的元素个数至少有<script type="math/tex"> \frac{3n}{10} - 6 </script>个，
所以至多有<script type="math/tex"> \frac{7n}{10} + 6 </script>个元素被递归的调用SELECT，
有了这个结论之后就能保证SELECT函数可以在线性的时间内完成。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《算法导论》读书总结1]]></title>
    <link href="http://chouqin.github.io/blog/2012/11/19/clrs-1/"/>
    <updated>2012-11-19T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/11/19/clrs-1</id>
    <content type="html"><![CDATA[<p>正如上一篇所说，我这几天都在学习《算法导论》这本书，
也终于是下定决心要好好把这本书看出个所以然来。
这几天看下来，发现最大的困扰并不是知识的难度，
而是克服自己内心的浮躁。因为这本书并不像其他的工科教材，
它讲得东西是比较偏理论一些，里面充满了各种数学公式，数学定理,
包括一个算法正确性的证明，都采取了形式化的证明手段，
力求证明的数学严格性。
如果只是需要粗粗理解各种算法是什么样的以及如何实现的话，
那么看这本书有点不太合适，
因为这方面的东西并不是这本书的重点。</p>

<p>而我，也是在粗粗了解了各种算法和实现的基础上学习这本书的，
一开始扫了一下书的第一章，第二章和第六章，
发现和其他的算法书还差不多嘛，
直到看到第七章快速排序，
看到作者在大概描述完快速排序算法之后
（这个快速排序的划分函数还和我以前见过的都不一样，更加容易理解和实现），
转而开始分析快速排序的性能和随机化版本，我才明白，
我不能再这么浮躁地只是抱着了解了解算法的目的来学习这本书了。
于是我又回过去仔仔细细地从头看到了第7章，
虽然说这本书里的定理和数学公式很多，但是并不难理解，
因为作者总是把每一个步骤解释地十分细致和透彻，
每一步的证明没有很大的跨越，
每一个结论的得出都会指明依据的定理或者是前面的结论。
所以说好好看下去其实并没有很大难度，
关键是要能够静得下心。</p>

<p>下面是1～7章中我的几点体会：</p>

<!--more-->

<h3 id="section">循环不变式</h3>
<p>循环不变式用于证明算法的正确性，
它能够保证一个算法能够终止，
而且当它终止时，得到的结果是正确的结果。
循环不变式的证明由三个部分组成：</p>

<ul>
  <li>初始化: 在循环的开始时，循环不变式成立。</li>
  <li>保持：如果在某一轮迭代之前循环不变式成立，那么在迭代之后，
循环不变式仍然成立。</li>
  <li>终止：如果保持循环不变式一直到循环的终止，那么这个算法将得到正确的结果。</li>
</ul>

<p>循环不变式与数学归纳法十分类似，采用的也是同样的思想。
在应用循环不变式对算法的正确性进行证明时，
难点不在于上述的三个步骤，而在于循环不变式的构造，
要构造一个循环不变式能够在循环过程中始终保持，
而且能体现算法正确性，这确实需要一定的技巧。
这就类似于在应用数学归纳法时选取归纳条件。</p>

<p>比如书中思考题2-2：（证明冒泡排序的正确性）</p>

<pre><code>for i &lt;- 1 to length[A]
    do for j &lt;- length[A] downto i+1
        do if A[j] &lt; A[j-1]
            then exchange A[j] &lt;-&gt; A[j-1]
</code></pre>

<p>b)对于2-4行(内层循环)给出一个循环不变式，并证明这个循环不变式是成立的。</p>

<p>内层循环的作用是把A[i]到A[n]（n是length[A]）中最小元素放到A[i],
可以采用如下的循环不变式来表示：</p>

<p>在每一轮迭代的开始，子数组A[j..n]中最小的元素位于A[j]。</p>

<p>下面对这个循环不变式进行证明：</p>

<ul>
  <li>初始化： 在第一轮迭代开始前，j = n，A[j..n]中就只有一个元素，
最小的元素位于A[n]。</li>
  <li>保持：在第k轮迭代时，
    <ul>
      <li>如果A[j] &gt;= A[j-1]，由循环不变式可知，
A[j]是字数组A[j..n]中最小的元素，那么循环结束时A[j-1]将是字数组A[j-1..n]中的最小元素。</li>
      <li>如果A[j] &lt; A[j-1], 那么在互换A[j]和A[j-1]之后，最小的元素仍然是A[j-1]。</li>
    </ul>
  </li>
  <li>终止: 在循环结束时j=i, 说明A[i]是字数组A[i..n]中的最小元素，
算法达到了把最小元素放到A[i]的目的。</li>
</ul>

<h3 id="section-1">渐进符号</h3>
<p>渐进符号用户描述一个算法的复杂度，以前只知道
渐进符号用于描述算法的量级，比如<script type="math/tex"> 2n^2 = O(n^2) </script> 
说明 
<script type="math/tex"> 2n^2 </script>
的量级是
<script type="math/tex">O(n^2)</script>。</p>

<p>书上给出了准确的定义:</p>

<script type="math/tex; mode=display">
O(g(n)) = \{f(n): \exists c,n， \forall n \geq n_0,  0 \leq f(n) \leq cg(n)\}
</script>

<p>同时有：</p>

<script type="math/tex; mode=display">
f(n) = O(g(n)) \Longleftrightarrow f(n) \in O(g(n)) 
</script>

<p>其他的符号如<script type="math/tex">\Omega</script>, <script type="math/tex">\Theta </script>都是类似的定义。
当然，我们只需要知道用<script type="math/tex"> O(f(n)) </script>来确定一个函数的上界，
用<script type="math/tex"> \Omega(f(n)) </script>来确定一个函数的下界就可以了。</p>

<h3 id="section-2">递归与主定理</h3>
<p>分治法是一种很常见的算法设计方法，
分治法的时间复杂度一般由如下的递归式给出：</p>

<script type="math/tex; mode=display">
T(n) = aT(n/b) + f(n)
</script>

<p>其中<script type="math/tex"> a \geq 1, b > 1</script>，f(n)一般用渐进函数表示。</p>

<p>对于这样的递归式，主定理给出了计算T(n)的方法：</p>

<ul>
  <li>如果存在常数<script type="math/tex"> \epsilon > 0 </script>，有
<script type="math/tex"> f(n) = O(n^{\log_ba - \epsilon}) </script>，
则
<script type="math/tex"> T(n) = \Theta(n^{\log_ba}) </script>;</li>
  <li>如果
<script type="math/tex"> f(n) = \Theta(n^{\log_ba}) </script>，
则
<script type="math/tex"> T(n) = \Theta(n^{\log_ba}\lg n) </script>;</li>
  <li>如果存在常数<script type="math/tex"> \epsilon > 0 </script>，有
<script type="math/tex"> f(n) = \Omega(n^{\log_ba + \epsilon}) </script>，
且对常数<script type="math/tex">% &lt;![CDATA[
 c < 1  %]]&gt;</script>与足够大的n,有
<script type="math/tex"> af(n/b) \leq cf(n) </script>，则
<script type="math/tex"> T(n) = \Theta(f(n)) </script>。</li>
</ul>

<p>运用主定理，能够很快地求出分治算法的复杂度。</p>

<h3 id="section-3">指示器随机变量</h3>
<p>指示器随机变量的定义如下:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
    X_H = I\{H\} = 
     \begin{cases}
         1 & \text{如果H发生} \\
         0 & \text{如果H没有发生}
     \end{cases}
 %]]&gt;</script>

<p>指示器随机变量是随机变量的一种，可以求出它的期望如下：
$$
    E[X_H] = Pr_H
$$</p>

<p>指示器随机变量有一个很好的性质，它只能取0或者1，
可以把它这些变量加起来求总的发生次数,
因此当它应用到重复随机试验中时,
统计重复试验某一事件发生次数的期望，
比如在随机化的快速排序中统计交换次数的期望,
可以通过如下公式得到：</p>

<script type="math/tex; mode=display"> 
E[X] = E[\sum_{i=1}^n X_i] = \sum_{i=1}^n E[X_i]
</script>

<p>要使等式的第二步成立，不一定要保证<script type="math/tex"> X_i </script>之间是相互独立的。</p>

<p>这周的读书笔记就先写到这里，下周开始写第8章开始的内容。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL 基本优化]]></title>
    <link href="http://chouqin.github.io/blog/2012/11/15/mysql-basic/"/>
    <updated>2012-11-15T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/11/15/mysql-basic</id>
    <content type="html"><![CDATA[<p>这几天好好地研究了一下mysql,认真地看了《High Performance MySQL》的几章，
才发现，要能够精通mysql真的是一个长期的工程，有效地管理mysql,
使它能够具有很强的稳定性同时具有很快的相应速度，
这其中涉及的东西远远不是数据库的课上写几条sql语句那么简单。
而在这篇博客中，我也仅就mysql的一些基本优化知识谈谈我的看法，
待以后更加深入研究之后，再继续分享。</p>

<h2 id="mysql">MySQL的表的设计</h2>

<h3 id="normalized-schema-or-denormalized-schema">Normalized Schema Or Denormalized Schema?</h3>
<p>在一般的数据库教材中，讲到设计库表结构的设计，
都是将数据库设计范式作为设计的准则，因为这样设计的数据库表重复很少，
这样就会减少存储空间，
同时因为重复的内容少，维护起来也很方便，
因为如果很多的重复的话一个信息的更改可能会需要在多处进行更改才能保证数据的一致性。
然而，数据库范式并不是万能的，这样设计出来的数据库会造成查找时间的加长，
因为要查找一些数据往往需要将多个表join起来，而join是比较费时间的数据库操作，
同时，一些有关系的列被分散到各个表中，不好组合在一起建成一个索引，
这样也会减低查找的速度。
所以在设计数据库的表的结构时，要结合应用的实际情况，平衡考虑。</p>

<!--more-->

<h3 id="cache-table--summary-table">Cache Table &amp; Summary Table</h3>
<p>使用“空间换取时间”的理念，在数据统计的过程中，为了方便同时，
我们会建立一些缓存表，
这些表的目的是把一个表中的多行信息或者多个表的信息综合起来，
比如有一个表保存了今天的用户访问记录，
就可以建成一个daycount表统计每天有多少用户访问，
这样如果需要查询某一天有多少用户访问的时候直接去这个表中去查了。
缓存表引入的一个问题是缓存表的维护，
一般是通过一些周期性跑的脚本去更新这些缓存表，
FlexView这个工具能够自动的帮我们维护这些缓存表，
有兴趣的可以尝试一下。</p>

<h3 id="section">数据类型的选择</h3>
<p>尽量选择小的，简单的数据类型，能用tinyint就不要用int,能有enum就不要用varchar。
同时尽量不要用NULL，因为NULL会引入许多的问题，首先是它不容易被索引，
同时保存它占用了更多的空间。</p>

<h2 id="section-1">索引优化总结</h2>

<h3 id="section-2">为什么索引能够提高查找的速度？</h3>

<ul>
  <li>索引能够减少需要数据库需要读取的数据。因为它不需要整个表都读取一遍，
同时如果使用了覆盖索引，那么需要的数据就在索引中，只要将索引的数据返回即可。</li>
  <li>索引能够帮助数据库进行排序。如果要排序的字段刚好在索引中，
由于索引本身就是排好序的，这样就不需要再进行排序，减少了时间和空间的浪费。</li>
  <li>索引能够把随机IO转化为顺序IO，这是因为索引靠近的数据一般存储的位置也是相邻的，
这样能够顺序读取。</li>
</ul>

<h3 id="section-3">多字段索引时顺序的选择</h3>
<p>有时，建立索引一个字段的索引往往就够用了，因为通过这一个字段，就能过滤掉大部分的行，
剩下来的行数比较少，这样再进行过滤或者是sort, group等操作都不会有很大的压力。
然而，如果表中的数据非常多，一个字段过滤之后可能数据还是非常多，
这时就需要建立一个多字段的索引，又称为组合索引。</p>

<p>组合索引的顺序选择非常重要，因为mysql只能拿一个索引的前缀进行索引。比如有一个索引
(col1, col2)，那么如果你的where语句中col1 = a and col2 = b或者是col1 = a，
这时mysql可以使用这个索引。但如果你的where语句是col2 = b这时就不能使用这个索引。
另外一个关乎索引顺序的地方是如果你的过滤条件是一个范围(range condition)的时候，再拿上面的索引为例，
如果你where语句有col1 = 1 and col2 &lt; 2时，两个过滤的条件都会在使用索引过滤的时候起到作用，
而如果where语句是col1 &gt; 1 and col2 = 2，这时只有第一个过滤条件在过滤索引时起到作用，也就是说，
在这时存储引擎会把col1 &gt; 1的所有行都返回到mysql server，
而后服务器再通过col2 = 2过滤掉一些行，这个过滤的效果显然不好，
特别是当数据量较大的时候。关于这个的详细解释，
可以参考这篇<a href="http://jorgenloland.blogspot.sg/2011/08/mysql-range-access-method-explained.html">The MySQL range access method explained</a>。</p>

<p>既然索引的顺序这么重要，那如何去设计列的顺序呢？我总结了一些我的看法：</p>

<ul>
  <li>A Rule of Thumb: 选择最具有过滤性列的放在索引的前面，因为这样的列能够很快地过滤掉
一些不需要的行。</li>
  <li>把最经常拿来过滤的字段放在索引的前面，因为mysql使用的是前缀索引，
如果不经常使用的列放在前面会造成索引的失效。</li>
  <li>把那些比较容易使用范围来进行过滤的字段放在索引后面，比如说day, created_at什么的。
因为如果这些字段放在前面会造成后面字段的过滤条件不起作用。</li>
</ul>

<h3 id="explain">理解explain语句</h3>
<p>要知道一个索引设计得好不好，它有没有在sql语句中被合理地使用，
通过explain sql来查看sql一些执行细节是很有必要的。
explain sql的输出结果中，除了包含索引选择等信息，
还会告诉你诸如mysql如何对结果进行排序等信息。</p>

<p><a href="http://weevilgenius.net/2010/09/mysql-explain-reference/">MySQL Explain – Reference</a>
这篇博客详细地讲述了explain语句输出的各个字段表示的意义，
特别是将type(access type)这个部分讲得特别清楚。</p>

<h2 id="sql">优化SQL语句</h2>
<p>设计好表的结构和索引之后，仍然需要采取适当的方式来进行查询才能达到更好的执行效率。
《High Performance MySQL》给出了几个优化的技巧：</p>

<ul>
  <li>尽量使用join来代替子查询语句，因为它能够更好地利用索引。</li>
  <li>使用’deferred join’来优化limit offset,具体可参照《High Performance MySQL》的6.7.5节。</li>
  <li>优化join:
    <ul>
      <li>确保被join的字段在第二个表中被索引</li>
      <li>确保group by或者order by的字段在同一个表中</li>
    </ul>
  </li>
</ul>

<h2 id="section-4">推荐阅读</h2>
<ul>
  <li><a href="http://net.tutsplus.com/tutorials/other/top-20-mysql-best-practices/">Top 20+ MySQL Best Practices</a>，
陈皓写了这篇的<a href="http://coolshell.cn/articles/1846.html">翻译版</a>。</li>
  <li><a href="http://isky000.com/database/mysql-performance-tuning-index">MySQl 性能优化</a></li>
</ul>

<h2 id="section-5">预告</h2>
<p>前两天<a href="http://weibo.com/jeffz">@老赵</a>发起了一个资助大学生读书的计划，
我有幸得到了他资助的《算法导论》一本。
这样一本书并不是随便就能得来的，正如老赵所说：</p>

<blockquote>
  <p>因此，千万不要把这个计划当做是免费的图书来源，选书要谨慎，拿到书就要好好阅读。
在我看来，参与这个计划其实更多的是压力。
当然，有适当的压力对于学习也是很有好处的，不是么？</p>
</blockquote>

<p>而我，也正是需要这样的一种压力，能够督促我更好地去学习这样一本经典教材。
因此，接下来我会经常地在这里公布我的读书笔记，更多的是自己学习算法的心得体会，
希望能够多多有所感悟，学到更多的东西。:)</p>

<p>特别感谢老赵的热心，能够让我们阅读这些经典的书籍，也希望他能够帮助更多的人。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅谈中文编码]]></title>
    <link href="http://chouqin.github.io/blog/2012/11/11/chinese-encoding/"/>
    <updated>2012-11-11T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/11/11/chinese-encoding</id>
    <content type="html"><![CDATA[<p>作为一个天朝的程序员，总是会在编程的时候与中文打交道。一开始对于编码不是很熟悉，也没有弄明白它里面的原理，
在处理中文的时候总是会遇到各种各样的问题，特别是在用python处理中文的时候，
所以特地花时间研究了一下中文编码，并通过python来熟悉一些概念。</p>

<p>废话不多说，先上干货，<a href="http://www.searchtb.com/2012/04/chinese_encode.html">中文编码杂谈</a>，
这篇文章是淘宝搜索技术团队写的，深入浅出，基本上将中文编码的各个方面讲得十分细致，而且十分通俗易懂。
我很难讲得比这篇文章更好了，我主要从几个侧面来阐述一下我对于中文编码的理解。</p>

<h2 id="section">中文编码是什么</h2>
<p>中文编码其实就是将中文转化为二进制比特串的过程，而不同的编码方式会把同一个中文字符转化为不同的二进制表示，
比如“中”这个字，通过utf-8编码会转化为二进制E4B8AD，而在计算机中，所有的数据都是通过二进制保存，这样我们就可以
通过二进制E4B8AD来保存“中”字，然后我们如果需要读取保存的这个字，我们首先需要知道编码方式是utf-8，然后就能将
E4B8AD转化为“中”。</p>

<h2 id="python">python的中文处理</h2>
<p>python提供了对unicode很好的支持，同时也能将unicode转化为其他的各种编码。</p>

<p>下面通过代码来对解释一下pytho中的编码问题。</p>

<div class="highlight"><pre><code class="python">    <span class="o">&gt;&gt;&gt;</span><span class="n">a</span> <span class="o">=</span> <span class="s">&quot;我是123&quot;</span>
    <span class="o">&gt;&gt;&gt;</span><span class="n">a</span>
    <span class="s">&#39;</span><span class="se">\xe6\x88\x91\xe6\x98\xaf</span><span class="s">123&#39;</span>
    <span class="o">&gt;&gt;&gt;</span><span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="nb">str</span>
    <span class="o">&gt;&gt;&gt;</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="mi">9</span>
</code></pre></div>

<!--more-->

<p>从上面的代码可以看到，python把”我是123”这个字符串当成是str类型，其实只是把这个字符串的编码
二进制当成中文来处理。当我们通过输入法输入”我是123”时，输入法会根据我们系统的LACALE值将”我是123”
编码成相应的二进制，而python遇到二进制值时的处理也是要根据系统的编码方式，如果是一个python的脚本，
我们可以通过再脚本的头部通过</p>

<pre><code>`# -*- coding:utf-8 -*- `
</code></pre>

<p>设置python处理编码的方式。</p>

<p>同时可以看到”我是123”这个字符串的长度是9，这是因为字符串a在utf8编码时的二进制表示为<code>'\xe6\x88\x91\xe6\x98\xaf\x21\x22\x23'</code>,
一共占了9个字节，python的len()函数对于字符串就是计算它占了多少个byte,所以:len(a) = 9。</p>

<p>下面看如何与unicode进行相互转化:(此时采用的编码是utf8，其他的编码也是一样的处理):</p>

<div class="highlight"><pre><code class="python">    <span class="o">&gt;&gt;&gt;</span><span class="n">ua</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="o">&gt;&gt;&gt;</span><span class="n">ua</span>
    <span class="s">u&#39;</span><span class="se">\u6211\u662f</span><span class="s">123&#39;</span>
    <span class="o">&gt;&gt;&gt;</span><span class="k">print</span> <span class="n">ua</span>
    <span class="err">我是</span><span class="mi">123</span>
    <span class="o">&gt;&gt;&gt;</span><span class="nb">type</span><span class="p">(</span><span class="n">ua</span><span class="p">)</span>
    <span class="nb">unicode</span>
    <span class="o">&gt;&gt;&gt;</span><span class="nb">len</span><span class="p">(</span><span class="n">ua</span><span class="p">)</span>
    <span class="mi">5</span>
    <span class="o">&gt;&gt;&gt;</span><span class="n">b</span> <span class="o">=</span> <span class="n">ua</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="o">&gt;&gt;&gt;</span><span class="n">b</span>
    <span class="s">&#39;</span><span class="se">\xe6\x88\x91\xe6\x98\xaf</span><span class="s">123&#39;</span>
</code></pre></div>

<p>将字符串转换为unicode通过decode()函数，反过来通过encode()函数。同时也可以通过：</p>

<div class="highlight"><pre><code class="python">    <span class="n">ua</span> <span class="o">=</span> <span class="nb">unicode</span><span class="p">(</span><span class="s">&quot;我是123&quot;</span><span class="p">,</span> <span class="s">&quot;utf-8&quot;</span><span class="p">)</span>
</code></pre></div>

<p>或者是</p>

<div class="highlight"><pre><code class="python">    <span class="n">ua</span> <span class="o">=</span> <span class="s">u&quot;我是123&quot;</span>
</code></pre></div>

<p>得到同样的unicode。可以看到ua的长度为5，因为在unicode中不管是汉字还是字母或者是数字，
都当作同样的字符来进行处理，这样一个unicode的长度就是所有字符的个数，而不管这些字符是中文
汉字还是英文字符。这样的好处就在于能够很好地定位到一个具体的字符，字符串的截取以及正则表达式
匹配等操作都十分方便。所以推荐在处理包含中文的字符串时，先把这个字符串转化为unicode，然后再
进行操作，操作完以后再encode成字符串。</p>

<p>关于中文编码就很浅显地谈到这里，希望能给大家带来帮助，有什么问题可以在留言中和我讨论。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[最近的总结与感悟]]></title>
    <link href="http://chouqin.github.io/blog/2012/10/27/feeling/"/>
    <updated>2012-10-27T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/10/27/feeling</id>
    <content type="html"><![CDATA[<h2>来由</h2>

<p>这段时间真的很忙，忙得都没时间好好看书，好好写博客。</p>

<p>每天都要上班，还要忙着保研的各种事情，有时还在保研和直接工作中纠结，
导致一有一点空闲时间，就什么事情也没想干了。</p>

<p>还好，现在这些事情也终于告一段落，也不用再去纠结什么了，终于可以静下心来
去做自己喜欢做的事，踏踏实实地学习某些东西了。</p>

<p>但是总结一番还是有点必要的，不然这些日子的纠结不是白费了吗。</p>

<!--more-->


<h2>我为什么选择读研</h2>

<p>其实这个星期的前两天还在纠结当中，可是就好像砸中牛顿的那个苹果一样，
某种东西突然在我的头脑中闪现，让我顿悟，这个东西就是：梦想。</p>

<p>梦想，别扯淡了，这年头谁还看中这个。</p>

<p>我看中，我认为一个人一旦失去了梦想，活着也就没有什么意思了。
能支持一个人不断向前，不断超越自己的动力，也只有梦想。</p>

<p>我的梦想又是什么呢？很简单，在自己所在的领域有所建树，然后把
这个领域的技术能够向前推动一点，哪怕只是一点。而这个简单的梦想，
仍需要很多的努力才能实现，我的希望是能够一直在这个努力的过程中，
不要因为其他的东西的干扰而偏离了梦想。</p>

<p>而我差点因为微软的offer而偏离，极高的工资，舒适的工作环境，做的却
不是自己喜欢做的事。我明白，相对于其他在微软实习或者工作的人来说，
我还是相差太远。他们都是计算机竞赛的佼佼者，身上顶着各种光环，在计算机方面的积累比我
多了好几年，单就他们做过的题，我可能一辈子都来不及做完。我现在的学的东西也不是很扎实，
什么都知道一点，可都不精，如果再在微软待下去，或许就会沉浸在这种安逸的生活中，无法再
往一个更高的方向发展了。对于正值奋斗年华的我来说，过分的安乐真的不是什么好事。
而且在微软做的不是我喜欢做的事，要想突破感觉还是太难了。</p>

<p>那为什么不把工作当成白天的事，然后空闲时间去做自己喜欢做的事呢？我也考虑过这个问题，
最后发现这很难成功。因为这样每天最多能花两个小时在自己喜欢做的事情上面，而同时可能会
有各种事情打乱你的计划，想对于正式工作的每天八小时，这其中的差距可想而知。在互联网这样一个
高速发展的行业，低速成长是很容易被淘汰的，这样的过程，最多持续半年，我想就会终止，然后渐渐地
开始沦落为毫无激情的上班族。能够通过用这种方式坚持的，至少在中国我还没有听说过。</p>

<p>所以，我还需要很多的积累，扎实地磨练技术，同时更加开阔自己的眼界，而这些，通过研究生的三年，能够做到。</p>

<h2>对自己目前的定位</h2>

<p>总的来说，就是接触了很多的东西，但没有什么谈得上精通。</p>

<h3>语言</h3>

<p>语言确实用过很多，上过两个学期的C++课程，用C++写了数据结构的作业和USACO上的一些题，对于C++，应该算是最
熟悉的语言之一了吧，它的语法，还有很多相关的概念，包括虚函数，多态等等，都已经掌握了。可是不能算精通，对于它
的掌握仅仅局限于课堂，没用过STL,看过的书也就只有《C++ Primer》一本（教材除外），也没用它开发过大型的项目，对于
C++这样一门庞大的语言来说，这些还远远不够。</p>

<p>关于C，也就用它写过操作系统的大作业，对于Unix环境下的C编程有一定的了解，现在如果要用C写一个大型的项目的话，
应该也没有什么问题，但如果要称得上是精通，还需要大量的练习才行。</p>

<p>关于php，python，现在在上班的时候用得比较多，也正在处于一个水平稳步上升的阶段，我想经过一年的积累，这两门语言应该
是能够相当熟练，甚至是精通。</p>

<p>关于javascript，CSS(如果它也算语言的话)，基本的语法也都知道，可是积累还远远不够，特别是javascript，这门上手容易，精通确
很难的语言，因为工作主要偏后端，所以熟练程度还是不够。</p>

<p>关于C#，用它做过几个项目，用了WPF,ASP.NET，感觉C#这门语言还是比较容易上手的，写起代码来也很方便，配合上VS这个强大的IDE，
开发还是挺快的。我对它的了解还比较基础，至于它的反射，Delegation，Event等等东西，只是清楚概念，没有实际使用过。</p>

<p>另外，我上过程序设计语言这门课程，在这门课程中，我接触了大量的语言，也用这些语言写过程序。
使用过Java，Perl,Scheme,Haskell,Prolog这些语言。值得一提的是，scheme和prolog我都写过好几个程序，
虽然这两门语言都比较奇怪，但是写程序时确实能够开阔思路，还是两门比较有趣的语言，我比较喜欢。</p>

<p>对于“语言之争”，我没有特别的看法，我也没有特别的感觉说只用某一门语言或者只喜欢某一种语言。我觉得在不同的领域，
不同的场景，可能有些语言比另外一些语言要适合一些，比如说开发系统级别的应用程序，对执行效率要求比较高，这样，
C或者C++可能要适合一些，又比如一些做一些自动事情的脚本，可能python或者php用起来更加方便一些。每个语言都有它的
优点，对于语言我还是没有什么挑剔。</p>

<h3>专业基础知识</h3>

<p>对于专业知识，大部分都只限于课程，都是通过教材来了解，虽然这些教材都是国外的经典教材，
可是我觉得我们利用的还是太少了，大家都平时没怎么认真学习，然后到了考试，老师会给出几个
重点，然后大家根据这几个重点复习，应付考试而已。这些经典的教材，又岂是短短的这几天能够
掌握的？而我也不过是把这几天的时间分配到了整个学期而已，也就是说，我会跟着老师的上课进度，
把这些教材看一遍，看得有多深入，浅尝辄止罢了，粗粗地过完内容，然后总结一下了事。掌握得不是很扎实，
导致成绩也不是很好。专业基础课中，掌握得比较扎实的应该算操作系统和编译原理了吧，因为这两门课都做过
课程设计，多多少少需要了解一些东西。另外数据库也算把教材看得比较透彻的一门课，虽然考试成绩不咋的。</p>

<h3>算法</h3>

<p>只是知道常见几种算法:贪心法，分治法，动态规划。数据结构了解了：数，堆，哈希表，图，以及图的遍历，
最小生成树，最短路径。对于算法来说，和那些比较厉害的人的差距就在于：练习不够。别人能够做到各种算法
烂熟于胸，看到某类问题立刻想到相关的算法，因为什么，就是练习了那么多，一个问题做上10几遍，怎么能不熟。
所以在算法方面，我还得勤加练习，不然只能维持在现在的，看上去都会的水平。说现在找工作只看算法有点绝对，但
只要算法好想找任何工作是绝对没有问题的，各种经历告诉我这个观点的正确性。另外，在此提醒自己，《算法导论》
一定要坚持看完了，给自己下定一个决心吧。</p>

<h3>技术之外</h3>

<p>首先是表达能力有待增强，把自己清楚的东西讲到让别人也清楚这确实是一种艺术。写博客是一种很好的锻炼自己表达
能力的手段，所以我会经常把自己对技术的感悟通过写博客的方式表达出来，同时也分享了东西给大家。</p>

<p>其次是提高英语的口语能力，多说，多听。</p>

<h2>规划</h2>

<p>在研究生的三年中，我需要达到下面的目标：</p>

<ul>
<li>执行力：下定决心去做好每一件事</li>
<li>了解自己研究方向：数据挖掘的方方面面，达到一个比较高的级别</li>
<li>算法能力再提升一个档次，把算法从劣势转为优势</li>
<li>对于大数据，云计算，虚拟化有比较深入的了解</li>
</ul>


<p>目标并不多，也不是很远大，但仍然需要认真地去执行。</p>

<p>另外，希望在这将近一年的实习生涯中达到下面的目标：</p>

<ul>
<li>精通php,python</li>
<li>对mysql性能优化有完整的理解和解决方案</li>
</ul>


<h2>结语</h2>

<p>前方路已经越发明朗了，接下来就是坚定地走下去。</p>
]]></content>
  </entry>
  
</feed>
