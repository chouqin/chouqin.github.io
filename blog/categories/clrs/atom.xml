<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: clrs | Chouqin's Blog]]></title>
  <link href="http://chouqin.github.io/blog/categories/clrs/atom.xml" rel="self"/>
  <link href="http://chouqin.github.io/"/>
  <updated>2013-10-21T21:38:47+08:00</updated>
  <id>http://chouqin.github.io/</id>
  <author>
    <name><![CDATA[chouqin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[最短路径与最大流]]></title>
    <link href="http://chouqin.github.io/blog/2013/01/06/clrs-24-26/"/>
    <updated>2013-01-06T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2013/01/06/clrs-24-26</id>
    <content type="html"><![CDATA[<h2 id="section">最短路径</h2>

<p>在最短路径问题中，
希望在一个图中找出从一个节点到另外一个节点的最短路径，
可能要找出从某一个特定节点到其他节点的最短路径，
也可能是找出所有节点对之间的最短路径，
图中边的权重可能为负值，甚至包含负的回路，
因此，在不同的情况下，有不同的算法适合求解问题，
关于求解所有节点之间的最短路径问题已经在动态规划时详细地解释过Floyd算法，
现在就谈谈两个处理单源最短路径的算法, Dijkstra算法和Bellman-Ford算法。</p>

<h3 id="dijkstra">Dijkstra算法</h3>

<p>Dijkstra算法用于求解所有边的权重为非负值时的单源最短路径问题，
它与Prim算法很相似，利用一个集合S保存已经求出最短路径的节点集合，
开始是S只包含源节点s,
每次从V-S中挑选出一个距离S中节点最近的节点u放入S，同时正确地设置u的邻居节点的路径长度，
直到S为V。</p>

<p>对于Dijkstra算法的正确性，只需要递归地证明下面的性质成立：</p>

<pre><code>当节点u被加入到S时，u到s的最短路径已经被正确的设置, 而且u到s的最短路径上的前趋节点w已经被添加进S。
</code></pre>

<ul>
  <li>初始化：一开始时，这个性质显然成立</li>
  <li>保持：假设当u被添加到S时，u到s的最短路径已经被正确的设置，对于u的任何一个邻接节点v，
如果s到v的最短路径是<script type="math/tex"> s \xrightarrow{p} u \xrightarrow{} v </script>，那么s到v的路径能够被正确的设置，
而且从v到s最短路径上的前趋节点u已经被添加进S, 这样当v被添加进S时，上述的性质都是能够保持的。</li>
</ul>

<h3 id="bellman-ford">Bellman-Ford算法</h3>

<p>Bellman-Ford算法用于求解权重可以为负值时的单源最短路径问题，
而且它还可以用于判断图中是否存在s可达的负的回路。
Bellman-Ford的执行过程就是运行|V|-1次更新操作，
每次更新操作遍历每一条边(u, v)更新dist[v]，伪代码如下：</p>

<p><div class="highlight"><pre><code class="pascal">    <span class="k">procedure</span> <span class="nf">update</span><span class="p">((</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">))</span><span class="o">:</span>
        <span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">dist</span><span class="p">[</span><span class="n">v</span><span class="p">]</span><span class="o">,</span> <span class="n">dist</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">+</span><span class="n">w</span><span class="p">(</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">))</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>

<span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">k</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="err">|</span><span class="n">V</span><span class="err">|</span><span class="o">-</span><span class="mi">1</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">in</span> <span class="n">E</span><span class="o">:</span>
        <span class="n">update</span><span class="p">((</span><span class="n">u</span><span class="o">,</span> <span class="n">v</span><span class="p">))</span> 
</code></pre></div>
</code></pre>

<!--more-->

<p>要证明这个算法的正确性，先说明它的两个性质：</p>

<ol>
  <li>如果调用update((u, v))时，dist[u]已经被正确的设置，
那么dist[v]也将会被正确地设置。</li>
  <li>如果dist[v]已经被正确的设置，
调用任意的update((u, v))都不会改变dist[v]的值，
也就是说多次地执行update是安全的。</li>
</ol>

<p>有了这个性质，对于任意节点v, 
通过对v到s的最短路径的长度做一个简单的归纳，
就能够说明当算法结束时，dist[v]能够被正确的设置。</p>

<p>在我看来，Bellman-Ford算法的价值并不在于这个算法本身，
它给出求解一些问题的普遍思路。对于有着相互依赖的k个元素<script type="math/tex"> \{n_1, n_2, ..., n_k\} </script>,
如果它们之间的关系很复杂，比如如果<script type="math/tex"> n_1 </script>和<script type="math/tex"> n_2 </script>之间有关系，那么<script type="math/tex"> n_1 </script>和<script type="math/tex"> n_3 </script>之间可能就会有关系，
而且这种关系可能构成一个循环，如果每次找到了两个元素的关系就去更新其他元素的关系就会陷入一个死循环，
但如果利用Bellman-Ford算法的思想，就能明白对于任意两个元素<script type="math/tex"> n_i </script>和<script type="math/tex"> n_j </script>，它们之间的关系最多隔着k-2个中间元素，
第1次更新的时候可以把没有隔中间元素的两个元素的关系确立好，第2次更新的时候可以把只隔1个元素的两个元素确定好，
依次类推，当k-1次更新的时候，所有元素的关系都能确定好。就不需要一确定两个元素的关系就去考虑要不要更新相关的元素，
思路显得清晰。</p>

<h2 id="section-1">最大流问题</h2>

<p>最大流问题是图论中一类很重要的问题，因为它和线性规划也有着很强的关联，
所以它的应用也十分广泛。在最大流问题中，对于图G，有两个特殊的节点s,t，
它的任何一条边都有一个容量c，对每条边的一个特定赋值称为一个流f，
流必须满足两个性质：</p>

<ol>
  <li>对于任意一条边e，<script type="math/tex"> 0 \leq f_e \leq c_e </script></li>
  <li>对于除了s,t之外的任意节点u, 入流等于出流, 即: <script type="math/tex"> \sum\limits_{(w,u) \in E} f_{wu} = \sum\limits_{(u, z) \in E} f_{uz} </script></li>
</ol>

<p>最大流是想找出一个f，使得<script type="math/tex"> \sum\limits_{s,u \in E} f_{su} </script>最大。</p>

<p>求解最大流的算法非常直观：</p>

<ol>
  <li>从零流量开始</li>
  <li>每次从f的残留网络中选择一条从s到t的路径，在这条路径上增加流，
重复这个过程直到残留网络中不存在从s到t的路径为止</li>
</ol>

<p>要证明这个算法的正确性，需要了解图的(s,t)-割，
以及割的容量，一个图的(s,t)-割把图分成互不交叉的两个组L和R,
使得s在L中，t在R中。该割的容量就是横跨L和R两个集合的所有边的容量之和，
有如下性质成立：</p>

<p>对于任意流f，任意(s,t)-割(L, R), <script type="math/tex"> size(f) \leq capacity(L, R) </script></p>

<p>说明割的容量是任何流的大小的上限。</p>

<p>下面说明最大流算法的正确性。当程序终止时，残留网络<script type="math/tex"> G^f </script>中不存在由s到t的路径，
那么令L为<script type="math/tex"> G^f </script>中s可达的所有节点，R为其他的节点，那么此时size(f) = capacity(L, R)。
这是因为对于任何从L到R的边e, 有</p>

<script type="math/tex; mode=display"> 
f_e = c_e 且 f_{e'} = 0 其中f_{e'}表示从e的反向流量 
</script>

<p>因为这其中任何一个违反都会导致e的终止节点在<script type="math/tex"> G^f </script>中从s可达。所以此时size(f) = capacity(L, R)。
所以对于任意流f’, 都有<script type="math/tex"> size(f') \leq size(f) </script>，意味这f是一个最大流。</p>

<p>关于最大流还有两个很重要的东西：</p>

<ol>
  <li>如果采用BFS在残留网络中寻找从s到t的最短路径，会使得迭代的次数不会超过O(VE)</li>
  <li>最大流可用于二部图的匹配，关键是要证明容量为整数的图中找出的最大流给任意边的赋值都是整数。</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[图的基本算法]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/30/clrs-22-23/"/>
    <updated>2012-12-30T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/30/clrs-22-23</id>
    <content type="html"><![CDATA[<h2 id="section">广度优先遍历</h2>

<p>对于广度优先遍历，在每次遍历时，都试图把同一个级别的所有节点先遍历，
再遍历下一个级别的节点。它的实现方式是通过一个队列保存需要去遍历的节点，
在每次遍历到一个节点时，都把它的邻接节点放入队列（如果这个节点没有被遍历过的话）等待着被遍历，
这样能保证更深层次的节点会遍历在它的任何邻接节点的后面，因为它的邻接节点更先进入队列。</p>

<p>广度优先遍历可以用来求解无权图中的单源最短路径问题，
对于节点s，在它上面执行一次广度优先遍历就能求出各个节点和s相距的节点数，
这也就是它们到达节点s所需的距离。对于广度优先遍历，
算法首先会发现和s距离为k的所有节点，然后再去发现和s距离为k+1的节点。
这其实和Dijkstra算法是采用同样的思想，先找出和s距离更近的节点，
在这基础上再找出更远的节点，因为这样的话当确定好了更远节点的路径时，
就不需要反过来再去修改更近节点的路径，因为通过更远节点的路径肯定没有先前的那条路径好。</p>

<h2 id="section-1">深度优先遍历</h2>

<p>深度优先遍历与广度优先遍历不一样，在遍历到每一个节点时，尽量往更深节点去遍历，
遍历完之后再考虑同一个级别的节点。它的实现方式不需要队列，
直接通过递归函数就可以完成这个步骤。每次遍历到一个节点时，先把当前的节点设为已经遍历过，
然后在它的邻接节点上执行递归遍历的函数（没有遍历过的邻接节点）。如果对整个图进行深度优先遍历，
首先会选定一个节点，然后在它上面执行深度优先遍历，如果遍历到了所有节点就停止，
否则选择另一个没有遍历到的节点重复这个过程直至所有的节点都遍历完。在深度优先搜索的过程中，
会形成一棵棵以挑选出的节点为根的深度优先树组成的深度优先搜索森林。</p>

<p>在深度优先遍历遍历到每一个节点时，可以利用一个计数器记录遍历节点开始时的时间和结束时的时间，
依据这个时间来确定节点遍历的相对顺序。设节点v遍历的开始时间为d[v]，结束时间为f[v]，
那么时间区间[d[v], f[v]]就代表了这个节点处在遍历过程中的时间，更具体的说，
是节点处在递归函数的栈中的时间。因此对于任何节点u, v，
[d[v], f[v]]和[d[u]， f[u]]只能是不相交或者是一个包含另一个。
（通过栈可能更好理解一点）</p>

<p>利用这样的计数器，可以完成对图的很多操作，比如说拓扑排序和有向图的连通性检查。</p>

<!--more-->

<h3 id="section-2">拓扑排序</h3>

<p>拓扑排序是对于有向无环图的节点进行一次排序，使得对于任意的节点u, v，如果u有一条边到v，
那么u一定出现在v的前面。</p>

<p>利用深度优先遍历得到的f值，可以很容易地对节点进行拓扑排序：按f值的大小进行排序，
具有较大f值的节点排在前面。</p>

<p>可以利用f值进行排序是通过如下性质保证的：</p>

<pre><code>如果f[u] &gt; f[v]，那么一定没有从v到u的边。
</code></pre>

<p>要证明这个性质，可以考虑f[u] &gt; f[v]的两种情况：</p>

<ul>
  <li>
    <p>[d[u], f[u]]与[d[v], f[v]]不相交且在其之后，那么此时遍历完v之后，
u还没开始遍历，此时不可能有v到u的边，因为如果有的话那么遍历v完成之前就会遍历u，矛盾。</p>
  </li>
  <li>
    <p>[d[u], f[u]]包含[d[v], f[v]]，那么说明在遍历u结束之前遍历到了v，这样就存在一条从u到v的路径，
如果有v到u的边，就会形成一个环，与无环图矛盾。</p>
  </li>
</ul>

<h3 id="section-3">有向图的强连通分量</h3>

<p>对于处于有向图的同一个强连通分量的任意节点u, v，存在一条路径从u到v，
同时也存在一条路径从v到u。显然任意两个连通分量不能相交，目的是找出有向图中的所有强连通分量，
注意单个节点可以作为一个强连通分量。</p>

<p>利用深度优先遍历，可以确定有向图的所有强连通分量，方法如下：</p>

<ol>
  <li>首先通过一次深度优先遍历确定所有节点的f值</li>
  <li>按f值倒序深度优先遍历原图的反图，在得到的深度优先搜索森林中，
处于同一棵深度优先搜索树中的节点组成一个强连通分量。</li>
</ol>

<p>这个算法的正确性由下面的性质保证：</p>

<pre><code>对于任意节点u,v，u,v处于同一强连通分量当且仅当它们在第2步中处于同一棵深度优先搜索树。
</code></pre>

<p>证明这个性质，不妨设f[u] &gt; f[v]:</p>

<ul>
  <li>左边到右边, 如果u，v处于同一强连通分量，那么在反图中一定存在从u到v的路径，
那么遍历到u时一定会沿着这条路径遍历到v，保证了u，v在同一棵深度优先搜索树中。</li>
  <li>
    <p>右边到左边，如果u, v在同一棵深度优先搜索树中，说明在反图中有一条u到v的路径，
也就是原图有一条从v到u的路径，只需要证明原图有一条从u到v的路径即可。
和证明拓扑排序一样，f[u] &gt; f[v]只有两种情况：</p>

    <ul>
      <li>
        <p>[d[u], f[u]]与[d[v], f[v]]不相交且在其之后，那么此时遍历完v之后，
  u还没开始遍历，由于存在从v到u的路径，那么遍历v完成之前就会遍历u，所以这种情况不可能。</p>
      </li>
      <li>
        <p>[d[u], f[u]]包含[d[v], f[v]]，这种情况是唯一可能的情况，此时存在一条从u到v的路径</p>
      </li>
    </ul>
  </li>
</ul>

<p>因此证明结束。</p>

<h2 id="section-4">最小生成树</h2>

<p>在最小生成树问题中，给定一个无向连通图G = (V, E)，从E中挑出权值和最小的|V| - 1条边，
使得这些节点依旧连通。</p>

<p>有两种算法求解最小生成树问题，而且两种算法都是贪心算法，都满足贪心算法的贪心选择性质。</p>

<h3 id="kruskal">Kruskal算法</h3>

<p>在Kruskal算法中，每次都试图挑选权值最小的一条边，
但要保证添加这条边不会导致存在回路，如果会导致回路，则不考虑这条边。</p>

<p>可以很简单的通过修改最优解的方式证明这个算法的贪心选择性质，从而证明算法的正确性。</p>

<h3 id="prim">Prim算法</h3>

<p>在Prim算法中，利用一个不断增长的集合S，这个集合原来只包含一个元素，
然后每次往集合S中添加一个节点，这个节点是V-S中距离S中任意节点最近的节点，
在把这个节点添加到S的同时，把这个节点和S中与这个节点最近的节点组成的边添加为最小生成树的边。
显然，Prim算法能够保证每次添加一条边时，都不会导致回路。</p>

<p>同样可以很简单的通过修改最优解的方式证明这个算法的贪心选择性质，从而证明算法的正确性。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[贪心算法和B树]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/18/clrs-1618/"/>
    <updated>2012-12-18T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/18/clrs-1618</id>
    <content type="html"><![CDATA[<h2 id="section">贪心算法</h2>
<p>动态规划是一种解决问题的通用方法，
在求解最优化问题的时候，
动态规划能够综合考虑到各种情况然后做出最优的选择。
可是，对于一些特殊的问题，
在从子问题中做出选择时，可以不用考虑所有的子问题，
而只需要考虑一个子问题，
因为选择这个子问题一定可以达到一个最优解，
在这种情况下，就可以采用贪心算法来解决。
贪心算法的好处在于，不需要考虑所有的子问题，
只需要考虑一种情况，这时求解的子问题的数目就减少了，
同时，可以采用一种自顶向下的方法解决问题，
逐步地把问题转化为更小的子问题，直到可以轻易解决。</p>

<h3 id="section-1">从动态规划到贪心</h3>
<p>书上给出了一个这样的例子来说明从动态规划算法转化到贪心算法。</p>

<p>有n个活动组成集合<script type="math/tex"> S = \{a_1, a_2, ..., a_n\} </script>，它们需要占用同一个资源，
这个资源在同一个时间只能被一个活动占用，每一个活动<script type="math/tex"> a_i </script>使用资源的起始时间和结束时间分别为
<script type="math/tex"> s_n, f_n </script>，如果区间<script type="math/tex"> [s_i, f_i) </script>与区间<script type="math/tex"> [s_j, f_j) </script>不重叠，
就称活动<script type="math/tex"> a_i </script>与活动<script type="math/tex"> a_j </script>是兼容的，求S的一个由互相兼容的活动组成的最大子集，
假设活动已经按结束时间排好序。</p>

<p>对于这个问题，可以定义如下子问题<script type="math/tex"> S_{ij} </script>，
表示从S的子集<script type="math/tex"> S_{ij} </script>中得到的最大兼容子集，
其中<script type="math/tex">% &lt;![CDATA[
 S_{ij} = \{ a_k \in S: s_k \geq f_i and f_k < s_j \} %]]&gt;</script>，
也就是说，<script type="math/tex"> S_{ij} </script>是由所有在<script type="math/tex"> a_i </script>结束之后开始，
在<script type="math/tex"> a_j </script>开始之前结束的活动组成的集合。
通过定义这样一个子问题，
就可以很容易地得出如下递推公式，</p>

<script type="math/tex; mode=display">
A_{ij} = A_{ik} \bigcup \{a_k\} \bigcup A_{kj}, 其中A_{ij}表示子问题S_{ij}的解
</script>

<p>从而利用动态规划解决这个问题。</p>

<p>然而，动态规划并不是一个最优的解法，
因为要求解的子问题的个数为<script type="math/tex"> O(n^2) </script>个，
而且求解每个子问题时选择的个数也有<script type="math/tex"> O(n) </script>个，
这就导致了通过动态规划求解问题所需的复杂度为<script type="math/tex"> O(n^3) </script>。</p>

<p>如果采用贪心的算法，每次通过选取<script type="math/tex"> S_{ij} </script>中具有最早结束时间的活动<script type="math/tex"> a_m </script>作为划分元素的话，
那么就可以通过</p>

<script type="math/tex; mode=display">
A_{ij} = A_{im} \bigcup \{a_m\} \bigcup A_{mj}
</script>

<p>得到一个最优的解，而不用考虑其它元素作为划分元素时的子问题。</p>

<!--more-->

<p>定义函数递归函数RECURSIVE-ACTIVITY-SELECTOR(S, f, i, n)求取子问题<script type="math/tex"> S_{i(n+1)} </script>的解，
伪代码如下：</p>

<pre><code>def RECURSIVE-ACTIVITY-SELECTOR(s, f, i, n)
    m := i + 1
    while m &lt;= n and s[m] &lt; f[i]
        do m := m + 1
    if m &lt;= n
        then return {a[m]} union RECURSIVE-ACTIVITY-SELECTOR(s, f, m, n)
        else return EMPTY_SET
</code></pre>

<p>求解原问题就可以通过调用RECURSIVE-ACTIVITY-SELECTOR(s, f, 0, n)来完成。
从代码中可以看出，每个活动都只被检查过一次，如果函数调用的时间可以忽略不计的话(
这个递归地算法可以通过迭代来实现，所以算法本身可以不用考虑这个问题)，
那么整个算法的时间复杂度为<script type="math/tex"> \Theta(n) </script>。相比于动态规划，效率要提高很多。</p>

<h4 id="section-2">关于这个问题的几点解释</h4>

<ol>
  <li>
    <p>关于为什么可以将<script type="math/tex"> a_m </script>选作分界元素需要说明两点：</p>

    <ol>
      <li>
        <p>一定有某一个最大兼容子集包含元素<script type="math/tex"> a_m </script>，也就是说，
 如果要挑选出一些元素组成最大兼容子集，
 那么先把<script type="math/tex"> a_m </script>选中放入这个集合中肯定能导致一个最优解。
 关于这种命题的证明，普遍的方式是假设有一个最优解没有包含这个元素，
 那么把这个元素和某个元素替换后会导致一个不会比原来差的解。
 书上也是采取这样的证明方式。以后在证明最小生成树的贪心算法时也是采取这样的方式。</p>
      </li>
      <li>
        <p>把<script type="math/tex"> a_m </script>放入最大兼容子集后，这个最大兼容子集的其余元素一定是子问题<script type="math/tex"> S_{mj} </script>的一个解。
 这个比较好证明，只需要证明对于任意和<script type="math/tex"> a_m </script>兼容的元素<script type="math/tex"> a_k </script>, 一定有
 <script type="math/tex"> s_k \geq f_m </script>即可。</p>
      </li>
    </ol>

    <p>有了这两点，就能得出：</p>

<script type="math/tex; mode=display">
 A_{ij} = \{a_m\} \bigcup A_{mj} = A_{im} \bigcup \{a_m\} \bigcup A_{mj}, 第二个等式成立是因为A_{im} = \emptyset
 </script>

    <p>也就是将<script type="math/tex"> a_m </script>选作分界元素, 同时可以不需要求解<script type="math/tex"> S_{im} </script>。</p>
  </li>
  <li>
    <p>需要注意的是<script type="math/tex"> S_{ij} \neq \{a_{i+1}, a_{i+2}, ..., a_{j-1} \}</script>，
这个等式只有在<script type="math/tex"> i=0, j=n+1 </script>时成立，
但是从代码中我们可以看到，
在调用RECURSIVE-ACTIVITY-SELECTOR(S, f, i, n)时，
此时可能被添加进最大兼容子集的元素集合是<script type="math/tex"> \{a_{i+1}, a_{i+2}, ..., a_{n} \} </script>,
而不是<script type="math/tex"> S_{i(n+1)} </script>，然而这并不会导致什么问题，因为在选取<script type="math/tex"> a_m </script>时，已经过滤掉了开始时间小于<script type="math/tex"> f_i </script>的元素，
随着迭代次数的加深，那些开始时间小于<script type="math/tex"> f_i </script>的元素也会被过滤掉，因为开始时间小于<script type="math/tex"> f_i </script>也一定会小于<script type="math/tex"> f_m </script>，
在更深的迭代时同样会被过滤。</p>

    <p>采取这样的方式实现代码能够降低时间和空间的复杂度，因为如果每次求解子问题时都需要求出<script type="math/tex"> S_{ij} </script>这个集合的话，
 需要<script type="math/tex"> O(n) </script>的时间来求出，同时也需要一个数组来保存这个子集，显然不如书上的这个实现简单。</p>
  </li>
  <li>
    <p>这个问题如果用动态规划的话可以采用另外一种思路，
令c[i]表示集合<script type="math/tex"> \{a_1, ..., a_i \} </script>中，包含元素<script type="math/tex"> a[i] </script>的最大兼容子集的元素个数，
那么有如下递归公式成立</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

 c[i] = \max \{\max_{j < i}_{s_i > f_j } \{c[j] + 1\}, 1 \}
  %]]&gt;</script>

    <p>利用这个递归公式求解的话，时间复杂度可以降到<script type="math/tex"> O(n^2) </script>。</p>
  </li>
</ol>

<h3 id="section-3">贪心算法的基本条件</h3>
<p>总的来说，贪心算法比动态规划效率要高，实现起来也相对简单一些，
同时也是一般人比较容易想到的算法。但是这并不意味着它比较简单，
因为并不是所有的问题都能够使用贪心法得到解决，
它比动态规划有更多的限制条件，
它必须满足两个基本条件：</p>

<ol>
  <li>
    <p>贪心选择性质：一个全局最优解可以通过局部最有解得到。
这是贪心算法与动态规划的不同之处。
证明贪心选择性质一般用上面提到的修改最优解，
使其包含局部最优解，
然后得到一个不差于最优解的解，就能证明。</p>
  </li>
  <li>
    <p>最优子结构，这和动态规划一样，可以通过”剪切，粘贴”的方法证明。</p>
  </li>
</ol>

<h3 id="section-4">哈夫曼编码</h3>

<p>贪心算法可以用于求解很多问题，
在图算法中的最小生成树算法，
单源最短路径算法等都是利用贪心法解决，
关于这些算法，我在图算法时再详细阐述，
现在说另外一个比较典型的贪心算法的例子。</p>

<p>哈夫曼编码，这个基本是任何算法书都需要提及的使用贪心算法的例子。
有n个不同字符，知道它们的出现的出现次数，
如何设计一个前缀编码使得整个文件的编码最短。利用一个优先级队列，
每次把队列的频率最小的两个元素出队，组成一个新的元素然后入队，直到队列只剩一个元素为止。
这个算法贪心选择性质的证明也比较简单。</p>

<h3 id="section-5">另一种贪心算法</h3>

<p>前面说到的贪心算法都是用于求解最优化问题，
在应用贪心算法的时候，看问题是否具备贪心选择的性质，
如果具备，就通过贪心法求解。
有另外一种问题也可以归入贪心算法的范畴，这样的问题不是求最优解，
而只是需要正确地的解决某一个问题，在这种问题中，没有最优解可言，
只是求出问题的正确的解就可以。在解决问题的过程中，可能会有很多选择，
类似于要不要选择某个元素，要不要把某个变量设成True，
这许多的选择组合起来就会导致解有很多种可能性，
目的就在于从这许多的解中找出满足指定条件的一个解，如果存在的话。
这就类似于走迷宫，有许多的分叉路口，就很多种走法，
从这些走法中找出一个能走到出口的就可以。</p>

<p>对于这些问题，暴力搜索每一种可能性显然不是一种好方法，
动态规划也可以用于解决这样的问题，
在解决一个问题时利用一个子问题是否满足条件来决定当前的问题是否满足条件。
而贪心算法在解决这种问题时采取了一种更加直观的想法: 必须要做某一个选择，
否则就是不满足条件的解。如果问题具有这样的性质，就可以很容易地选出一个解，
因此每次的选择都是唯一的，然后再看这个选择是否满足条件即可。如果满足条件，
那么就找到了一个解，如果不满足，那么就没有解，因为其他的解肯定不满足条件。
下面通过Horn公式来更详细的说明。</p>

<p>在Horn公式中，我们指定了一些布尔变量(比如x，y, z)必须满足的性质，通过两种公式给出:</p>

<ol>
  <li>蕴含式：在这种公式中，左边为合取范式，右边为单一变量, 所有变量必须不含否定，比如<script type="math/tex"> (z \bigwedge w)  \Longrightarrow u </script>
或者<script type="math/tex"> \Longrightarrow x </script>,
而<script type="math/tex"> (z \bigwedge \bar w)  \Longrightarrow u </script>就不是这种蕴含式</li>
  <li>完全由变量的否定组成的析取范式, 比如 <script type="math/tex"> (\bar u \bigvee \bar v \bigvee \bar y )</script>。</li>
</ol>

<p>问题是给定一个Horn公式，确定是否可以给公式中出现的变量赋予合适的布尔值，使所有的这些公式都能得到满足。
很显然，要满足蕴含式，需要要把一些变量设为True, 而要满足析取范式，需要把一些变量设为False。
对于每一个变量，赋值的方式都有两种，遍历所有的可能性显然是效率不高的。</p>

<p>贪心算法通过这样的思路来解决：</p>

<ol>
  <li>首先把变量都设为False，</li>
  <li>如果有蕴含式不满足，就把蕴含式右边的变量设成True，然后继续这个步骤直到所有的蕴含式都满足为止, 否则到步骤3。</li>
  <li>查看是否有析取范式不满足，如果全满足，那么就找到了一个解，否则，无解。</li>
</ol>

<p>说明两点：</p>

<ol>
  <li>
    <p>为什么这个算法是正确的。如果找到了一个解，显然是正确的。
如果没找到解，为什么就无解呢？因为前面的把变量设为True是“必须”的，
也就是说，一个变量被设为True，那么在任何正确的解中，它必须被设为True，
所有在这些必须的步骤都完成之后，如果不满足条件，也就没有解可以满足条件了。</p>
  </li>
  <li>
    <p>重复检查所有蕴含式是否满足的次数的不超过n+1次，其中n为变量的个数。
因为除了第一次检查，其余每一次检查都是因为前一次有变量被设为True，
(否则如果没有变量被设为True, 那么所有的蕴含式都满足，就不会再去检查了),
而变量被设为True的次数不超过n次，所以检查次数不超过n+1次，
这就保证了检查所有蕴含式是否满足并不是一个复杂度非常高的过程。</p>
  </li>
</ol>

<p>在这种贪心算法中，解决思路是找出那些必须要执行的步骤，一步一步，将问题简化，
最终解决。</p>

<h2 id="b">B树</h2>

<p>B树也是一种平衡地二叉查找树，类似于红黑树，
它也能够支持动态地插入，删除和查找数据。
B树主要用于保存数据到磁盘中，
比如很多数据库的索引就是通过B树进行保存。
由于磁盘的读取速度相对于内存要慢得多，
所以尽量地减少IO的次数显得非常重要，
B树也正是实现了这样的思想，B树的深度不会太深，
这样查找数据所需要遍历的节点数就会很少，
相应的IO次数也会减少。</p>

<p>在B树中，一个非根的节点至少包含t-1个关键字，
这样每一个非根的节点就至少有t个子女，这样一棵包含n个关键字的B树的高度h至多为
<script type="math/tex"> \log t \frac{n+1}{2} </script>。但是一个节点包含的关键字又不能太多，
一方面是因为一次IO只能读取指定数量的字节，
另一方面太多的关键字会导致定位一个关键字比较耗时，所以B树的每个节点包含至多2t-1个关键字。</p>

<p>这些性质能够保证B树查找的性能，但是在插入和删除的时候就需要维护这些性质。
具体表现在：</p>

<ul>
  <li>
    <p>当插入一个关键字到一个已经满了节点（包含2t-1个关键字），就需要把这个节点分裂成两个，
同时把这个节点中间关键字插入到它的父节点，这样可能会导致父节点的关键字超过2t-1，
所以需要一直向上到根来进行维护。</p>
  </li>
  <li>
    <p>当删除一个关键字时，会导致只有t-1个关键字的节点不满足性质，这时可以通过向它的兄弟“借”一个关键字，
如果兄弟包含至少t个关键字的话，否则，就和兄弟合并，然后从父节点删除一个关键字，
同样的，此时需要一直向上到根来进行维护。</p>
  </li>
</ul>

<p>书上在插入和删除节点的时候为了避免向上过滤来进行维护，
在遍历到某一个节点的时候，就把性质维护好，这样当一个节点遍历到的时候，
就能保证它的父节点不需要再去维护了。这样的方法，对于插入还好，
对于删除操作就显得有点复杂，考虑了好多种情况，
我觉得还是向上过滤进行维护比较好，并没有增加复杂度。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[红黑树扩充与动态规划]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/12/clrs-14-15/"/>
    <updated>2012-12-12T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/12/clrs-14-15</id>
    <content type="html"><![CDATA[<h2 id="section">红黑树的扩充</h2>

<p>由于红黑树这种结构很好的平衡性（树的高度不会很高），
对于动态变化的集合插入，查找，删除等操作的复杂度都比较低，
通过给它的节点增加一些其他的属性，
能够得到一些在特定情况下很有用的数据结构。</p>

<h3 id="section-1">扩充数据结构的四个步骤</h3>

<ol>
  <li>选择基础的数据结构</li>
  <li>确定需要给数据结构添加哪些信息，
这些信息可能被添加到每个节点中，也可能被添加作为整体数据结构的性质</li>
  <li>验证在数据结构的基本操作的过程中，这些信息可以被有效的维护，
这里的有效是指不会因为维护这些信息增加基础操作的复杂度</li>
  <li>利用这些信息提供一些有用的操作</li>
</ol>

<h3 id="section-2">通过扩充红黑树得到顺序统计</h3>

<p>通过给红黑树的每一个节点x附加属性size[x]，
表示以x为根的子树的节点个数，
可以通过递归确定一棵红黑树的第i小关键字的元素。
由于包含n个元素的红黑树的高度为<script type="math/tex"> O(\lg n) </script>，每次递归高度都会下降一层，
所以查找第i小关键字的时间复杂度为<script type="math/tex"> O(\lg n) </script>。</p>

<p>在第9章中，给出了获取n个元素的数组中第i个元素的<script type="math/tex"> \Theta(n) </script>的算法，
而一个包含n个元素的数组如果是有序的话，那么获取第i个元素的复杂度是<script type="math/tex"> O(1) </script>。
但是这种扩充的数据结构的好处在于它的动态性，它的插入和删除的时间复杂度也是<script type="math/tex"> O(\lg n) </script>，
而一个有序数组的插入和删除的复杂度是<script type="math/tex"> O(n) </script>。</p>

<h3 id="section-3">通过扩充红黑树得到区间树</h3>

<p>在区间树中，每一个节点x包含了一段区间int[x]，同时包含了一个max[x]，
表示以x为根的子树中所有区间的右端点的最大值，同时每一个节点的key[x] = low[int[x]]，
也就是说是把每一个节点所包含区间的左端点作为key。</p>

<p>区间树使得查找整个红黑树中与某一个区间i重合的区间变得十分容易，
可以如下递归实现：</p>

<ol>
  <li>如果当前节点为空，返回空节点</li>
  <li>如果区间i与当前节点的区间重合，返回当前节点</li>
  <li>如果区间i的左端点小于当前节点左儿子的max，递归查找左子树</li>
  <li>否则递归查找右子树</li>
</ol>

<p>情况1，2很自然，情况4也比较好理解，
因为如果i的左端点大于左儿子的max，它就大于那么对于左子树中所有节点的右端点，
左子树中一定不存在和区间i重合区间。情况3需要一定的思考，
因为如果i的左端点小于当前节点左儿子的max，并不能保证它一定不会与右子树中的区间重合，
所以如果只是递归查找左子树，如果左子树中有区间和i重合，那么能够返回正确结果
（因为只需要找到一个和i重合的区间就可以），如果左子树中没有区间与i重合，
那右子树中可能会有区间与i重合，导致没有返回正确的结果。情况是这样的吗？</p>

<p>不是这样的，下面可以证明在情况3时如果左子树中没有找到与i重合的区间，
那么在右子树中也一定不存在和i重合的区间。</p>

<p>假设左儿子的max来自于high[j]（也就是说，是左子树中区间j的右端点)，
那么一定有</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
high[i] < low[j]
 %]]&gt;</script>

<p>否则区间i和j重合，对于右子树中的任意区间k，一定有</p>

<script type="math/tex; mode=display"> 
low[k] \geq low[j] > high[i] \text{第一个不等式成立是根据红黑树关键字的性质}
</script>

<p>所以k与i不重合。</p>

<h2 id="section-4">动态规划</h2>

<!--more-->

<p>动态规划主要用于求解最优化问题，
它的基本思想是通过把子问题的结果保存起来，
这样当遇到一个更大的问题时，如果它需要解决子问题，
那么可以直接使用保存好的子问题的结果，而不用再去重复解决子问题。</p>

<h3 id="section-5">动态规划适用的基本条件</h3>

<p>使用动态规划必须要满足两个基本的条件：</p>

<ol>
  <li>最优子结构。一个问题的最优解包含子问题的最优解。
通常可以通过”剪切-粘贴”的方法证明最优子结构，也就是说，
假设一个问题的最优解没有包含子问题的最优解，
那么把相应的子问题的解替换成最优解将得到一个更好的解，
从而得出矛盾。</li>
  <li>重叠子问题。如果没有大量的重叠子问题，
那么直接通过递归求解子问题就可以，
动态规划相对于递归的好处也就在于不用重复去计算重叠的子问题，
从而节省了时间。</li>
</ol>

<h3 id="section-6">动态规划解题的基本思路</h3>

<p>在确定了一个问题适合采用动态规划进行解决之后，
仍然需要考虑几个问题。最主要的问题就是如何将问题利用更小的子问题来进行解决，
此时的思路是通过把原来的问题通过转化变成更小的子问题，
利用合适的转化可以把一个问题缩小成一个更小的子问题，比如最长递增子序列问题，
求以元素n结尾的最长递增子序列的长度，
可以转化为求以比n小的排在n前面的某个元素结尾的最长递增子序列的长度。
通过转化之后问题就缩小了。</p>

<p>将问题转换成子问题之后，必须要知道如何通过子问题的解得到原问题的解，
也就是所谓的递推公式，
比如上述问题，知道n之前的某个小于n元素的最长子序列的长度之后，
n的最长子序列的长度就是这个长度加1。</p>

<p>一个问题可能转化成多个子问题，比如说上面的问题，
比n小的排在n之前的元素可能有多个，这时，就需要从多个子问题之间做出选择。
这个选择通常是比较容易的，直接从所有根据子问题递推得到的解中选出一个最优解即可。
一般情况下，还需要记录此时的选择，用于构造出一个最优解。</p>

<p>把上述的问题都考虑好之后，就可以按照问题的大小，
从小到大依次将各个问题解决，直到达到所需要的问题的大小，
就得到了所需问题的解。</p>

<h3 id="section-7">动态规划的经典问题</h3>

<h4 id="lcs">最长公共子序列（LCS）</h4>

<ul>
  <li>问题描述：
定义序列<script type="math/tex">% &lt;![CDATA[
 X = <x_1, x_2, ..., x_m>  %]]&gt;</script>的一个子序列为
<script type="math/tex">% &lt;![CDATA[
 Z = <x_{i_1}, x_{i_2}, ..., x_{i_k}>  %]]&gt;</script>，其中
<script type="math/tex">% &lt;![CDATA[
 i_1 < i_2 < ... < i_k, k \geq 1  %]]&gt;</script>。求两个序列
<script type="math/tex">% &lt;![CDATA[
 X = <x_1, x_2, ..., x_m>  %]]&gt;</script>和<script type="math/tex">% &lt;![CDATA[
 Y = <y_1, y_2, ..., y_n>  %]]&gt;</script>的最长公共子序列的长度c[m, n]。</li>
  <li>
    <p>求解方法：
定义c[i, j]为序列<script type="math/tex"> X_i </script>和<script type="math/tex"> Y_j </script>的LCS的长度，
有如下递推公式成立</p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 
      c[i, j] = 
          \begin{cases}
              0 & \text{i=0 或j=0} \\
              c[i-1, j-1] + 1 & i,j > 0, x_i = y_j \\
              max\{c[i, j-1], c[i-1, j]\} & i,j > 0, x_i \neq y_j
          \end{cases}
   %]]&gt;</script>
  </li>
  <li>说明:
其实c[i, j]有三个子问题， c[i-1, j-1], c[i-1, j], c[i, j-1],
为什么当<script type="math/tex"> x_i = y_j </script>时只需要考虑第一个子问题，因为有如下不等式成立:</li>
</ul>

<script type="math/tex; mode=display">
c[i-1, j-1] + 1 \geq c[i, j-1] \\
c[i-1, j-1] + 1 \geq c[i-1, j]
</script>

<p>因为c[i, j-1]相对于c[i-1, j-1]就多了一个元素c[i]，
最多能够为最长公共子序列多增加长度1，同理对于c[i-1, j]也是如此。</p>

<h4 id="section-8">背包问题</h4>

<ul>
  <li>问题描述：
给定一个重量为w的背包，有n件商品重量分别为<script type="math/tex"> w_1, w_2, ..., w_n </script>,
价值分别为<script type="math/tex"> v_1, v_2, ..., v_n </script>，求这个背包能容纳的最大的商品价值</li>
  <li>
    <p>问题求解：</p>

    <ul>
      <li>如果对于每一件商品，可以拿取任意多次，则定义K(w)表示重量为w的背包最大的价值，
  有如下递推关系成立：</li>
    </ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

  K(w) = max\{K(w-w_i) + v_i\}, i=1..n, w_i < w
   %]]&gt;</script>

    <ul>
      <li>如果没一件商品只能拿一次，就不能采取上面的方法了，因为如果在K(w)转换至<script type="math/tex"> K(w-w_i) </script>时使用了
  商品i, 在求解<script type="math/tex"> K(w-w_i) </script>就不能再使用商品i,上述的递推公式不成立。必须采用另外一种方法。
  定义K(w, i)为重量为w的背包在装载商品1..i时的最大价值，有如下递推关系成立：</li>
    </ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

  K(w, i) = max\{K(w-w_i, i-1) + v_i, K(w, i-1)\}, i=1..n, w_i < w
   %]]&gt;</script>
  </li>
</ul>

<h3 id="floyd">Floyd算法的正确性</h3>

<p>Floyd算法用于求解图中所有节点中的最短路径。
基本思想是通过n（n为节点个数）次循环更新所有节点对之间的最短路径，
伪代码如下：</p>

<p><div class="highlight"><pre><code class="pascal">    <span class="k">for</span> <span class="n">k</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
        <span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
            <span class="k">for</span> <span class="n">j</span> <span class="o">:=</span> <span class="mi">1</span> <span class="k">to</span> <span class="n">n</span>
                <span class="k">if</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">path</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="err">&amp;</span><span class="n">lt</span><span class="o">;</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="k">then</span>
                    <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">:=</span> <span class="n">path</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">+</span><span class="n">path</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">;</span>
</code></pre></div></p>

<p>在每次迭代时，对于任意节点对(i, j)，如果(i, k)的路径长度加(k, j)的路径长度小于
原来的(i, j)的路径长度，
那么就将(i, j)的路径长度更新为(i, k)的路径长度加(k, j)的路径长度（也就是说，
让(i, j)的最短路径经过k）。
算法的时间复杂度为<script type="math/tex"> O(n^3) </script>。</p>

<p>动态规划对于这个算法的理解是，在迭代k结束之后，
此时(i, j)的最短路径为仅使用{1, 2, …, k}作为中间节点的最短路径，
当循环结束时，k=n, 此时(i, j)的最短路径为使用任意节点作为中间节点的最短路径，
也就是(i, j)之间的最短路径。</p>

<p>凭直接感觉，比如说(i, j)之间的最短路径为：</p>

<script type="math/tex; mode=display">
i \rightarrow ... \rightarrow k_1 \rightarrow ... \rightarrow k_2 \rightarrow ... \rightarrow j
</script>

<p>其中<script type="math/tex">% &lt;![CDATA[
 k_1 < k_2  %]]&gt;</script>,
如果最外层的循环遍历到<script type="math/tex"> k_1 </script>时，因为此时不能使用<script type="math/tex"> k_2 </script>作为中间节点，
所以不会把(i, j)之间的最短路径经过<script type="math/tex"> k_1 </script>，
当允许使用<script type="math/tex"> k_2 </script>作为中间节点时，
有不会再去遍历<script type="math/tex"> k_1 </script>让(i, j)之间的最短路径经过<script type="math/tex"> k_1 </script>, 
所以，(i, j)之间的最短路径没有被找到，这个算法好像是错误的。</p>

<p>我开始老是纠结在这样的感觉中，
认为Floyd算法可能并没有找到一条最短的路径，
可是又总是找不到一个反例，
后面经过仔细地思考，总结出两种方法来说明这个算法的正确性，
解除了我的疑虑。</p>

<h4 id="floyd-1">通过循环不变式来证明Floyd算法的正确性</h4>

<p>通过证明以下循环不变式证明算法的正确性:</p>

<p>在第k轮迭代开始前，对于任意节点对(i, j)，
此时的最短路径长度为使用节点{1, 2, .., k-1}作为中间节点的最短路径长度。</p>

<ol>
  <li>初始化：在开始时，k=1, 此时的最短的路径为不使用任何中间节点的最短路径。</li>
  <li>保持：在第k轮迭代开始时，
此时(i, j)之间的最短路径为使用{1，2，…, k-1}作为中间节点的最短路径，
令p为(i, j)之间使用{1, 2, …, k}的最短路径：
    <ul>
      <li>如果path[i][k] + path[k][j] &lt; path[i][j]，
 那么此时p一定为<script type="math/tex"> i \xrightarrow{p_1} k \xrightarrow{p_2} j </script>，
 其中<script type="math/tex"> p_1 </script>为(i, k)之间使用{1, 2, …, k-1}作为中间节点的最短路径，
 <script type="math/tex"> p_2 </script>为(k, j)之间使用{1, 2, …, k-1}作为中间节点的最短路径。
 所以此时p的长度为path[i][k] + path[k][j]，不变式得以保持</li>
      <li>如果path[i][k] + path[k][j] &gt;= path[i][j]，
 那么此时p一定也是(i, j)仅经过{1, 2, …, k-1}的最短路径(也就是说，
 此时p一定不经过k)，p的长度就是path[i][j], 不变式同样可以保持</li>
    </ul>
  </li>
  <li>终止：循环结束时，k=n+1, 此时(i, j)的最短路径是使用任意节点作为中间节点的最短路径，
也就是(i, j)的最短路径。</li>
</ol>

<p>对于这个循环不变式，定义<script type="math/tex"> path^{(k)}(i, j) </script>表示(i, j)之间仅使用节点1,…,k作为中间节点的最短路径的长度，
利用这个递推公式：</p>

<script type="math/tex; mode=display">
path^{(k)}(i, j) = min\{ path^{(k-1)}(i, k) + path^{(k-1)}(k, j), path^{(k-1)}(i, j) \}
</script>

<p>可能要更好理解一些。</p>

<h4 id="floyd-2">通过归纳证明Floyd算法的正确性</h4>

<p>可以通过这样一种思路来证明：假设k是(i, j)最短路径中最大的中间节点，
也就是说对于(i, j)最短路径中任意的中间节点m, 有<script type="math/tex"> m \leq k </script>，这样，
k是(i, j)最短路径中最后被迭代的节点，如果在迭代到k时，
能够将(i, j)之间最短路径长度正确的设置，那么这个算法就是正确的。
在迭代k时，如果(i, k)和(k, j)之间的最短路径已经被正确设置时，
那么(i, j)在迭代k结束之后能够被正确设置。</p>

<p>下面通过归纳(i, j)路径中中间节点的个数n来证明在迭代k(k是(i, j)最短路径中最后被迭代的节点)时，
(i, k)和(k, j)最短路径已经被正确的设置：</p>

<ol>
  <li>当n=1, 在迭代k时，(i, k)和(k, j)都没有中间节点，
最短路径就是节点i和k以及k和j之间的距离, 已经被正确的设置。</li>
  <li>如果<script type="math/tex"> n \leq s </script>时，命题成立。那么当n=s+1时，在迭代k时，
对于路径(i, k), 它的中间节点的个数<script type="math/tex"> n_1 \leq s </script>，
那么当这条路径的最后一个节点<script type="math/tex"> k_1 </script>被迭代时，<script type="math/tex"> (i, k_1) </script>和<script type="math/tex"> (k_1, k) </script>已经被正确设置，
迭代之后，能够将路径(i, k)正确设置，同理可以证明路径(k , j)也能够被正确设置。</li>
  <li>由上述两步可以得知对于任意个数的中间节点，(i, j)在迭代最后一个节点k时，
(i, k)和(k, j)能够被正确的设置。</li>
</ol>

<h3 id="section-9">忽略我</h3>
<p>最后还是吐槽一下动态规划这一章的翻译真的很烂，
感觉和前面的章节不是同一个人翻译的，
很多语句很不通顺，比如说有个反问句就绕了我好久，
试着推测原文才明白什么意思。
人和人之间还是有差距的啊，不管做什么都是，
希望后面的几章能够翻译好一点，bless!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《算法导论》之基本数据结构]]></title>
    <link href="http://chouqin.github.io/blog/2012/12/04/clrs-10-13/"/>
    <updated>2012-12-04T00:00:00+08:00</updated>
    <id>http://chouqin.github.io/blog/2012/12/04/clrs-10-13</id>
    <content type="html"><![CDATA[<h2 id="section">散列表中碰撞的解决</h2>
<p>由于散列表的元素个数小于关键字的取值集合U,
因此会有两个不同的关键字映射到散列表的同一个槽上，
这时就发生了碰撞。发生了碰撞时，
书上给出了两种方法来解决，
而且保证此时的散列表平均情况下的查找复杂度是O(1)。</p>

<h3 id="section-1">链接法</h3>
<p>在链接法中，关键字映射到同一个槽上的元素通过一个链表来保存，
此时散列表T[0..m-1]的任意元素T[j]是一个链表，
当插入一个元素时，将元素放在它所对应的槽所指向链表的头部。
下面对链接法的性能进行分析。</p>

<p>定义散列表T的装载因子<script type="math/tex"> \alpha = n / m </script>, 其中n是元素个数，m是散列表槽数,
我们假设元素满足简单一致散列的条件：
任何元素散列到m个槽中的每一个的可能性是相同的。</p>

<p>用<script type="math/tex"> n_j </script>表示链表T[j]的长度，有
$$
E[n_j] = \alpha = n/m
$$</p>

<p>有如下性质成立：</p>

<ol>
  <li>
    <p>链接方式散列表在简单一致假设下，查找一个不存在元素所需时间的期望为<script type="math/tex"> \Theta (1 + \alpha) </script></p>

    <p>假设查找的元素是k, 它所对应的槽为h(k)，链表T[h(k)]的长度<script type="math/tex"> E[n_{h(k)}] = \alpha </script>，
 所以平均情况下需要遍历一个长度为<script type="math/tex"> \alpha </script>的链表，外加常数的散列函数时间和寻址T[h(k)]的时间，
 总共为<script type="math/tex"> \Theta (1 + \alpha) </script></p>
  </li>
  <li>
    <p>链接方式散列表在简单一致假设下，平均查找一个已存在的元素所需的时间为<script type="math/tex"> \Theta (1 + \alpha) </script></p>

    <p>对于任意元素x，检查的元素个数等于x所在链表中，出现在x之前的元素个数加1。
 设<script type="math/tex"> x_i </script>是第i个插入的元素，i=1,2,..,n,
 定义：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

     X_{ij} =
      \begin{cases}
          1 & x_i\text{和}x_j\text{在同一槽中} \\
          0 & \text{否则}
      \end{cases}
  %]]&gt;</script>

    <p>由简单一致性假设，<script type="math/tex"> E[X_{ij}] = 1/m </script>，所以检查元素个数的期望为：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

 \begin{array} {lcl}
 E[\frac{1}{n} \sum_{i=1}^{n} (1 + \sum_{j=0}^{i-1}X_{ij})]
     &=& 1 + \frac{n-1}{2m} \\
     &=& 1 + \frac{\alpha}{2} - \frac{\alpha}{2n}
 \end{array}
  %]]&gt;</script>

    <p>所以平均查找时间为: <script type="math/tex"> \Theta (2 + \frac{\alpha}{2} - \frac{\alpha}{2n}) = \Theta (1 + \alpha) </script></p>
  </li>
</ol>

<!--more-->

<h3 id="section-2">开放寻址法</h3>
<p>在开放寻址法中，对于每一个关键字k，定义探查序列
    &lt;h(k, 0), h(k, 1),…, h(k, m-1)&gt;
是&lt;0, 1, …, m-1&gt;的一个排列。在插入某一个元素x时，如果它的关键字是k,
按照它所对应的探查序列从h(k, 0)到h(k, m-1)依次检查散列表，如果h(k,i)是空槽，
那么将x插入到这个槽，否则检查h(k, i+1)。在查找时，
也是沿着探查序列开始寻找。</p>

<p>探查序列的计算方法有很多，比如说线性探查法，二次探查法，双重散列法。
但是这些技术都不能保证一致散列的假设：
对于每一个关键字k, &lt;h(k, 0), h(k, 1),…, h(k, m-1)&gt;是&lt;0, 1, …, m-1&gt;的任何一种排列的可能性是相同的。</p>

<p>在一致散列的假设下，有如下性质成立：</p>

<ul>
  <li>对于装载因子为<script type="math/tex">% &lt;![CDATA[
 \alpha = n/m < 1  %]]&gt;</script>的开放散列表，查找一个不存在的元素所需的探查数期望至多为<script type="math/tex"> \frac{1}{1-\alpha} </script>
定义随机变量X为探查数，<script type="math/tex"> A_i </script>为进行了第i次探查，有:</li>
</ul>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
E[X] &= \sum_{i=1}^{\infty} i \bullet Pr\{X = i\} \\
    &= (Pr\{X=1\} + Pr\{X=2\} + ...) + (Pr\{X=2\} + Pr\{X=3\} + ...) + ... \\
       &= \sum_{i=1}^{\infty}Pr\{ X \geq i \} \\
Pr\{ X \geq i \} &= Pr\{ A_1 \bigcap A_2 \bigcap ... \bigcap A_{i-1} \} \\
    &= Pr\{A_1\} \bullet Pr\{ A_2 | A_1 \} \bullet ... \bullet Pr\{ A_{i-1} | A_1 \bigcap A_2 \bigcap ... \bigcap A_{i-2} \} \\
Pr\{ A_1 \} &= \frac{n}{m} = \alpha \\
Pr\{ A_j | A_1 \bigcap A_2 \bigcap ... \bigcap A_{j-1} \} &= \frac{n-j+1}{m-j+1} \leq \frac{n}{m} = \alpha \\
Pr\{X \geq i \} &= \frac{n}{m} \bullet \frac{n-1}{m-1} \bullet \frac{n-2}{m-2} \bullet ... \bullet \frac{n-i+2}{m-i+2} \\
    &\leq (\frac{n}{m})^{i-1} = \alpha^{i-1} \\
E[X] &= \sum_{i=1}^{\infty}Pr\{ X \geq i \} \leq \sum_{i=1}^{\infty} \alpha^{i-1} \\
    &= \sum_{i=1}^{\infty} \alpha^{i-1} = \frac{1}{1-\alpha}
\end{align}
 %]]&gt;</script>

<ul>
  <li>
    <p>向一个装载因子为<script type="math/tex"> \alpha </script>的开放寻址散列表中插入一个元素，平均情况下最多进行<script type="math/tex"> \frac{1}{1-\alpha} </script>次探查。</p>

    <p>因为要插入一个元素x，只需要做一次查找x就能找到一个空槽，所以探查次数与查找一个不存在元素的查找相同。</p>
  </li>
  <li>
    <p>一个装载因子为<script type="math/tex"> \alpha </script>的开放散列表中查找一个存在的元素的期望探查次数至多为<script type="math/tex"> \frac{1}{\alpha} \ln \frac{1}{1-\alpha} </script></p>

    <p>对于每一个元素x，查找它所需要的探查次数与插入它所需要的探查次数相同，
  对于第i个插入的元素x, 所需的探查次数最多为<script type="math/tex"> \frac{1}{1-\frac{i}{m}} = \frac{m}{m-i} </script>，
  所以平均的探查次数最多为：</p>

<script type="math/tex; mode=display">
  \frac{1}{n} \sum_{i=0}^{n-1} \frac{m}{m-i} = \frac{m}{n} \sum_{i=0}^{n-1}\frac{1}{m-i}
      \leq \frac{1}{\alpha} \ln \frac{1}{1-\alpha}
  </script>
  </li>
</ul>

<p>对比开放寻址法与链接法，链接法能够支持装载因子<script type="math/tex"> \alpha > 1 </script>的情况，
而开放寻址法不能支持。</p>

<h2 id="section-3">二叉查找树与红黑树</h2>
<p>二叉查找树和红黑数都是用来存储动态集合的数据结构，
红黑树对二叉查找树进行了扩展，通过一些额外的性质，
保证了二叉查找树的平衡性，
这样就能够保证树的高度为O(lgn)， 其中n是节点的个数。
有了这些额外的性质时，
在插入节点或者删除节点的时候就需要一些额外的操作来保持这些性质。</p>

<h3 id="section-4">二叉查找树的基本操作</h3>
<p>二叉查找树所支持的基本操作有：</p>

<ol>
  <li>查找。
因为在二叉查找树中， 对于任何一个节点，
左子树中的关键字都小于当前节点的关键字，
而右子树中的关键字都大于当前节点的关键字，
所以可以通过一个简单的递归的来查找一个关键字：
如果关键字大于当前关键字，则递归查询右子树，
否则如果关键字小于当前关键字，递归查询左子树。</li>
  <li>
    <p>插入。插入也可以通过简单的递归来实现：</p>

    <ul>
      <li>如果要插入的关键字大于当前的关键字，如果右子树为空，
 则把这个节点作为当前节点的右儿子，否则递归插入到右子树</li>
      <li>如果要插入的关键字小于当前的关键字，如果左子树为空，
 则把这个节点作为当前节点的左儿子，否则递归插入到左子树</li>
    </ul>
  </li>
  <li>寻找二叉查找树中的最小节点和最大节点。
这两个操作是对称的，只需要给出求最小节点的方法，
采用递归的方式实现：
    <ul>
      <li>如果左子树非空，则返回左子树中的最小节点</li>
      <li>否则返回当前节点</li>
    </ul>
  </li>
  <li>寻找节点x的直接前趋或者直接后继。
这两个操作是对称的，只需要给出寻找直接后继的方法：
节点x的直接后继是指关键字大于key[x]中最小的那个节点，
    <ul>
      <li>如果x的右儿子存在，那么后继在x的右子树中，
 以x的右子树中的最小节点就是x的直接后继</li>
      <li>如果x的右儿子不存在，那么需要</li>
    </ul>
  </li>
  <li>删除。在删除一个节点x的时候，有三种情况需要考虑：
    <ul>
      <li>如果要删除的节点是叶节点，直接删除即可。</li>
      <li>如果要删除的节点只有一个儿子，那么先建立它的祖先和它儿子的父子关系,
 然后把它删除。</li>
      <li>如果要删除的节点有两个儿子，那么先从它的右子树中找到x的直接后继节点y，
 此时y一定没有左儿子（因为如果y有左儿子的话左儿子一定大于x且小于y，
 与y是x的直接后继矛盾）, 所以可以把y先从树中移除(删除y一定属于前两种情况)，
 然后用y代替x的位置。</li>
    </ul>
  </li>
</ol>

<h3 id="section-5">红黑树的性质</h3>
<p>相对于二叉查找树来说，赋予了每一个节点红色或者黑色，
同时整个红黑树需要保持下面的性质：</p>

<ol>
  <li>每个节点或者是红的，或者是黑的</li>
  <li>根节点是黑的</li>
  <li>每个叶节点是黑的</li>
  <li>如果一个节点是红的，那么它的两个儿子必须是黑的</li>
  <li>对每一个节点，从该节点到叶节点的所有路径上包含相同数目的黑节点</li>
</ol>

<p>其中，性质3可以不用考虑，因为在红黑树中，
所有的叶节点都是NIL, 它永远都是黑色。</p>

<p>有了这几条性质之后，
能保证一棵有n个节点（不包括NIL叶节点）的红黑树高度至多为2lg(n+1)。
这时，查找操作能够在O(lgn)的时间内完成。</p>

<h3 id="section-6">在插入和删除时红黑树性质的保持</h3>
<p>红黑树的性质可能在插入或者删除节点的时候被破坏，
此时需要一些操作来维护红黑数的性质。</p>

<h4 id="section-7">插入</h4>
<p>插入一个节点时，始终把新插入的节点的设成红色，
这时，会有两种原因造成红黑树性质的破坏：</p>

<ol>
  <li>如果新插入的节点是根节点，那么会破坏性质2</li>
  <li>如果插入节点的父节点是红色，那么将会破坏性质4</li>
</ol>

<p>函数RB-INSERT_FIX_UP()用于在插入z时红黑树T性质的保持：</p>

<pre><code>def RB-INSERT-FIXUP (T, z):
    while color[p[z]] = RED
        do if p[z] = left[p[p[z]]]
            then y ← right[p[p[z]]]
            if color[y] = RED                   
                then color[p[z]] ← BLACK        ###case1
                color[y] ← BLACK                ###case1
                color[p[p[z]]] ← RED            ###case1
                z ← p[p[z]]                     ###case1
            else if z = right[p[z]]            
                    then z ← p[z]               ###case2
                    LEFT-ROTATE (T, z)          ###case2
                color[p[z]] ← BLACK             ###case3
                color[p[ p[z]]] ← RED           ###case3
                RIGHT-ROTATE (T, p[p[z]])       ###case3
        else (same as then clause
            with “right” and “left” exchanged)
    color[root[T]] ← BLACK
</code></pre>

<p>这个函数能达到目的因为：</p>

<ol>
  <li>如果是上面的原因1违反, 那么p[z]是黑色，不会进入循环，直接在最后一行把根节点设为黑色</li>
  <li>如果是原因2违反，情况就要复杂一些，不能简单地把当前节点或者其父节点设为黑色就能解决问题，
因为此时可能会导致从根到各个叶节点路径上黑节点数目不相等（经过z的个数多1）。在这种情况下，
就要想办法把性质4的不一致向根节点“传递”，因为如果这种不一致到了根节点，
直接把根节点设为红色就可以，而不会引起其他的问题, 代码中分了三种情况：
    <ol>
      <li>
        <p>如果是情况1，p[z]和z的叔叔都是红色，可以把p[z]和y(z的叔叔)都设为黑色，
 然后把p[p[z]]设为红色，这样就把这种红红的不一致向上传递了两层，
 这种不一致在向上传递的过程中会有三种情况：</p>

        <ol>
          <li>没有造成不一致， 因为虽然把newz = p[p[z]]设为了红色，但可能此时p[newz]也是黑色，没有违反性质4</li>
          <li>造成不一致然后遇到了情况1， 这时会把这种不一致继续向上传递</li>
          <li>造成不一致然后遇到了情况2，3，这时直接可以通过旋转和颜色调整解决，不用向上传递</li>
        </ol>
      </li>
    </ol>

    <p>无论是哪一种情况，要么会被解决，要么传递到根由根来解决。</p>

    <ol>
      <li>如果是情况2，3，这时可以通过旋转和重新着色解决性质4的不一致，而不会造成其他问题。</li>
    </ol>
  </li>
</ol>

<h4 id="section-8">删除</h4>
<p>在删除一个节点时，如果被删除的节点是红色，
那么不会有问题，因为它的儿子和父亲都是黑色，
不会违背性质4，
同时任何路径上的黑色节点的个数也不会发生变化。
但如果删除的是一个黑色的节点y，会有以下原因导致性质违背：</p>

<ol>
  <li>如果y是根节点，而y的红色儿子成为了新的根，会违背性质2</li>
  <li>如果y的儿子x(y最多有一个儿子，可以从二叉查找树的删除中得到这个结论)和父亲都是红色，
那么会违背性质4</li>
  <li>删除y会导致经过y的路径上的黑节点数目个数少1，违背性质5</li>
</ol>

<p>函数RB-DELETE-FIXUP()用于在删除节点x的父亲时性质维护：</p>

<pre><code>def RB-DELETE-FIXUP(T, x):
    while x != root[T] and color[x] = BLACK
        do if x = left[p[x]]
            then w ← right[p[x]]
            if color[w] = RED
                then color[w] ← BLACK                                  ###case1
                color[p[x]] ← RED                                      ###case1
                LEFT-ROTATE (T, p[x])                                  ###case1
                w ← right[p[x]]                                        ###case1
            if color[left[w]] = BLACK and color[right[w]] = BLACK
                then color[w] ← RED                                    ###case2
                x ← p[x]                                               ###case2
            else if color[right[w]] = BLACK
                    then color[left[w]] ← BLACK                        ###case3
                    color[w] ← RED                                     ###case3
                    RIGHT-ROTATE (T, w)                                ###case3
                    w ← right[p[x]]                                    ###case3
                color[w] ← color[p[x]]                                 ###case4
                color[p[x]] ← BLACK                                    ###case4
                color[right[w]] ← BLACK                                ###case4
                LEFT-ROTATE (T, p[x])                                  ###case4
                x ← root[T]                                            ###case4
        else (same as then clause with “right” and “left” exchanged)
    color[x] ← BLACK
</code></pre>

<p>从代码中可以看出，原因1或者原因2都没有进入循环，直接通过把x设为黑色就能解决问题。
解决原因3的基本思路是给x赋予一层多余的黑色(充当一个黑色节点的计数)，试着把这个多余的黑色往根传递, 
在向上传递的过程中，可能会遇到3种情况：</p>

<ol>
  <li>这种多余的黑色传递到了一个红色的节点，那么直接把这个红色的节点设为黑色即可</li>
  <li>在传递过程中遇到了情况3，4，可以通过旋转和颜色调整而解决问题，不会引起其他的问题</li>
  <li>一直遇到情况2而传递到了根节点，这时直接去掉这个多余的黑色即可，
因为此时从根到叶节点的所有路径的黑节点数目都少1，性质5得到解决。</li>
</ol>

<p>为什么再调整过程中旋转的次数不超过3次？简单看来，有如下转换关系：</p>

<ol>
  <li>case1 -&gt; case2, case3, case4,情况1结束之后将到达情况2，或情况3，或情况4</li>
  <li>case2 -&gt; new while, 情况2之后将进入新的循环</li>
  <li>case3 -&gt; case4，情况3将到达情况4</li>
  <li>case4 -&gt; 终止，情况4之后把x设为root，将导致循环终止</li>
</ol>

<p>情况1会有旋转，如果进入了情况3或情况4，将导致循环终止，此时旋转次数不超过3次，
但如果进入进入情况2，那么将会进入新的循环，此时有可能碰到情况1然后再次旋转，
然后进入再进入情况2…这样一直向上到根，旋转的次数可能会超过3次，
是这样吗？</p>

<p>上面的情况的是不可能发生的，因为情况1会把p[x]设为红色，如果此时进入情况2，
在新的循环开始时，新的x就是p[x]，它的颜色是红色，直接会退出循环，把x设为黑色，
调整结束，不会再继续向上传递。所以旋转的次数不会超过3次。</p>
]]></content>
  </entry>
  
</feed>
